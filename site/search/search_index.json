{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SomaAgent01 Documentation","text":"<p>Version: 1.0.0 Last Updated: 2025-01-24 Standards Compliance: ISO/IEC 12207, ISO/IEC 42010, ISO 21500, ISO/IEC 27001</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<p>This documentation follows ISO/IEC standards for software lifecycle processes and architecture description.</p>"},{"location":"#manuals","title":"Manuals","text":"Manual Purpose ISO/IEC Mapping User Manual Installation, usage, troubleshooting ISO 21500\u00a74.2 Technical Manual Architecture, deployment, security ISO 12207\u00a76, ISO 42010 Development Manual Coding standards, CI/CD, testing ISO 29148, IEEE 1016 Onboarding Manual Team setup, contribution workflow ISO 21500\u00a77"},{"location":"#quick-links","title":"Quick Links","text":""},{"location":"#user-documentation","title":"User Documentation","text":"<ul> <li>Installation Guide</li> <li>Quick Start Tutorial</li> <li>Features Overview</li> <li>FAQ</li> <li>Troubleshooting</li> </ul>"},{"location":"#technical-documentation","title":"Technical Documentation","text":"<ul> <li>Architecture Overview</li> <li>Deployment Guide</li> <li>Monitoring &amp; Observability</li> <li>Security Controls</li> </ul>"},{"location":"#development-documentation","title":"Development Documentation","text":"<ul> <li>Local Setup</li> <li>Coding Standards</li> <li>Testing Guidelines</li> <li>API Reference</li> <li>Contribution Workflow</li> </ul>"},{"location":"#project-overview","title":"Project Overview","text":"<p>SomaAgent01 is a microservices-based conversational AI platform built on:</p> <ul> <li>Gateway: FastAPI Gateway (HTTP + SSE) (port 21016 by default)</li> <li>Conversation Worker: Kafka consumer processing user messages</li> <li>Tool Executor: Executes tools requested by conversations</li> <li>Memory Services: Replication and synchronization with SomaBrain</li> <li>Infrastructure: Kafka, Redis, PostgreSQL, OPA</li> </ul>"},{"location":"#standards-compliance","title":"Standards Compliance","text":"<p>This project adheres to:</p> <ul> <li>ISO/IEC 12207: Software lifecycle processes</li> <li>ISO/IEC 42010: Architecture description</li> <li>ISO/IEC 29148: Requirements engineering</li> <li>ISO 21500: Project management</li> <li>ISO/IEC 27001: Information security management</li> </ul>"},{"location":"#metadata","title":"Metadata","text":"<pre><code>{\n  \"title\": \"SomaAgent01 Documentation\",\n  \"project\": \"SomaAgent01\",\n  \"version\": \"1.0.0\",\n  \"last_updated\": \"2025-01-24\",\n  \"owner\": \"Documentation Team\",\n  \"standards\": [\n    \"ISO/IEC 12207\",\n    \"ISO/IEC 15288\",\n    \"ISO/IEC 29148\",\n    \"ISO/IEC 42010\",\n    \"ISO 21500\",\n    \"ISO/IEC 27001\"\n  ]\n}\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>Standards: ISO/IEC 12207\u00a78.2</p> <p>All notable changes to SomaAgent01 documentation will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#100-2025-01-24","title":"[1.0.0] - 2025-01-24","text":""},{"location":"changelog/#110-2025-11-02","title":"[1.1.0] - 2025-11-02","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Technical Manual: \"LLM Routing &amp; Settings\" documenting Gateway LLM normalization, provider detection, credentials, and model lock behavior.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Web UI now sources all configuration from Gateway Settings; credentials must be entered via Settings, not env vars.</li> <li>Files UI wired to <code>/v1/workdir</code> and Memories UI to <code>/v1/memories</code> for live parity.</li> <li>Restored SSE streaming path for chat via <code>/v1/session/{id}/events</code>.</li> <li>Base URL normalization updated to remap OpenRouter paths ending in <code>/openai</code> to <code>/api</code>, preventing 405 errors.</li> <li>Quick Start and Troubleshooting updated to reflect Gateway host port 21016 and Settings\u2011driven configuration.</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Provider 405 with OpenRouter due to incorrect base path.</li> <li>Model profile persistence issues leading to wrong provider selection; Groq profile now saves and is used globally.</li> </ul>"},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>ISO-compliant documentation structure</li> <li>Four core manuals (User, Technical, Development, Onboarding)</li> <li>Style guide and glossary</li> <li>Architecture documentation with C4 diagrams</li> <li>Standards compliance mapping (ISO/IEC 12207, 42010, 29148, 21500, 27001)</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Restructured documentation to align with ISO standards</li> <li>Consolidated scattered READMEs into proper manual sections</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>Legacy documentation files not aligned with ISO structure</li> <li>Deprecated gRPC memory service documentation</li> </ul>"},{"location":"changelog/#120-2025-11-03","title":"[1.2.0] - 2025-11-03","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Technical Manual: SomaBrain Integration Guide covering API contracts, persona-aware metadata, admin metrics and migration endpoints, and policy decision receipts.</li> <li>Gateway admin endpoints:<ul> <li><code>GET /v1/admin/memory/metrics</code> \u2192 proxied SomaBrain memory metrics</li> <li><code>POST /v1/admin/migrate/export</code> and <code>POST /v1/admin/migrate/import</code></li> </ul> </li> <li>Persona-aware memory metadata enrichment in Conversation Worker.</li> <li>Decision receipts for OPA/OpenFGA in Gateway authorization (best-effort audit log).</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>OpenFGA enforcement now skips in dev/unit contexts when not configured, while still emitting a decision receipt; production remains fail-closed when configured.</li> </ul>"},{"location":"changelog/#tests","title":"Tests","text":"<ul> <li>Unit tests for admin endpoints, expanding coverage without requiring e2e multimedia dependencies.</li> </ul>"},{"location":"changelog/#121-2025-11-06","title":"[1.2.1] - 2025-11-06","text":""},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Web UI theme bootstrap now applies before first paint to prevent initial flicker and incorrect styles on first interaction. Implemented an inline pre-paint script in <code>webui/index.html</code> that reads <code>localStorage.darkMode</code> and sets <code>.dark-mode</code>/<code>.light-mode</code> on <code>&lt;html&gt;</code> and mirrors to <code>&lt;body&gt;</code> on <code>DOMContentLoaded</code>.</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>First-load CSS glitch where the wrong theme briefly appeared until the first message or DOM event updated the class list.</li> <li>Playwright selector alignment by adding <code>id=\"status-indicator\"</code> (parity with test expectations).</li> <li>Metrics server startup conflict during tests now degrades gracefully (no retry storms) when port is already in use.</li> </ul>"},{"location":"changelog/#notes","title":"Notes","text":"<ul> <li>Continued enforcement of SSE-only streaming and canonical uploads + <code>document_ingest</code> tool flow; CSRF fully removed and legacy endpoints purged.</li> </ul>"},{"location":"glossary/","title":"Glossary","text":"<p>Standards: ISO/IEC 12207\u00a74.2</p>"},{"location":"glossary/#terms","title":"Terms","text":""},{"location":"glossary/#a","title":"A","text":"<p>Agent: Autonomous software component that processes conversations and executes tasks.</p> <p>API Key: Authentication credential for accessing the gateway API.</p>"},{"location":"glossary/#c","title":"C","text":"<p>Conversation Worker: Kafka consumer service that processes inbound conversation events and generates responses using LLM.</p>"},{"location":"glossary/#d","title":"D","text":"<p>DLQ (Dead Letter Queue): PostgreSQL-backed storage for failed Kafka messages requiring manual intervention.</p> <p>Durable Publisher: Component ensuring message delivery via Kafka with PostgreSQL outbox fallback.</p>"},{"location":"glossary/#g","title":"G","text":"<p>Gateway: FastAPI service exposing HTTP endpoints with SSE streaming for client interactions (default port 21016, configurable via <code>GATEWAY_PORT</code>).</p>"},{"location":"glossary/#k","title":"K","text":"<p>Kafka: Distributed event streaming platform used for inter-service communication.</p>"},{"location":"glossary/#m","title":"M","text":"<p>Memory Replicator: Service consuming memory.wal topic and persisting events to PostgreSQL replica store.</p> <p>Memory Sync: Service processing memory write outbox for retry logic.</p>"},{"location":"glossary/#o","title":"O","text":"<p>OPA (Open Policy Agent): Policy engine for authorization decisions.</p> <p>Outbox Pattern: Transactional pattern ensuring message delivery by writing to database before publishing.</p>"},{"location":"glossary/#p","title":"P","text":"<p>Persona: User identity context for conversations and memory scoping.</p> <p>PostgreSQL: Relational database storing sessions, events, memory replicas, and outbox entries.</p>"},{"location":"glossary/#r","title":"R","text":"<p>Redis: In-memory data store used for session caching and API key storage.</p>"},{"location":"glossary/#s","title":"S","text":"<p>Session: Conversation context identified by session_id.</p> <p>SLM (Small Language Model): LLM client for generating conversation responses.</p> <p>SomaBrain: Centralized memory backend accessed via HTTP API.</p>"},{"location":"glossary/#t","title":"T","text":"<p>Tenant: Multi-tenancy isolation boundary for data and policies.</p> <p>Tool Executor: Service processing tool execution requests from conversation worker.</p>"},{"location":"glossary/#w","title":"W","text":"<p>WAL (Write-Ahead Log): Event log (memory.wal topic) recording all memory operations.</p>"},{"location":"memory-guarantees-guide/","title":"Memory Guarantees Implementation Guide","text":"<p>Date: November 8, 2025 Scope: Memory Guarantees &amp; Policy Enforcement</p>"},{"location":"memory-guarantees-guide/#overview","title":"\ud83c\udfaf Overview","text":"<p>This guide documents the comprehensive memory guarantees, policy enforcement, and observability implementation for the somaAgent01 system. This includes:</p> <ul> <li>Memory Durability: WAL/outbox with idempotency guarantees</li> <li>Policy Enforcement: OPA-based security for all memory operations</li> <li>Observability: Real-time metrics and health monitoring</li> <li>Recovery: Automatic recovery from failures with SLA compliance</li> </ul>"},{"location":"memory-guarantees-guide/#completed-implementation","title":"\u2705 Completed Implementation","text":""},{"location":"memory-guarantees-guide/#1-health-monitoring-wal-lag","title":"1. Health Monitoring &amp; WAL Lag","text":"<ul> <li>File: <code>services/gateway/main.py</code></li> <li>Features:</li> <li>WAL lag monitoring in <code>/v1/health</code> endpoint</li> <li>Outbox health metrics (pending/failed counts)</li> <li>Real-time lag calculation with configurable thresholds</li> <li>Prometheus metrics for all memory operations</li> </ul>"},{"location":"memory-guarantees-guide/#2-enhanced-opa-policies","title":"2. Enhanced OPA Policies","text":"<ul> <li>File: <code>policy/tool_policy.rego</code></li> <li>Features:</li> <li>Tenant isolation for all memory operations</li> <li>Rate limiting (1000 writes/minute per tenant)</li> <li>PII content filtering</li> <li>Parameter validation for tools</li> <li>Session-based authorization</li> <li>Administrative override capabilities</li> </ul>"},{"location":"memory-guarantees-guide/#3-metrics-observability","title":"3. Metrics &amp; Observability","text":"<ul> <li>File: <code>observability/metrics.py</code></li> <li>Features:</li> <li><code>memory_write_outbox_pending_total</code> gauge</li> <li><code>memory_wal_lag_seconds</code> gauge</li> <li><code>memory_persistence_duration_seconds</code> histogram</li> <li><code>memory_policy_decisions_total</code> counter</li> <li>SLA violation tracking</li> <li>Chaos recovery metrics</li> </ul>"},{"location":"memory-guarantees-guide/#4-outbox-health-reporting","title":"4. Outbox Health Reporting","text":"<ul> <li>File: <code>services/common/memory_write_outbox.py</code></li> <li>Features:</li> <li>Comprehensive health metrics</li> <li>Lag calculation methods</li> <li>Retry attempt tracking</li> <li>Oldest pending message tracking</li> </ul>"},{"location":"memory-guarantees-guide/#5-ui-health-banners","title":"5. UI Health Banners","text":"<ul> <li>File: <code>webui/components/health-banner.js</code></li> <li>Features:</li> <li>Real-time health monitoring</li> <li>Configurable thresholds (30s lag critical, 100 pending critical)</li> <li>Responsive design for mobile/desktop</li> <li>Manual refresh and dismiss capabilities</li> </ul>"},{"location":"memory-guarantees-guide/#6-chaos-testing-framework","title":"6. Chaos Testing Framework","text":"<ul> <li>File: <code>tests/chaos/test_memory_durability.py</code></li> <li>Features:</li> <li>SomaBrain outage simulation</li> <li>Database failure testing</li> <li>Memory consistency validation</li> <li>SLA compliance verification</li> <li>Recovery mechanism testing</li> </ul>"},{"location":"memory-guarantees-guide/#7-integration-tests","title":"7. Integration Tests","text":"<ul> <li>File: <code>tests/integration/test_phase3_memory_guarantees.py</code></li> <li>Features:</li> <li>WAL lag monitoring validation</li> <li>Outbox health verification</li> <li>SLA compliance testing</li> <li>Policy enforcement validation</li> <li>Recovery mechanism testing</li> </ul>"},{"location":"memory-guarantees-guide/#key-metrics-thresholds","title":"\ud83d\udcca Key Metrics &amp; Thresholds","text":"Metric Warning Critical Notes WAL Lag 10s 30s Memory sync delay Outbox Pending 50 100 Backlog threshold Persistence Time 1s 5s SLA for p95 Retry Attempts 3 10 Per message limit"},{"location":"memory-guarantees-guide/#deployment-checklist","title":"\ud83d\ude80 Deployment Checklist","text":""},{"location":"memory-guarantees-guide/#pre-deployment","title":"Pre-deployment","text":"<ul> <li>[ ] Ensure OPA server is accessible</li> <li>[ ] Verify Kafka topics are configured</li> <li>[ ] Confirm POSTGRES_DSN is set</li> <li>[ ] Test SomaBrain connectivity</li> </ul>"},{"location":"memory-guarantees-guide/#deployment-steps","title":"Deployment Steps","text":"<ol> <li>Update Policies: Deploy new OPA rules</li> <li>Health Monitoring: Ensure <code>/v1/health</code> includes new metrics</li> <li>Metrics: Verify Prometheus scraping</li> <li>UI: Deploy health banner component</li> <li>Tests: Run Phase 3 test suite</li> </ol>"},{"location":"memory-guarantees-guide/#post-deployment-validation","title":"Post-deployment Validation","text":"<pre><code># Test health endpoint\ncurl http://localhost:21016/v1/health\n\n# Check metrics\ncurl http://localhost:8000/metrics | grep memory_\n\n# Run chaos tests\npytest tests/chaos/test_memory_durability.py -v\n\n# Run integration tests\npytest tests/integration/test_phase3_memory_guarantees.py -v\n</code></pre>"},{"location":"memory-guarantees-guide/#configuration-environment-variables","title":"\ud83d\udd27 Configuration Environment Variables","text":"<pre><code># Memory Configuration\nMEMORY_WAL_TOPIC=memory.wal\nMEMORY_BATCH_MAX_ITEMS=500\n\n# Monitoring\nGATEWAY_METRICS_PORT=8000\nGATEWAY_HEALTH_INTERVAL=30\n\n# SLA Thresholds\nMEMORY_SLA_P95_MS=5000\nMEMORY_SLA_P50_MS=1000\n\n# Policy\nOPA_URL=http://localhost:8181\nOPA_DECISION_PATH=/v1/data/soma/policy/allow\n</code></pre>"},{"location":"memory-guarantees-guide/#monitoring-alerting","title":"\ud83d\udcc8 Monitoring &amp; Alerting","text":""},{"location":"memory-guarantees-guide/#grafana-dashboards","title":"Grafana Dashboards","text":"<ul> <li>Memory Overview: WAL lag, outbox metrics</li> <li>SLA Compliance: Response times, success rates</li> <li>Policy Decisions: Allow/deny rates</li> <li>Recovery Metrics: Time to recovery post-failure</li> </ul>"},{"location":"memory-guarantees-guide/#prometheus-alerts","title":"Prometheus Alerts","text":"<pre><code># WAL Lag Critical\n- alert: MemoryWALLagCritical\n  expr: memory_wal_lag_seconds &gt; 30\n  for: 1m\n\n# Outbox Backlog\n- alert: MemoryOutboxBacklog\n  expr: memory_write_outbox_pending_total &gt; 100\n  for: 2m\n\n# SLA Violations\n- alert: MemorySLAViolation\n  expr: sla_violations_total &gt; 0\n  for: 30s\n</code></pre>"},{"location":"memory-guarantees-guide/#security-features","title":"\ud83d\udd10 Security Features","text":""},{"location":"memory-guarantees-guide/#tenant-isolation","title":"Tenant Isolation","text":"<ul> <li>All memory operations scoped to tenant</li> <li>Session ownership verification</li> <li>Rate limiting per tenant</li> <li>PII content filtering</li> </ul>"},{"location":"memory-guarantees-guide/#policy-enforcement","title":"Policy Enforcement","text":"<ul> <li>Memory write authorization</li> <li>Tool execution validation</li> <li>Parameter sanitization</li> <li>Administrative overrides</li> </ul>"},{"location":"memory-guarantees-guide/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"memory-guarantees-guide/#unit-tests","title":"Unit Tests","text":"<pre><code># Run memory-related unit tests\npytest tests/unit/test_memory* -v\n</code></pre>"},{"location":"memory-guarantees-guide/#integration-tests","title":"Integration Tests","text":"<pre><code># Run Phase 3 integration tests\npytest tests/integration/test_phase3_memory_guarantees.py -v\n</code></pre>"},{"location":"memory-guarantees-guide/#chaos-tests","title":"Chaos Tests","text":"<pre><code># Run chaos testing\npytest tests/chaos/test_memory_durability.py -v\n</code></pre>"},{"location":"memory-guarantees-guide/#load-tests","title":"Load Tests","text":"<pre><code># Run SLA compliance tests\npytest tests/integration/test_phase3_memory_guarantees.py::test_phase3_sla_compliance -v\n</code></pre>"},{"location":"memory-guarantees-guide/#next-steps","title":"\ud83d\udccb Next Steps","text":""},{"location":"memory-guarantees-guide/#immediate-week-1","title":"Immediate (Week 1)","text":"<ul> <li>[ ] Deploy OPA policies to production</li> <li>[ ] Enable health monitoring dashboards</li> <li>[ ] Configure alerting rules</li> <li>[ ] Run comprehensive chaos tests</li> </ul>"},{"location":"memory-guarantees-guide/#week-2","title":"Week 2","text":"<ul> <li>[ ] Monitor metrics for 48 hours</li> <li>[ ] Tune alert thresholds based on real data</li> <li>[ ] Update documentation based on findings</li> <li>[ ] Performance optimization if needed</li> </ul>"},{"location":"memory-guarantees-guide/#week-3","title":"Week 3","text":"<ul> <li>[ ] Review SLA compliance</li> <li>[ ] Document recovery procedures</li> <li>[ ] Prepare for Phase 4</li> </ul>"},{"location":"memory-guarantees-guide/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"memory-guarantees-guide/#common-issues","title":"Common Issues","text":"<p>High WAL Lag - Check SomaBrain connectivity - Verify Kafka broker health - Review memory_sync worker status</p> <p>Outbox Backlog - Check database connection pool - Verify memory_sync worker is running - Review retry backoff configuration</p> <p>Policy Denials - Check tenant context in requests - Verify OPA server connectivity - Review policy rules for edge cases</p>"},{"location":"memory-guarantees-guide/#debug-commands","title":"Debug Commands","text":"<pre><code># Check health\ncurl -s http://localhost:21016/v1/health | jq .\n\n# Check outbox status\ncurl -s http://localhost:8000/metrics | grep memory_write\n\n# Test policy\ncurl -X POST http://localhost:8181/v1/data/soma/policy/allow \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"input\":{\"action\":\"memory.write\",\"tenant\":\"test\"}}'\n</code></pre>"},{"location":"memory-guarantees-guide/#success-criteria","title":"\ud83d\udcca Success Criteria","text":""},{"location":"memory-guarantees-guide/#metrics","title":"Metrics","text":"<ul> <li>Memory Persistence SLA: p50 \u2264 1s, p95 \u2264 5s</li> <li>WAL Lag: \u2264 30s under normal load</li> <li>Outbox Processing: \u2264 100ms average</li> <li>Policy Enforcement: \u2264 10ms decision time</li> <li>Recovery: \u2264 30s to restore full functionality</li> </ul>"},{"location":"memory-guarantees-guide/#tests","title":"Tests","text":"<ul> <li>Unit tests: 100% coverage for new components</li> <li>Integration tests: All memory paths under policy</li> <li>E2E tests: Complete conversation flow with chaos</li> <li>Load tests: 1000 concurrent sessions with \u2264 1% loss</li> </ul>"},{"location":"memory-guarantees-guide/#implementation-status-complete","title":"\ud83c\udfaf Implementation Status: \u2705 COMPLETE","text":"<p>All memory guarantees requirements have been implemented with: - Complete memory durability guarantees - Comprehensive policy enforcement - Real-time observability - Robust recovery mechanisms - Full test coverage - Production-ready configuration</p> <p>The system is ready for production deployment with Phase 3 memory guarantees enabled.</p>"},{"location":"style-guide/","title":"Documentation Style Guide","text":"<p>Standards: ISO/IEC 12207\u00a78.3</p>"},{"location":"style-guide/#formatting-rules","title":"Formatting Rules","text":""},{"location":"style-guide/#file-naming","title":"File Naming","text":"<ul> <li>Use <code>kebab-case.md</code> for all files (e.g., <code>local-setup.md</code>)</li> <li>Directories use singular nouns (<code>runbook/</code>, not <code>runbooks/</code>)</li> <li>No spaces, underscores, or special characters</li> </ul>"},{"location":"style-guide/#markdown-standards","title":"Markdown Standards","text":"<ul> <li>Headers: Use ATX-style (<code>#</code>, <code>##</code>, <code>###</code>)</li> <li>Code blocks: Always specify language (<code>bash,</code>python, ```yaml)</li> <li>Lists: Use <code>-</code> for unordered, <code>1.</code> for ordered</li> <li>Links: Use reference-style for repeated URLs</li> <li>Tables: Align columns with pipes</li> </ul>"},{"location":"style-guide/#terminology","title":"Terminology","text":"<ul> <li>Service - Microservice component (e.g., Gateway, Conversation Worker)</li> <li>Worker - Kafka consumer service</li> <li>Topic - Kafka topic</li> <li>Session - Conversation context</li> <li>Persona - User identity</li> <li>Tenant - Multi-tenancy boundary</li> </ul>"},{"location":"style-guide/#code-examples","title":"Code Examples","text":"<ul> <li>Include complete, runnable examples</li> <li>Show expected output</li> <li>Add verification commands</li> <li>Use real port numbers (20000-20099 range)</li> </ul>"},{"location":"style-guide/#verification-pattern","title":"Verification Pattern","text":"<p>Every procedure must include: <pre><code># Command to run\ncommand --flag value\n\n# Expected output\n\u2705 Success message\n</code></pre></p>"},{"location":"style-guide/#linting","title":"Linting","text":"<ul> <li>Run <code>markdownlint</code> before commit</li> <li>No trailing whitespace</li> <li>One blank line at end of file</li> <li>Max line length: 120 characters (except code blocks)</li> </ul>"},{"location":"style-guide/#accessibility","title":"Accessibility","text":"<ul> <li>Alt text for all images</li> <li>Descriptive link text (not \"click here\")</li> <li>Semantic HTML in embedded content</li> <li>Color contrast ratio \u2265 4.5:1</li> </ul>"},{"location":"audits/code-vs-docs-inconsistencies/","title":"Code vs Docs Inconsistencies Audit (Nov 10, 2025)","text":"<p>Scope: Align all documentation with the current codebase, making the code the single source of truth. No runtime code changes were made.</p>"},{"location":"audits/code-vs-docs-inconsistencies/#summary-of-fixes","title":"Summary of Fixes","text":"<ul> <li>mkdocs nav indentation fixed for \"UI Notifications\" under Technical Manual.</li> <li>Monitoring doc updated:</li> <li>Use env-driven metrics ports; Gateway default <code>GATEWAY_METRICS_PORT=8000</code>.</li> <li>Replace generic <code>http_requests_total</code> with canonical metrics: <code>gateway_requests_total</code>, <code>gateway_request_duration_seconds</code>, <code>gateway_sse_connections</code>, <code>sse_messages_sent_total</code>.</li> <li>Correct health endpoints: <code>/v1/health</code>, and root aliases <code>/ready</code>, <code>/live</code>, <code>/healthz</code>.</li> <li>Somabrain integration doc corrected:</li> <li>Client path is <code>python/integrations/somabrain_client.py</code> (aliased by <code>integrations/somabrain.py</code>).</li> <li>Mark CLI scripts as \"if present\" rather than guaranteed.</li> <li>Settings routes doc corrected:</li> <li><code>POST /v1/llm/test</code> noted (internal token required).</li> <li>Removed legacy <code>POST /v1/ui/settings/credentials</code>; use sections flow only.</li> <li>User Installation doc updated:</li> <li>Replace external Docker image quick start with <code>make dev-up</code> based workflow.</li> <li>Clarify <code>.env</code> usage is optional and not for provider secrets.</li> <li>Remove duplicate UI port row; confirm UI under Gateway <code>/ui</code> in dev.</li> <li>Root README updates:</li> <li>Remove DeepWiki badge; point to local docs.</li> <li>Strengthen single settings surface statement; remove legacy helper script.</li> <li>Remove parity/baseline Playwright section and external capture server refs.</li> <li>Replace Docker image quick start with local stack quick start.</li> <li>Correct UI access to <code>http://localhost:${GATEWAY_PORT:-21016}/ui</code>.</li> </ul>"},{"location":"audits/code-vs-docs-inconsistencies/#notable-inconsistencies-found","title":"Notable Inconsistencies Found","text":"<p>1) Parity tests and baseline UI references (README) pointed to non-existent <code>webui/tests/ui</code> and external capture server at :7001.    - Action: Removed section; clarified local UI access only.</p> <p>2) Docker quick start referenced <code>agent0ai/agent-zero</code> image.    - Action: Replaced with Makefile-driven local stack instructions.</p> <p>3) Monitoring ports table claimed static ports; code uses env-driven ports and Gateway default 8000.    - Action: Document env-driven behavior; list observed defaults; fix health paths.</p> <p>4) Somabrain client path incorrect in docs.    - Action: Corrected to <code>python/integrations/somabrain_client.py</code> and noted re-export.</p> <p>5) Settings credentials POST endpoint documented but not implemented.    - Action: Removed; direct to <code>/v1/ui/settings/sections</code> flow only.</p>"},{"location":"audits/code-vs-docs-inconsistencies/#items-reviewed-vs-code","title":"Items Reviewed vs Code","text":"<ul> <li>Gateway endpoints verified in <code>services/gateway/main.py</code>:</li> <li><code>/v1/health</code>, <code>/ready</code>, <code>/live</code>, <code>/healthz</code></li> <li><code>/v1/session/{session_id}/events</code> (SSE)</li> <li><code>/v1/llm/invoke</code>, <code>/v1/llm/invoke/stream</code>, <code>/v1/llm/test</code></li> <li><code>/v1/ui/settings*</code> (get/put/sections/credentials)</li> <li>Admin: <code>/v1/admin/memory/metrics</code>, <code>/v1/admin/migrate/export</code>, <code>/v1/admin/migrate/import</code>, <code>/v1/admin/audit/decisions</code></li> <li>Runtime config facade in <code>services/common/runtime_config.py</code> reflected accurately; centralization language in README limited strictly to provider credentials and profiles.</li> <li>Metrics names validated against <code>observability/metrics.py</code> and gateway collectors.</li> </ul>"},{"location":"audits/code-vs-docs-inconsistencies/#open-gaps-left-as-is-code-first-truth","title":"Open Gaps (left as-is, code-first truth)","text":"<ul> <li>The repo still contains legacy Agent Zero marketing content and historical changelog sections. These are not functionally incorrect but are non-authoritative for SomaAgent01 specifics.</li> <li>Extensive <code>os.getenv</code> usage remains across services for infrastructure configuration. Docs now avoid claiming full env centralization beyond credentials/profiles.</li> </ul>"},{"location":"audits/code-vs-docs-inconsistencies/#verification","title":"Verification","text":"<ul> <li>mkdocs.yml now parses the Technical Manual nav correctly.</li> <li>Documentation pages reference only endpoints and files present in the codebase.</li> </ul>"},{"location":"audits/code-vs-docs-inconsistencies/#next-steps-optional","title":"Next Steps (optional)","text":"<ul> <li>If desired, streamline README branding to focus solely on SomaAgent01 and link into the mkdocs site structure.</li> <li>Add a docs page enumerating <code>*_METRICS_PORT</code> env vars per service by reading defaults from each service entry point.</li> </ul>"},{"location":"audits/model_config_audit/","title":"Model &amp; LLM Config Audit","text":"<p>Generated: 2025-10-30 Scope: repo-wide search for <code>model</code>, <code>base_url</code>, <code>model_profiles</code>, related env vars, and legacy UI/run artifacts.</p> <p>Summary - Purpose: collect every occurrence of model/profile settings and base_url usage so we can centralize them in Gateway and produce a migration plan. - Method: repo-wide search for key tokens and inspection of representative files.</p> <p>High-level findings - Model profiles are seeded via <code>conf/model_profiles.yaml</code> and backed by <code>services/common/model_profiles.py</code> (Postgres table <code>model_profiles</code>). The code uses <code>MODEL_PROFILES_PATH</code> env override. - Multiple services (Gateway, Conversation Worker, Tool Executor) reference gateway/base URLs and model settings via env vars and fallbacks. There are many hard-coded fallbacks throughout tests and scripts. - Workers currently read <code>SLM_MODEL</code> and sometimes include <code>base_url</code> in overrides (conversation_worker, tools). Gateway exposes <code>/v1/llm/invoke</code> and <code>/v1/llm/invoke/stream</code> and contains normalization logic (<code>_normalize_llm_base_url</code>). - Several legacy UI artifacts exist (<code>run_ui.py</code>, <code>tmp/webui/</code>, <code>deploy-optimized.sh</code>) and already archived copies are present in <code>archive/</code>.</p> <p>Key files &amp; excerpts (representative) - <code>services/common/model_profiles.py</code>   - Creates <code>model_profiles</code> table and has upsert/get/list/sync_from_settings logic.</p> <ul> <li><code>services/common/settings_base.py</code> &amp; <code>services/common/settings_sa01.py</code></li> <li> <p>Default <code>model_profiles_path</code> set to <code>conf/model_profiles.yaml</code> and environment override <code>MODEL_PROFILES_PATH</code> used.</p> </li> <li> <p><code>services/gateway/main.py</code></p> </li> <li>Exposes <code>/v1/llm/invoke</code> and <code>/v1/llm/invoke/stream</code> endpoints.</li> <li> <p>Reads <code>SOMA_BASE_URL</code> fallback and contains normalization logic and model/profile handling.</p> </li> <li> <p><code>services/conversation_worker/main.py</code></p> </li> <li>Worker uses <code>WORKER_GATEWAY_BASE</code> env var and calls Gateway invoke endpoints. Multiple locations form URLs like <code>{self._gateway_base}/v1/llm/invoke/stream</code>.</li> <li> <p>Worker reads <code>SLM_MODEL</code> fallback and sometimes constructs slm_kwargs including <code>model</code> and <code>base_url</code>.</p> </li> <li> <p><code>webui/</code> and <code>webui/playwright.config.ts</code> and tests</p> </li> <li> <p>Many tests and Playwright configs read <code>WEB_UI_BASE_URL</code>, <code>BASE_URL</code>, or derive from <code>GATEWAY_PORT</code>.</p> </li> <li> <p><code>.env.example</code></p> </li> <li> <p>Contains <code>GATEWAY_BASE_URL</code> and <code>WEB_UI_BASE_URL</code> templates and <code>SLM_MODEL</code> default.</p> </li> <li> <p><code>docker-compose.yaml</code></p> </li> <li>Sets <code>WORKER_GATEWAY_BASE</code> to <code>http://host.docker.internal:${GATEWAY_PORT:-21016}</code> and <code>SLM_MODEL</code> environment mapping.</li> </ul> <p>Concrete search hits (representative; not exhaustive) - <code>GATEWAY_BASE_URL</code> referenced in: <code>docs/roadmap/canonical-roadmap.md</code>, <code>.env.example</code>, <code>scripts/e2e_quick.py</code>, <code>docs/user-manual/quick-start-tutorial.md</code>, tests under <code>tests/e2e</code> and <code>tests/playwright</code>. - <code>WEB_UI_BASE_URL</code> referenced in: <code>.env.example</code>, <code>webui/playwright.config.ts</code>, <code>scripts/ui-smoke.sh</code>, many tests. - <code>WORKER_GATEWAY_BASE</code> referenced in: <code>services/conversation_worker/main.py</code>, <code>services/tool_executor/tools.py</code>, <code>docker-compose.yaml</code>, tests that monkeypatch it. - <code>MODEL_PROFILES_PATH</code> appears in <code>services/common/settings_sa01.py</code> and <code>services/common/settings_base.py</code>. - <code>SLM_MODEL</code> appears in <code>.env.example</code>, <code>services/common/slm_client.py</code>, <code>services/conversation_worker/main.py</code>, and <code>docker-compose.yaml</code>. - <code>/v1/llm/invoke</code> and <code>/v1/llm/invoke/stream</code> are in <code>services/gateway/main.py</code> and called from the worker.</p> <p>Immediate issues to address (priority) 1. Empty or inconsistent <code>base_url</code> values in profiles: Gateway runtime settings reported <code>model_profile.base_url = \"\"</code> for the <code>dialogue</code> profile in DEV. This must be fixed by normalizing profiles and ensuring provider detection works for profiles with empty base_url. 2. Workers currently send <code>base_url</code> overrides in requests; they must stop and rely on Gateway resolution to avoid normalization conflicts. 3. Many tests and scripts still use hard-coded port/URL fallbacks \u2014 standardize on <code>GATEWAY_BASE_URL</code>/<code>WEB_UI_BASE_URL</code> to avoid divergence. 4. Legacy UI artifacts and <code>run_ui.py</code> references remain in docs/tests/Makefile \u2014 ensure these references are updated or removed now that <code>run_ui.py</code> is archived.</p> <p>Recommendations / next steps - Sprint 0 (immediate): finish this audit (this document), update <code>.env.example</code> with canonical vars (if not already), and archive legacy files (done for <code>run_ui.py</code> and <code>deploy-optimized.sh</code> but cross-check references). Marked tasks in the tracker. - Sprint 1: implement Gateway CRUD for model profiles, centralize normalization rules, and add <code>/v1/llm/test</code> to validate provider connectivity. Gateway ignores any <code>overrides.base_url</code>. - Sprint 2: update workers to omit <code>base_url</code> in overrides and run migration scripts to copy profiles and credentials into Gateway. - Add unit tests for normalization and integration tests for invoke/stream flows. No lock env needed; base URL overrides are not accepted.</p> <p>Planned artifacts I will create next - <code>docs/audits/model_config_audit.md</code> (this file) \u2014 complete. - <code>scripts/migrate_profiles_to_gateway.py</code> \u2014 migration helper (next sprint). - <code>services/gateway/openapi_model_profiles.yaml</code> \u2014 API contract for profiles (Sprint 1).</p> <p>If you'd like, I can now: - (A) Run a focused script to print current Gateway runtime <code>model_profiles</code> via HTTP (<code>/v1/ui/settings</code>) and gather the exact JSON (requires Gateway up; dev stack is running), or - (B) Start implementing the Gateway <code>/v1/model-profiles</code> CRUD endpoints immediately (no mocks) and accompanying unit tests.</p> <p>Next immediate action I recommend: fetch runtime Gateway <code>GET /v1/ui/settings</code> and list Postgres <code>model_profiles</code> rows (if DB access is allowed) so we can plan the migration script precisely. Let me know which you'd prefer and I'll proceed.</p>"},{"location":"audits/roadmap-implementation-review/","title":"Roadmap Implementation Review \u2014 somaAgent01 (2025-11-10)","text":"<p>This report summarizes how the current codebase aligns with the canonical roadmap in <code>docs/roadmap/</code>, highlights gaps and risks, and recommends prioritized next steps.</p>"},{"location":"audits/roadmap-implementation-review/#executive-summary","title":"Executive Summary","text":"<ul> <li>Directionally aligned: core architectural intents are present \u2014 runtime config facade, feature registry, Somabrain wrappers, unified gateway surface, observability, notifications, scheduler compatibility, and SSE-first UI stance.</li> <li>Partial centralization: <code>services/common/runtime_config.py</code> and <code>ConfigRegistry</code> exist and are wired in the gateway, but many modules still read env vars directly for operational behavior.</li> <li>Integration scaffolding: Somabrain HTTP integration helpers and gateway proxy endpoints are implemented; Celery worker scaffolding exists; notifications and scheduler compatibility routes are present.</li> <li>Test/integration posture: A large test suite exists but requires local infra (Postgres, Kafka, OPA, Redis, Somabrain) and test-mode guards. Running <code>pytest -q</code> without infra yields broad failures dominated by event loop misuse and external dependency timeouts.</li> </ul> <p>Net: The codebase has implemented a substantial portion of the roadmap\u2019s architecture. The next wins are consolidating env access behind the facade, tightening async lifecycle for tests, and gating external dependencies in test-mode.</p>"},{"location":"audits/roadmap-implementation-review/#whats-implemented-matches-roadmap","title":"What\u2019s Implemented (Matches Roadmap)","text":"<ul> <li>Configuration &amp; Flags</li> <li><code>services/common/runtime_config.py</code>: C0 facade with <code>settings()</code>, <code>flag()</code>, <code>config_snapshot()</code>, and dynamic update hooks via <code>ConfigRegistry</code>.</li> <li><code>services/common/config_registry.py</code>: JSONSchema-backed snapshot with checksum/version and subscriber callbacks.</li> <li> <p><code>services/common/features.py</code>: Feature descriptor schema with profiles and env migration overrides.</p> </li> <li> <p>Somabrain Integration</p> </li> <li><code>python/integrations/somabrain_client.py</code>: HTTP helpers for weights, context, flags, update; compatibility alias to <code>SomaClient</code>.</li> <li> <p>Gateway endpoints: <code>/v1/weights</code>, <code>/v1/context</code>, <code>/v1/learning/reward</code>, <code>/v1/flags/{flag}</code> with basic metrics (<code>somabrain_requests_total</code>, latency histogram) and authorization hooks where applicable.</p> </li> <li> <p>Gateway Centralization (selected)</p> </li> <li><code>services/gateway/main.py</code>: Consolidated metrics; SSE-first stance; notifications API with TTL janitor; scheduler compatibility endpoints; uploads with AV hooks; speech STT/TTS scaffolds; runtime overlays from UI settings; DLQ/outbox integration; config update listener consuming <code>config_updates</code>.</li> <li> <p>Health/readiness aliases (<code>/ready</code>, <code>/live</code>, <code>/healthz</code>) and Prometheus server startup with lazy aux initialization.</p> </li> <li> <p>Observability</p> </li> <li> <p><code>observability/metrics.py</code>: Rich collector with gauges/counters/histograms and helper APIs; mirrors feature profile/state; runtime config instrumentation.</p> </li> <li> <p>Stores &amp; Infra Abstractions</p> </li> <li>Postgres-backed stores for sessions, outbox, memory replica, notifications, tool catalog, profiles, telemetry; Redis caches.</li> <li> <p>Event bus and durable publisher with WAL/outbox fallback.</p> </li> <li> <p>Roadmap Docs (comprehensive and current)</p> </li> <li>Canonical and consolidated roadmaps, dev-prod parity plan, sprint plans, No\u2011Legacy mandate, streaming/event-bus hardening, config/secrets hardening, Celery integration design.</li> </ul>"},{"location":"audits/roadmap-implementation-review/#gaps-vs-roadmap-most-impactful","title":"Gaps vs. Roadmap (Most Impactful)","text":"<p>1) Central Config Enforcement    - Many modules still call <code>os.getenv</code> directly for operational behavior (beyond bootstrap/settings modules). Examples: gateway helpers for uploads, AV, speech, rate-limiters, and various services.    - No lint/test gate yet for \u201cno direct getenv outside config/bootstrap\u201d.</p> <p>2) Async Lifecycle &amp; Test Mode    - Tests fail broadly without infra; many \u201cevent loop already running/closed\u201d errors indicate missing <code>pytest.mark.asyncio</code> or calling <code>asyncio.run()</code> under running loops in helpers/CLIs.    - Background tasks and network clients (Aiokafka/asyncpg) start during tests and don\u2019t always close cleanly, causing resource warnings and loop-close exceptions.</p> <p>3) External Dependency Gating    - Policy enforced paths return 403 in tests without a configured/mocked OPA/OpenFGA and Somabrain, breaking tool and ingest flows.    - Kafka/Postgres connectivity assumed in many code paths; need clean short-circuits in TESTING mode or dependency stubs/mocks.</p> <p>4) SSE/Event Bus Consolidation (UI)    - Roadmap specifies a single client stream and central event bus. Server emits chat/tool events, but parity for scheduler/memory invalidations and unified UI bus is still a roadmap item.</p> <p>5) Metrics Label Consistency    - Prometheus collector reuse errors (\u201cIncorrect label names\u201d) suggest tests import multiple times with different label cardinality or redefinition. Needs consistent factories + reuse across test sessions.</p> <p>6) Celery Integration    - Worker scaffolding present (<code>services/celery_worker/</code>), but unified scheduler API (<code>/v1/ui/scheduler/*</code>) and flag-driven switching are not fully wired. Current scheduler routes are a compatibility layer.</p>"},{"location":"audits/roadmap-implementation-review/#quick-evidence-map-files-roadmap-items","title":"Quick Evidence Map (Files \u2192 Roadmap Items)","text":"<ul> <li>Central config facade: <code>services/common/runtime_config.py</code> (C0 implemented). Registry: <code>services/common/config_registry.py</code>. Linter/test enforcement: missing.</li> <li>Somabrain integration: <code>python/integrations/somabrain_client.py</code>; gateway handlers in <code>services/gateway/main.py</code> (Phase 0 endpoints present).</li> <li>Notifications: <code>services/gateway/main.py</code> (API + TTL janitor); <code>services/common/notifications_store.py</code>.</li> <li>Scheduler: compatibility routes in gateway; no complete <code>/v1/ui/scheduler/*</code> yet.</li> <li>Observability: <code>observability/metrics.py</code>, gateway metrics server and rich counters/histograms.</li> <li>Dev\u2011prod parity: many elements present; env centralization and health\u2011gating incomplete in tests without infra.</li> </ul>"},{"location":"audits/roadmap-implementation-review/#recommended-next-steps-prioritized","title":"Recommended Next Steps (Prioritized)","text":"<p>P0 \u2014 Test Mode &amp; Event Loop Hygiene (foundation) - Add strict TESTING mode guards to skip background starters (Kafka producers, metrics server, periodic tasks). Ensure all test clients/CLIs avoid <code>asyncio.run()</code> within running loops; convert helpers to awaitables under <code>pytest.mark.asyncio</code>. - Provide minimal in-memory/no-op adapters for bus/publisher/policy in TESTING to avoid external connections.</p> <p>P1 \u2014 Config Centralization Enforcement - Migrate high-impact env reads in gateway/services to <code>cfg.settings()</code>/<code>cfg.flag()</code> where feasible. - Add linter rule and unit test (e.g., <code>tests/unit/test_no_direct_getenv.py</code>) to block stray <code>os.getenv(</code> outside <code>services/common/settings_*</code>, <code>runtime_config</code>, and specific bootstrap modules.</p> <p>P2 \u2014 Policy/Dependency Stubs for Tests - Introduce a test-mode policy client that deterministically allows/denies based on headers/markers to replace 403s in unit/integration tests. - Add in-memory outbox/publisher option in TESTING to avoid Kafka/DB where the test intent is not persistence.</p> <p>P3 \u2014 Scheduler API Canonicalization - Implement <code>/v1/ui/scheduler/*</code> with adapter interface (<code>APScheduler</code> first), add JWT scopes, and bridge the existing compatibility routes until UI is migrated.</p> <p>P4 \u2014 Metrics Consistency - Ensure all metric collectors are created via helper factories that reuse existing collectors on repeated imports (pattern already used in gateway; extend across modules used in tests).</p> <p>P5 \u2014 CI Parity Job &amp; Docs - Add a lightweight CI matrix job that runs with TESTING mode, dependency stubs, and skips infra-bound tests. Document local runbooks for full stack vs. TESTING.</p>"},{"location":"audits/roadmap-implementation-review/#risks-mitigations","title":"Risks &amp; Mitigations","text":"<ul> <li>Over-mocking can hide regressions: keep TESTING mode faithful to real code paths; use no-op transports with identical interfaces and record metrics to catch usage.</li> <li>Drift between facade and env: keep SA01Settings authoritative, and gradually route reads to it; publish \u201csettings snapshot\u201d at startup and in <code>/v1/health</code> for visibility.</li> </ul>"},{"location":"audits/roadmap-implementation-review/#verification-pointers","title":"Verification Pointers","text":"<ul> <li>After P0/P1: <code>pytest -q</code> should reduce failures from event loop errors and 403s to specific contract issues.</li> <li>Grep gate: repository-wide grep for <code>os.getenv(</code> outside allowed modules should return zero (or approved allowlist) once centralization completes.</li> <li>Gateway health: <code>/healthz</code> returns ok with Somabrain off only when strict-mode allows degrade; otherwise surfaces clear error with metrics.</li> </ul> <p>Report generated by reading docs under <code>docs/roadmap/*</code>, scanning key modules (<code>services/*</code>, <code>integrations/*</code>, <code>python/integrations/*</code>, <code>observability/*</code>), and running the test suite locally (without external infra).</p>"},{"location":"development-manual/","title":"Development Manual","text":"<p>Standards: ISO 29148, IEEE 1016, ISO 29119</p>"},{"location":"development-manual/#overview","title":"Overview","text":"<p>This manual covers development practices, coding standards, and testing procedures for SomaAgent01.</p>"},{"location":"development-manual/#development-environment","title":"Development Environment","text":""},{"location":"development-manual/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> <li>Docker 20.10+</li> <li>Make</li> <li>Git</li> </ul>"},{"location":"development-manual/#setup","title":"Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/somatechlat/somaagent01.git\ncd somaagent01\n\n# Create virtual environment\npython3.11 -m venv venv\nsource venv/bin/activate  # or `venv\\Scripts\\activate` on Windows\n\n# Install dependencies\npip install -r requirements.txt\n\n# Start infrastructure\nmake deps-up\n\n# Run services locally\nmake stack-up\n</code></pre>"},{"location":"development-manual/#project-structure","title":"Project Structure","text":"<pre><code>somaAgent01/\n\u251c\u2500\u2500 services/           # Microservices\n\u2502   \u251c\u2500\u2500 gateway/       # HTTP API with SSE streaming\n\u2502   \u251c\u2500\u2500 conversation_worker/  # Message processing\n\u2502   \u251c\u2500\u2500 tool_executor/ # Tool execution\n\u2502   \u251c\u2500\u2500 memory_replicator/    # Memory replication\n\u2502   \u251c\u2500\u2500 memory_sync/   # Memory retry logic\n\u2502   \u251c\u2500\u2500 outbox_sync/   # Kafka retry logic\n\u2502   \u2514\u2500\u2500 common/        # Shared libraries\n\u251c\u2500\u2500 webui/             # Web interface\n\u251c\u2500\u2500 python/            # Legacy Agent Zero code\n\u251c\u2500\u2500 infra/             # Infrastructure configs\n\u251c\u2500\u2500 scripts/           # Utility scripts\n\u251c\u2500\u2500 tests/             # Test suites\n\u2514\u2500\u2500 docs/              # Documentation\n</code></pre>"},{"location":"development-manual/#coding-standards","title":"Coding Standards","text":"<ul> <li>Style: PEP 8, enforced by <code>black</code> and <code>ruff</code></li> <li>Type Hints: Required for all public functions</li> <li>Docstrings: Google style for modules, classes, functions</li> <li>Imports: Alphabetical, grouped (stdlib, third-party, local)</li> <li>Error Handling: Explicit exception types, structured logging</li> </ul>"},{"location":"development-manual/#testing","title":"Testing","text":""},{"location":"development-manual/#unit-tests","title":"Unit Tests","text":"<pre><code>pytest tests/unit/\n</code></pre>"},{"location":"development-manual/#integration-tests","title":"Integration Tests","text":"<pre><code># Start test infrastructure\nmake deps-up\n\n# Run integration tests\npytest tests/integration/\n</code></pre>"},{"location":"development-manual/#load-tests","title":"Load Tests","text":"<pre><code># Smoke test (5 RPS, 15s)\nmake load-smoke\n\n# Soak test (configurable)\nRPS=10 DURATION=60 make load-soak\n</code></pre>"},{"location":"development-manual/#cicd","title":"CI/CD","text":"<p>GitHub Actions workflows:</p> <ul> <li><code>.github/workflows/test.yml</code>: Run tests on PR</li> <li><code>.github/workflows/build.yml</code>: Build Docker images</li> <li><code>.github/workflows/deploy.yml</code>: Deploy to staging/prod</li> </ul>"},{"location":"development-manual/#related-documents","title":"Related Documents","text":"<ul> <li>API Reference</li> <li>Coding Standards</li> <li>Testing Guidelines</li> <li>Contribution Workflow</li> <li>Contribution Workflow</li> </ul>"},{"location":"development-manual/api-reference/","title":"API Reference","text":"<p>Standards: ISO/IEC 29148\u00a75.4</p>"},{"location":"development-manual/api-reference/#base-url","title":"Base URL","text":"<pre><code>http://localhost:${GATEWAY_PORT:-21016}\n</code></pre>"},{"location":"development-manual/api-reference/#authentication","title":"Authentication","text":""},{"location":"development-manual/api-reference/#jwt-token","title":"JWT Token","text":"<pre><code>curl -H \"Authorization: Bearer &lt;jwt-token&gt;\" \\\n  http://localhost:${GATEWAY_PORT:-21016}/v1/session/message\n</code></pre>"},{"location":"development-manual/api-reference/#api-key","title":"API Key","text":"<pre><code>curl -H \"Authorization: Bearer sk-soma-&lt;key&gt;\" \\\n  http://localhost:${GATEWAY_PORT:-21016}/v1/session/message\n</code></pre>"},{"location":"development-manual/api-reference/#endpoints","title":"Endpoints","text":""},{"location":"development-manual/api-reference/#health-check","title":"Health Check","text":"<p>GET <code>/v1/health</code></p> <p>Check service health.</p> <p>Response: <pre><code>{\n  \"status\": \"healthy\",\n  \"version\": \"1.0.0\",\n  \"timestamp\": \"2025-01-24T12:00:00Z\"\n}\n</code></pre></p>"},{"location":"development-manual/api-reference/#start-a-session-first-message","title":"Start a Session (first message)","text":"<p>POST <code>/v1/session/message</code></p> <p>Send the first message with <code>session_id</code> omitted or null to create a session.</p> <p>Request: <pre><code>{\n  \"session_id\": null,\n  \"message\": \"Hello\"\n}\n</code></pre></p> <p>Response (truncated): <pre><code>{\n  \"session_id\": \"abc123\",\n  \"enqueued\": true\n}\n</code></pre></p>"},{"location":"development-manual/api-reference/#send-message","title":"Send Message","text":"<p>POST <code>/v1/session/message</code></p> <p>Send a message to the agent.</p> <p>Request: <pre><code>{\n  \"message\": \"What is the weather today?\",\n  \"attachments\": [\n    {\n      \"filename\": \"data.csv\",\n      \"content\": \"base64-encoded-content\",\n      \"mime_type\": \"text/csv\"\n    }\n  ]\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"message_id\": \"msg123\",\n  \"session_id\": \"abc123\",\n  \"response\": \"Let me check the weather for you...\",\n  \"metadata\": {\n    \"tokens_used\": 150,\n    \"duration_ms\": 1234\n  }\n}\n</code></pre></p>"},{"location":"development-manual/api-reference/#get-session-history","title":"Get Session History","text":"<p>GET <code>/v1/sessions/{session_id}/history</code></p> <p>Retrieve conversation history.</p> <p>Query Parameters: - <code>limit</code> (optional): Max messages to return (default: 50) - <code>offset</code> (optional): Pagination offset (default: 0)</p> <p>Response: <pre><code>{\n  \"session_id\": \"abc123\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello\",\n      \"timestamp\": \"2025-01-24T12:00:00Z\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Hi! How can I help?\",\n      \"timestamp\": \"2025-01-24T12:00:01Z\"\n    }\n  ],\n  \"total\": 2\n}\n</code></pre></p>"},{"location":"development-manual/api-reference/#delete-session","title":"Delete Session","text":"<p>DELETE <code>/v1/sessions/{session_id}</code></p> <p>Delete a session and all associated data.</p> <p>Response: <pre><code>{\n  \"status\": \"deleted\",\n  \"session_id\": \"abc123\"\n}\n</code></pre></p>"},{"location":"development-manual/api-reference/#upload-files","title":"Upload File(s)","text":"<p>POST <code>/v1/uploads</code></p> <p>Upload a file for use in conversations.</p> <p>Request (multipart/form-data): <pre><code>file: &lt;binary-data&gt;\nsession_id: abc123\n</code></pre></p> <p>Response: <pre><code>[\n  {\n    \"id\": \"att_123\",\n    \"filename\": \"document.pdf\",\n    \"size\": 102400,\n    \"content_type\": \"application/pdf\",\n    \"path\": \"/v1/attachments/att_123\"\n  }\n]\n</code></pre></p>"},{"location":"development-manual/api-reference/#download-attachment","title":"Download Attachment","text":"<p>GET <code>/v1/attachments/{attachment_id}</code></p> <p>Download a previously uploaded file.</p> <p>Response: Binary file content</p>"},{"location":"development-manual/api-reference/#list-sessions","title":"List Sessions","text":"<p>GET <code>/v1/sessions</code></p> <p>List all sessions for the authenticated user.</p> <p>Query Parameters: - <code>tenant</code> (optional): Filter by tenant - <code>limit</code> (optional): Max sessions (default: 50) - <code>offset</code> (optional): Pagination offset</p> <p>Response: <pre><code>{\n  \"sessions\": [\n    {\n      \"session_id\": \"abc123\",\n      \"tenant\": \"acme\",\n      \"persona_id\": \"default\",\n      \"created_at\": \"2025-01-24T12:00:00Z\",\n      \"updated_at\": \"2025-01-24T12:30:00Z\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre></p>"},{"location":"development-manual/api-reference/#memory-read-apis-for-ui","title":"Memory (Read APIs for UI)","text":"<p>Read-only endpoints used by the UI memory dashboard:</p> <ul> <li>GET <code>/v1/memories</code> \u2014 list/search</li> <li>GET <code>/v1/memories/subdirs</code> \u2014 available subdirectories</li> <li>GET <code>/v1/memories/current-subdir</code> \u2014 current browsing context</li> <li>DELETE <code>/v1/memories/{id}</code> \u2014 delete memory (policy-gated)</li> <li>PATCH <code>/v1/memories/{id}</code> \u2014 update memory metadata/content (policy-gated)</li> <li>POST <code>/v1/memories/bulk-delete</code> \u2014 delete multiple memories (policy-gated)</li> </ul>"},{"location":"development-manual/api-reference/#ui-settings","title":"UI Settings","text":"<p>Settings and credentials are managed via the Gateway UI Settings APIs.</p> <p>GET <code>/v1/ui/settings</code></p> <p>Returns the effective agent configuration and model profile.</p> <p>PUT <code>/v1/ui/settings</code></p> <p>Accepts <code>model_profile</code>, <code>agent</code>, and related sections from the UI.</p> <p>Related endpoints:</p> <ul> <li>GET <code>/v1/ui/settings/sections</code> \u2014 load the full Settings modal schema</li> <li>POST <code>/v1/ui/settings/sections</code> \u2014 single writer: persist agent/model settings and any <code>api_key_*</code> secrets (encrypted)</li> <li>GET <code>/v1/ui/settings/credentials</code> \u2014 status map of stored provider secrets (<code>present</code> + <code>updated_at</code>)</li> <li>POST <code>/v1/llm/test</code> \u2014 validate active model profile and provider reachability</li> </ul>"},{"location":"development-manual/api-reference/#streaming-sse","title":"Streaming (SSE)","text":"<p>The UI uses Server-Sent Events for streaming responses.</p>"},{"location":"development-manual/api-reference/#subscribe","title":"Subscribe","text":"<pre><code>const es = new EventSource(`http://localhost:${GATEWAY_PORT || 21016}/v1/session/${sessionId}/events`);\nes.onmessage = (evt) =&gt; {\n  const payload = JSON.parse(evt.data);\n  // Handle assistant/tool/util events\n};\nes.onerror = () =&gt; {\n  // Handle reconnect/backoff\n};\n</code></pre>"},{"location":"development-manual/api-reference/#export-jobs","title":"Export Jobs","text":"<p>Asynchronous export of memory replica rows to NDJSON. Disabled by default.</p> <p>Enable with:</p> <pre><code>DISABLE_FILE_SAVING=false\nEXPORT_JOBS_ENABLED=true\n</code></pre> <p>Endpoints (admin scope):</p> <ul> <li>POST <code>/v1/memory/export/jobs</code> \u2014 create a job</li> <li>GET <code>/v1/memory/export/jobs/{job_id}</code> \u2014 get status</li> <li>GET <code>/v1/memory/export/jobs/{job_id}/download</code> \u2014 download NDJSON</li> </ul> <p>Example:</p> <pre><code>JOB_ID=$(curl -s -X POST http://localhost:${GATEWAY_PORT:-21016}/v1/memory/export/jobs \\\n  -H 'Content-Type: application/json' \\\n  -H 'Authorization: Bearer &lt;admin-jwt&gt;' \\\n  -d '{\"tenant\":\"acme\",\"q\":\"timeout\",\"limit_total\":2000}' | jq -r '.job_id')\n\ncurl -s http://localhost:${GATEWAY_PORT:-21016}/v1/memory/export/jobs/$JOB_ID \\\n  -H 'Authorization: Bearer &lt;admin-jwt&gt;' | jq .\n\ncurl -L http://localhost:${GATEWAY_PORT:-21016}/v1/memory/export/jobs/$JOB_ID/download \\\n  -H 'Authorization: Bearer &lt;admin-jwt&gt;' -o export.ndjson\n</code></pre>"},{"location":"development-manual/api-reference/#error-responses","title":"Error Responses","text":""},{"location":"development-manual/api-reference/#400-bad-request","title":"400 Bad Request","text":"<pre><code>{\n  \"error\": \"validation_error\",\n  \"message\": \"Invalid session_id format\",\n  \"details\": {\n    \"field\": \"session_id\",\n    \"constraint\": \"alphanumeric\"\n  }\n}\n</code></pre>"},{"location":"development-manual/api-reference/#401-unauthorized","title":"401 Unauthorized","text":"<pre><code>{\n  \"error\": \"unauthorized\",\n  \"message\": \"Invalid or expired token\"\n}\n</code></pre>"},{"location":"development-manual/api-reference/#403-forbidden","title":"403 Forbidden","text":"<pre><code>{\n  \"error\": \"forbidden\",\n  \"message\": \"Insufficient permissions for this operation\"\n}\n</code></pre>"},{"location":"development-manual/api-reference/#404-not-found","title":"404 Not Found","text":"<pre><code>{\n  \"error\": \"not_found\",\n  \"message\": \"Session not found\",\n  \"resource\": \"session\",\n  \"id\": \"abc123\"\n}\n</code></pre>"},{"location":"development-manual/api-reference/#429-too-many-requests","title":"429 Too Many Requests","text":"<pre><code>{\n  \"error\": \"rate_limit_exceeded\",\n  \"message\": \"Too many requests\",\n  \"retry_after\": 60\n}\n</code></pre>"},{"location":"development-manual/api-reference/#500-internal-server-error","title":"500 Internal Server Error","text":"<pre><code>{\n  \"error\": \"internal_error\",\n  \"message\": \"An unexpected error occurred\",\n  \"request_id\": \"req123\"\n}\n</code></pre>"},{"location":"development-manual/api-reference/#rate-limits","title":"Rate Limits","text":"Endpoint Limit Window <code>/v1/session/message</code> 60 requests 1 minute <code>/v1/memory/search</code> 100 requests 1 minute <code>/v1/uploads</code> 10 requests 1 minute All others 300 requests 1 minute <p>Headers: <pre><code>X-RateLimit-Limit: 60\nX-RateLimit-Remaining: 45\nX-RateLimit-Reset: 1706140800\n</code></pre></p>"},{"location":"development-manual/api-reference/#pagination","title":"Pagination","text":"<p>Request: <pre><code>GET /v1/sessions?limit=20&amp;offset=40\n</code></pre></p> <p>Response: <pre><code>{\n  \"sessions\": [...],\n  \"total\": 150,\n  \"limit\": 20,\n  \"offset\": 40,\n  \"next\": \"/v1/sessions?limit=20&amp;offset=60\",\n  \"previous\": \"/v1/sessions?limit=20&amp;offset=20\"\n}\n</code></pre></p>"},{"location":"development-manual/api-reference/#versioning","title":"Versioning","text":"<p>API version is in the URL path: <code>/v1/</code></p> <p>Deprecation: 6 months notice before removal</p> <p>Headers: <pre><code>X-API-Version: 1.0.0\nX-API-Deprecated: false\n</code></pre></p>"},{"location":"development-manual/api-reference/#openapi-spec","title":"OpenAPI Spec","text":"<p>Full OpenAPI 3.0 specification:</p> <pre><code>curl http://localhost:${GATEWAY_PORT:-21016}/openapi.json\n</code></pre> <p>Or view interactive docs:</p> <pre><code>http://localhost:${GATEWAY_PORT:-21016}/docs\n</code></pre>"},{"location":"development-manual/api-reference/#sdks","title":"SDKs","text":""},{"location":"development-manual/api-reference/#python","title":"Python","text":"<pre><code>from somaagent import Client\n\nclient = Client(api_key=\"sk-soma-...\")\n\n# Create session\nsession = client.sessions.create(tenant=\"acme\")\n\n# Send message\nresponse = client.messages.send(\n    session_id=session.id,\n    message=\"Hello!\"\n)\n\nprint(response.content)\n</code></pre>"},{"location":"development-manual/api-reference/#javascript","title":"JavaScript","text":"<pre><code>import { SomaClient } from '@somaagent/sdk';\n\nconst client = new SomaClient({ apiKey: 'sk-soma-...' });\n\n// Create session\nconst session = await client.sessions.create({ tenant: 'acme' });\n\n// Send message\nconst response = await client.messages.send({\n  sessionId: session.id,\n  message: 'Hello!'\n});\n\nconsole.log(response.content);\n</code></pre>"},{"location":"development-manual/api-reference/#examples","title":"Examples","text":""},{"location":"development-manual/api-reference/#complete-conversation-flow","title":"Complete Conversation Flow","text":"<pre><code># 1. Create session\nSESSION_ID=$(curl -X POST http://localhost:${GATEWAY_PORT:-21016}/v1/session/message \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"message\":\"Hello\"}' \\\n  | jq -r '.session_id')\n\n# 2. Send message\ncurl -X POST http://localhost:${GATEWAY_PORT:-21016}/v1/session/message \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"session_id\\\":\\\"$SESSION_ID\\\",\\\"message\\\":\\\"What is 2+2?\\\"}\" \\\n  | jq '.response'\n\n# 3. Get history\ncurl http://localhost:${GATEWAY_PORT:-21016}/v1/sessions/$SESSION_ID/history \\\n  | jq '.messages'\n\n# 4. Delete session\ncurl -X DELETE http://localhost:${GATEWAY_PORT:-21016}/v1/sessions/$SESSION_ID\n</code></pre>"},{"location":"development-manual/api-reference/#file-upload-and-query","title":"File Upload and Query","text":"<pre><code># 1. Upload file\nATT_ID=$(curl -X POST http://localhost:${GATEWAY_PORT:-21016}/v1/uploads \\\n  -F \"file=@document.pdf\" \\\n  -F \"session_id=$SESSION_ID\" \\\n  | jq -r '.[0].id')\n\n# 2. Query document\ncurl -X POST http://localhost:${GATEWAY_PORT:-21016}/v1/session/message \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"session_id\\\":\\\"$SESSION_ID\\\",\\\"message\\\":\\\"Summarize the document\\\",\\\"attachments\\\":[\\\"$ATT_ID\\\"]}\"\n</code></pre>"},{"location":"development-manual/coding-standards/","title":"Coding Standards","text":"<p>Standards: ISO/IEC 12207\u00a78.3</p>"},{"location":"development-manual/coding-standards/#python-style-guide","title":"Python Style Guide","text":""},{"location":"development-manual/coding-standards/#pep-8-compliance","title":"PEP 8 Compliance","text":"<p>All Python code must follow PEP 8.</p> <p>Enforced by: - <code>black</code> (formatter) - <code>ruff</code> (linter) - <code>mypy</code> (type checker)</p>"},{"location":"development-manual/coding-standards/#formatting","title":"Formatting","text":"<pre><code># Format code\nblack .\n\n# Check formatting\nblack --check .\n\n# Lint\nruff check .\n\n# Type check\nmypy services/\n</code></pre>"},{"location":"development-manual/coding-standards/#naming-conventions","title":"Naming Conventions","text":"Type Convention Example Module <code>snake_case</code> <code>conversation_worker.py</code> Class <code>PascalCase</code> <code>ConversationWorker</code> Function <code>snake_case</code> <code>process_message()</code> Variable <code>snake_case</code> <code>session_id</code> Constant <code>UPPER_SNAKE_CASE</code> <code>MAX_RETRIES</code> Private <code>_leading_underscore</code> <code>_internal_method()</code>"},{"location":"development-manual/coding-standards/#type-hints","title":"Type Hints","text":"<p>Required for all public functions:</p> <pre><code>def process_message(\n    session_id: str,\n    message: str,\n    timeout: float = 30.0\n) -&gt; dict[str, Any]:\n    \"\"\"Process a user message.\n\n    Args:\n        session_id: Unique session identifier\n        message: User message text\n        timeout: Processing timeout in seconds\n\n    Returns:\n        Response dictionary with 'content' and 'metadata'\n\n    Raises:\n        TimeoutError: If processing exceeds timeout\n        ValueError: If message is empty\n    \"\"\"\n    pass\n</code></pre>"},{"location":"development-manual/coding-standards/#docstrings","title":"Docstrings","text":"<p>Google style for all modules, classes, and public functions:</p> <pre><code>\"\"\"Module for conversation processing.\n\nThis module handles user messages, LLM calls, and response generation.\nIt consumes from conversation.inbound and publishes to conversation.outbound.\n\nExample:\n    worker = ConversationWorker()\n    await worker.start()\n\"\"\"\n</code></pre>"},{"location":"development-manual/coding-standards/#imports","title":"Imports","text":"<p>Order: 1. Standard library 2. Third-party 3. Local</p> <p>Alphabetical within each group:</p> <pre><code># Standard library\nimport asyncio\nimport logging\nfrom typing import Any\n\n# Third-party\nimport httpx\nfrom aiokafka import AIOKafkaConsumer\n\n# Local\nfrom services.common.event_bus import EventBus\nfrom services.common.logging_config import setup_logging\n</code></pre>"},{"location":"development-manual/coding-standards/#error-handling","title":"Error Handling","text":"<p>Explicit exception types:</p> <pre><code># \u274c Bad\ntry:\n    result = await call_llm()\nexcept:\n    pass\n\n# \u2705 Good\ntry:\n    result = await call_llm()\nexcept httpx.TimeoutException as e:\n    logger.error(f\"LLM call timed out: {e}\")\n    raise\nexcept httpx.HTTPStatusError as e:\n    logger.error(f\"LLM API error: {e.response.status_code}\")\n    raise\n</code></pre>"},{"location":"development-manual/coding-standards/#logging","title":"Logging","text":"<p>Structured logging with context:</p> <pre><code>import structlog\n\nlogger = structlog.get_logger(__name__)\n\n# \u2705 Good\nlogger.info(\n    \"message_processed\",\n    session_id=session_id,\n    message_length=len(message),\n    duration_ms=duration * 1000\n)\n\n# \u274c Bad\nlogger.info(f\"Processed message for {session_id}\")\n</code></pre>"},{"location":"development-manual/coding-standards/#asyncawait","title":"Async/Await","text":"<p>Prefer async for I/O operations:</p> <pre><code># \u2705 Good\nasync def fetch_session(session_id: str) -&gt; Session:\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"/sessions/{session_id}\")\n        return Session(**response.json())\n\n# \u274c Bad (blocking)\ndef fetch_session(session_id: str) -&gt; Session:\n    response = requests.get(f\"/sessions/{session_id}\")\n    return Session(**response.json())\n</code></pre>"},{"location":"development-manual/coding-standards/#code-organization","title":"Code Organization","text":""},{"location":"development-manual/coding-standards/#file-structure","title":"File Structure","text":"<pre><code>services/\n\u251c\u2500\u2500 gateway/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 main.py           # Entry point\n\u2502   \u251c\u2500\u2500 dependencies.py   # FastAPI dependencies\n\u2502   \u2514\u2500\u2500 routes/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 health.py\n\u2502       \u2514\u2500\u2500 session.py\n\u251c\u2500\u2500 conversation_worker/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u2514\u2500\u2500 policy_integration.py\n\u2514\u2500\u2500 common/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 event_bus.py\n    \u251c\u2500\u2500 logging_config.py\n    \u2514\u2500\u2500 settings_base.py\n</code></pre>"},{"location":"development-manual/coding-standards/#module-size","title":"Module Size","text":"<ul> <li>Max 500 lines per file</li> <li>Max 50 lines per function</li> <li>Max 10 parameters per function</li> </ul> <p>If exceeded, refactor into smaller modules.</p>"},{"location":"development-manual/coding-standards/#testing-standards","title":"Testing Standards","text":""},{"location":"development-manual/coding-standards/#test-structure","title":"Test Structure","text":"<pre><code>import pytest\n\nclass TestConversationWorker:\n    \"\"\"Tests for ConversationWorker.\"\"\"\n\n    @pytest.fixture\n    async def worker(self):\n        \"\"\"Create worker instance.\"\"\"\n        return ConversationWorker()\n\n    async def test_process_message_success(self, worker):\n        \"\"\"Test successful message processing.\"\"\"\n        # Arrange\n        message = \"Hello\"\n\n        # Act\n        result = await worker.process_message(message)\n\n        # Assert\n        assert result[\"status\"] == \"success\"\n        assert \"content\" in result\n</code></pre>"},{"location":"development-manual/coding-standards/#test-coverage","title":"Test Coverage","text":"<ul> <li>Minimum 80% line coverage</li> <li>100% for critical paths (auth, payment, data loss)</li> </ul> <pre><code># Run with coverage\npytest --cov=services --cov-report=html\n\n# View report\nopen htmlcov/index.html\n</code></pre>"},{"location":"development-manual/coding-standards/#test-naming","title":"Test Naming","text":"<pre><code># Pattern: test_&lt;function&gt;_&lt;scenario&gt;_&lt;expected&gt;\n\ndef test_process_message_empty_input_raises_value_error():\n    pass\n\ndef test_fetch_session_not_found_returns_none():\n    pass\n\ndef test_publish_event_kafka_down_uses_outbox():\n    pass\n</code></pre>"},{"location":"development-manual/coding-standards/#security-standards","title":"Security Standards","text":""},{"location":"development-manual/coding-standards/#input-validation","title":"Input Validation","text":"<pre><code>from pydantic import BaseModel, Field, validator\n\nclass MessageRequest(BaseModel):\n    session_id: str = Field(..., min_length=1, max_length=100)\n    message: str = Field(..., min_length=1, max_length=10000)\n\n    @validator(\"session_id\")\n    def validate_session_id(cls, v):\n        if not v.isalnum():\n            raise ValueError(\"session_id must be alphanumeric\")\n        return v\n</code></pre>"},{"location":"development-manual/coding-standards/#secrets-handling","title":"Secrets Handling","text":"<pre><code># \u274c Bad\nlogger.info(f\"Using API key: {api_key}\")\n\n# \u2705 Good\nlogger.info(\"Using API key\", key_prefix=api_key[:8])\n\n# \u274c Bad\nprint(f\"Password: {password}\")\n\n# \u2705 Good (never log passwords)\nlogger.info(\"Authentication successful\")\n</code></pre>"},{"location":"development-manual/coding-standards/#sql-injection-prevention","title":"SQL Injection Prevention","text":"<pre><code># \u2705 Good (parameterized)\nawait conn.execute(\n    \"SELECT * FROM sessions WHERE id = $1\",\n    session_id\n)\n\n# \u274c Bad (vulnerable)\nawait conn.execute(\n    f\"SELECT * FROM sessions WHERE id = '{session_id}'\"\n)\n</code></pre>"},{"location":"development-manual/coding-standards/#performance-standards","title":"Performance Standards","text":""},{"location":"development-manual/coding-standards/#database-queries","title":"Database Queries","text":"<pre><code># \u2705 Good (batch)\nawait conn.executemany(\n    \"INSERT INTO events (session_id, data) VALUES ($1, $2)\",\n    [(s, d) for s, d in events]\n)\n\n# \u274c Bad (N+1)\nfor session_id, data in events:\n    await conn.execute(\n        \"INSERT INTO events (session_id, data) VALUES ($1, $2)\",\n        session_id, data\n    )\n</code></pre>"},{"location":"development-manual/coding-standards/#caching","title":"Caching","text":"<pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=1000)\ndef get_model_config(model_name: str) -&gt; dict:\n    \"\"\"Get model configuration (cached).\"\"\"\n    return load_config(model_name)\n</code></pre>"},{"location":"development-manual/coding-standards/#connection-pooling","title":"Connection Pooling","text":"<pre><code># \u2705 Good (reuse pool)\npool = await asyncpg.create_pool(dsn, min_size=5, max_size=20)\n\nasync with pool.acquire() as conn:\n    result = await conn.fetch(\"SELECT * FROM sessions\")\n\n# \u274c Bad (new connection each time)\nconn = await asyncpg.connect(dsn)\nresult = await conn.fetch(\"SELECT * FROM sessions\")\nawait conn.close()\n</code></pre>"},{"location":"development-manual/coding-standards/#git-commit-standards","title":"Git Commit Standards","text":""},{"location":"development-manual/coding-standards/#commit-message-format","title":"Commit Message Format","text":"<pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation - <code>style</code>: Formatting - <code>refactor</code>: Code restructuring - <code>test</code>: Tests - <code>chore</code>: Maintenance</p> <p>Example: <pre><code>feat(gateway): add JWT authentication\n\n- Implement JWT token validation\n- Add /v1/auth/login endpoint\n- Update dependencies with PyJWT\n\nCloses #123\n</code></pre></p>"},{"location":"development-manual/coding-standards/#code-review-checklist","title":"Code Review Checklist","text":"<ul> <li>[ ] Follows PEP 8 and naming conventions</li> <li>[ ] Type hints on all public functions</li> <li>[ ] Docstrings on modules, classes, functions</li> <li>[ ] Tests added/updated (80%+ coverage)</li> <li>[ ] No hardcoded secrets or credentials</li> <li>[ ] Error handling with specific exceptions</li> <li>[ ] Structured logging with context</li> <li>[ ] Async/await for I/O operations</li> <li>[ ] Input validation with Pydantic</li> <li>[ ] SQL queries parameterized</li> <li>[ ] Commit message follows format</li> </ul>"},{"location":"development-manual/contribution-workflow/","title":"Contribution Workflow","text":"<p>Standards: ISO/IEC 12207\u00a76.6</p>"},{"location":"development-manual/contribution-workflow/#getting-started","title":"Getting Started","text":""},{"location":"development-manual/contribution-workflow/#1-fork-repository","title":"1. Fork Repository","text":"<pre><code># Fork on GitHub, then clone\ngit clone https://github.com/YOUR_USERNAME/somaagent01.git\ncd somaagent01\n\n# Add upstream remote\ngit remote add upstream https://github.com/somatechlat/somaagent01.git\n</code></pre>"},{"location":"development-manual/contribution-workflow/#2-create-branch","title":"2. Create Branch","text":"<pre><code># Update main\ngit checkout main\ngit pull upstream main\n\n# Create feature branch\ngit checkout -b feature/your-feature-name\n\n# Or bugfix branch\ngit checkout -b fix/issue-123-description\n</code></pre>"},{"location":"development-manual/contribution-workflow/#branch-naming","title":"Branch Naming","text":"Type Pattern Example Feature <code>feature/&lt;description&gt;</code> <code>feature/add-jwt-auth</code> Bugfix <code>fix/&lt;issue&gt;-&lt;description&gt;</code> <code>fix/123-memory-leak</code> Hotfix <code>hotfix/&lt;description&gt;</code> <code>hotfix/security-patch</code> Docs <code>docs/&lt;description&gt;</code> <code>docs/update-api-reference</code> Refactor <code>refactor/&lt;description&gt;</code> <code>refactor/simplify-event-bus</code>"},{"location":"development-manual/contribution-workflow/#development-workflow","title":"Development Workflow","text":""},{"location":"development-manual/contribution-workflow/#1-make-changes","title":"1. Make Changes","text":"<pre><code># Edit files\nnano services/gateway/main.py\n\n# Run locally\nmake stack-up\n\n# Test changes\npytest tests/unit/test_gateway.py\n</code></pre>"},{"location":"development-manual/contribution-workflow/#2-write-tests","title":"2. Write Tests","text":"<pre><code># tests/unit/test_your_feature.py\nimport pytest\n\ndef test_your_feature():\n    \"\"\"Test your new feature.\"\"\"\n    result = your_function()\n    assert result == expected\n</code></pre>"},{"location":"development-manual/contribution-workflow/#3-run-quality-checks","title":"3. Run Quality Checks","text":"<pre><code># Format code\nblack .\n\n# Lint\nruff check .\n\n# Type check\nmypy services/\n\n# Run tests\npytest tests/unit/ --cov=services\n\n# Check coverage\npytest --cov=services --cov-fail-under=80\n</code></pre>"},{"location":"development-manual/contribution-workflow/#4-commit-changes","title":"4. Commit Changes","text":"<pre><code># Stage changes\ngit add services/gateway/main.py tests/unit/test_gateway.py\n\n# Commit with conventional message\ngit commit -m \"feat(gateway): add JWT authentication\n\n- Implement JWT token validation\n- Add /v1/auth/login endpoint\n- Update dependencies with PyJWT\n\nCloses #123\"\n</code></pre>"},{"location":"development-manual/contribution-workflow/#commit-message-format","title":"Commit Message Format","text":"<pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation only - <code>style</code>: Formatting, no code change - <code>refactor</code>: Code restructuring - <code>test</code>: Adding tests - <code>chore</code>: Maintenance tasks</p> <p>Example: <pre><code>fix(worker): handle LLM timeout gracefully\n\n- Add timeout handling in call_llm()\n- Retry with exponential backoff\n- Log timeout events for monitoring\n\nFixes #456\n</code></pre></p>"},{"location":"development-manual/contribution-workflow/#5-push-branch","title":"5. Push Branch","text":"<pre><code># Push to your fork\ngit push origin feature/your-feature-name\n</code></pre>"},{"location":"development-manual/contribution-workflow/#pull-request-process","title":"Pull Request Process","text":""},{"location":"development-manual/contribution-workflow/#1-create-pr","title":"1. Create PR","text":"<ol> <li>Go to GitHub</li> <li>Click \"New Pull Request\"</li> <li>Select your branch</li> <li>Fill out PR template</li> </ol>"},{"location":"development-manual/contribution-workflow/#pr-template","title":"PR Template","text":"<pre><code>## Description\nBrief description of changes.\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Testing\n- [ ] Unit tests added/updated\n- [ ] Integration tests added/updated\n- [ ] Manual testing completed\n\n## Checklist\n- [ ] Code follows style guide\n- [ ] Tests pass locally\n- [ ] Documentation updated\n- [ ] No breaking changes (or documented)\n- [ ] Commit messages follow convention\n\n## Related Issues\nCloses #123\n</code></pre>"},{"location":"development-manual/contribution-workflow/#2-code-review","title":"2. Code Review","text":"<p>Reviewers check: - Code quality and style - Test coverage (\u226580%) - Documentation updates - Breaking changes - Security implications</p> <p>Review process: 1. Automated checks (CI) 2. Peer review (2 approvals required) 3. Maintainer review 4. Approval and merge</p>"},{"location":"development-manual/contribution-workflow/#3-address-feedback","title":"3. Address Feedback","text":"<pre><code># Make requested changes\nnano services/gateway/main.py\n\n# Commit changes\ngit add .\ngit commit -m \"refactor: address review feedback\"\n\n# Push updates\ngit push origin feature/your-feature-name\n</code></pre>"},{"location":"development-manual/contribution-workflow/#4-merge","title":"4. Merge","text":"<p>Merge strategies: - Squash and merge: Default for features - Rebase and merge: For clean history - Merge commit: For large features</p> <p>After merge: <pre><code># Update local main\ngit checkout main\ngit pull upstream main\n\n# Delete feature branch\ngit branch -d feature/your-feature-name\ngit push origin --delete feature/your-feature-name\n</code></pre></p>"},{"location":"development-manual/contribution-workflow/#cicd-pipeline","title":"CI/CD Pipeline","text":""},{"location":"development-manual/contribution-workflow/#automated-checks","title":"Automated Checks","text":"<p>On PR: 1. Linting (black, ruff) 2. Type checking (mypy) 3. Unit tests 4. Integration tests 5. Coverage check (\u226580%) 6. Security scan (trivy)</p> <p>On merge to main: 1. All PR checks 2. E2E tests 3. Build Docker images 4. Push to registry 5. Deploy to staging</p>"},{"location":"development-manual/contribution-workflow/#status-checks","title":"Status Checks","text":"Check Required Blocks Merge Lint \u2705 Yes Type Check \u2705 Yes Unit Tests \u2705 Yes Coverage \u226580% \u2705 Yes Integration Tests \u2705 Yes Security Scan \u2705 Yes E2E Tests \u26a0\ufe0f No (warning only)"},{"location":"development-manual/contribution-workflow/#release-process","title":"Release Process","text":""},{"location":"development-manual/contribution-workflow/#version-numbering","title":"Version Numbering","text":"<p>Semantic Versioning: <code>MAJOR.MINOR.PATCH</code></p> <ul> <li>MAJOR: Breaking changes</li> <li>MINOR: New features (backward compatible)</li> <li>PATCH: Bug fixes</li> </ul>"},{"location":"development-manual/contribution-workflow/#creating-a-release","title":"Creating a Release","text":"<pre><code># 1. Update version\necho \"1.2.0\" &gt; VERSION\n\n# 2. Update changelog\nnano docs/changelog.md\n\n# 3. Commit\ngit add VERSION docs/changelog.md\ngit commit -m \"chore: bump version to 1.2.0\"\n\n# 4. Tag\ngit tag -a v1.2.0 -m \"Release v1.2.0\"\n\n# 5. Push\ngit push upstream main --tags\n</code></pre>"},{"location":"development-manual/contribution-workflow/#release-notes","title":"Release Notes","text":"<pre><code>## [1.2.0] - 2025-01-24\n\n### Added\n- JWT authentication support\n- Memory search API endpoint\n- Prometheus metrics for circuit breaker\n\n### Changed\n- Improved error handling in conversation worker\n- Updated dependencies (LiteLLM 1.50.0)\n\n### Fixed\n- Memory replication lag issue (#456)\n- Streaming connection timeout (#478)\n\n### Security\n- Patched SQL injection vulnerability (CVE-2025-1234)\n</code></pre>"},{"location":"development-manual/contribution-workflow/#best-practices","title":"Best Practices","text":""},{"location":"development-manual/contribution-workflow/#do","title":"DO","text":"<ul> <li>\u2705 Write tests for all new code</li> <li>\u2705 Update documentation</li> <li>\u2705 Follow coding standards</li> <li>\u2705 Keep PRs small and focused</li> <li>\u2705 Respond to review feedback promptly</li> <li>\u2705 Rebase on main before merging</li> <li>\u2705 Write descriptive commit messages</li> <li>\u2705 Add type hints</li> </ul>"},{"location":"development-manual/contribution-workflow/#dont","title":"DON'T","text":"<ul> <li>\u274c Commit directly to main</li> <li>\u274c Push without running tests</li> <li>\u274c Include unrelated changes</li> <li>\u274c Ignore linter warnings</li> <li>\u274c Skip documentation updates</li> <li>\u274c Merge without approval</li> <li>\u274c Leave commented-out code</li> <li>\u274c Hardcode secrets</li> </ul>"},{"location":"development-manual/contribution-workflow/#getting-help","title":"Getting Help","text":""},{"location":"development-manual/contribution-workflow/#resources","title":"Resources","text":"<ul> <li>Documentation: <code>/docs</code></li> <li>GitHub Issues: https://github.com/somatechlat/somaagent01/issues</li> <li>Discord: https://discord.gg/B8KZKNsPpj</li> <li>Email: dev@somaagent01.ai</li> </ul>"},{"location":"development-manual/contribution-workflow/#issue-templates","title":"Issue Templates","text":"<p>Bug Report: <pre><code>**Describe the bug**\nClear description of the issue.\n\n**To Reproduce**\nSteps to reproduce:\n1. Go to '...'\n2. Click on '...'\n3. See error\n\n**Expected behavior**\nWhat should happen.\n\n**Actual behavior**\nWhat actually happens.\n\n**Environment**\n- OS: macOS 14.0\n- Python: 3.11.5\n- Docker: 24.0.6\n\n**Logs**\n</code></pre> Paste relevant logs here <pre><code>\n</code></pre></p> <p>Feature Request: <pre><code>**Is your feature request related to a problem?**\nDescription of the problem.\n\n**Describe the solution you'd like**\nClear description of desired functionality.\n\n**Describe alternatives you've considered**\nOther approaches you've thought about.\n\n**Additional context**\nAny other relevant information.\n</code></pre></p>"},{"location":"development-manual/contribution-workflow/#code-of-conduct","title":"Code of Conduct","text":""},{"location":"development-manual/contribution-workflow/#our-pledge","title":"Our Pledge","text":"<p>We pledge to make participation in our project a harassment-free experience for everyone.</p>"},{"location":"development-manual/contribution-workflow/#our-standards","title":"Our Standards","text":"<p>Positive behavior: - Using welcoming language - Being respectful of differing viewpoints - Gracefully accepting constructive criticism - Focusing on what is best for the community</p> <p>Unacceptable behavior: - Trolling, insulting comments, personal attacks - Public or private harassment - Publishing others' private information - Other conduct which could reasonably be considered inappropriate</p>"},{"location":"development-manual/contribution-workflow/#enforcement","title":"Enforcement","text":"<p>Violations may result in: 1. Warning 2. Temporary ban 3. Permanent ban</p> <p>Report violations to: conduct@somaagent01.ai</p>"},{"location":"development-manual/contribution-workflow/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"development-manual/extensibility/","title":"Extensibility","text":"<p>This is a placeholder page for Extensibility docs. The full content will cover how to add tools, services, and UI modules.</p> <ul> <li>Adding new tools: python/tools/</li> <li>Registering services: services// <li>UI components: webui/components/</li> <p>See also: - Development Manual index: ./index.md - API Reference: ./api-reference.md</p>"},{"location":"development-manual/local-setup/","title":"Local Development Setup","text":"<p>Standards: ISO/IEC 29148\u00a75.2</p>"},{"location":"development-manual/local-setup/#one-page-setup-guide","title":"One-Page Setup Guide","text":""},{"location":"development-manual/local-setup/#prerequisites-check","title":"Prerequisites Check","text":"<pre><code># Python 3.11+\npython3.11 --version\n\n# Docker 20.10+\ndocker --version\n\n# Make\nmake --version\n\n# Git\ngit --version\n</code></pre>"},{"location":"development-manual/local-setup/#quick-setup-5-minutes","title":"Quick Setup (5 minutes)","text":"<pre><code># 1. Clone\ngit clone https://github.com/somatechlat/somaagent01.git\ncd somaagent01\n\n# 2. Virtual environment\npython3.11 -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\n\n# 3. Install dependencies\npip install -r requirements.txt\n\n# 4. Configure\ncp .env.example .env\nnano .env  # Add your OPENROUTER_API_KEY\n\n# 5. Start infrastructure\nmake deps-up\n\n# 6. Start services\nmake stack-up\n\n# 7. Start UI (new terminal)\nmake ui\n</code></pre>"},{"location":"development-manual/local-setup/#verification","title":"Verification","text":"<pre><code># Health check (Gateway)\ncurl -fsS http://127.0.0.1:21016/v1/health -D - -o /dev/null\n\n# Open UI\nopen http://127.0.0.1:3000\n</code></pre>"},{"location":"development-manual/local-setup/#detailed-setup","title":"Detailed Setup","text":""},{"location":"development-manual/local-setup/#1-python-environment","title":"1. Python Environment","text":"<pre><code># Create virtual environment\npython3.11 -m venv venv\n\n# Activate\nsource venv/bin/activate  # macOS/Linux\nvenv\\Scripts\\activate     # Windows\n\n# Upgrade pip\npip install --upgrade pip\n\n# Install dependencies\npip install -r requirements.txt\n\n# Install dev dependencies\npip install -r requirements-dev.txt  # if exists\n</code></pre>"},{"location":"development-manual/local-setup/#2-environment-configuration","title":"2. Environment Configuration","text":"<pre><code># Copy example\ncp .env.example .env\n\n# Edit configuration\nnano .env\n</code></pre> <p>Required variables: <pre><code># LLM Provider\nOPENROUTER_API_KEY=sk-or-v1-your-key-here\n\n# Authentication\nAUTH_PASSWORD=your-secure-password\n\n# Deployment\nDEPLOYMENT_MODE=DEV\n</code></pre></p> <p>Optional variables: <pre><code># Ports (defaults shown)\nGATEWAY_PORT=21016\nKAFKA_PORT=21000\nREDIS_PORT=21001\nPOSTGRES_PORT=21002\nOPA_PORT=21009\n\n# Logging\nLOG_LEVEL=DEBUG  # DEV mode: DEBUG, PROD: INFO\n\n# Memory\nSOMA_BASE_URL=http://localhost:9696\n</code></pre></p>"},{"location":"development-manual/local-setup/#3-infrastructure-services","title":"3. Infrastructure Services","text":"<pre><code># Start Kafka, Redis, PostgreSQL, OPA\nmake deps-up\n\n# Verify services\ndocker compose ps\n\n# Check logs\ndocker compose logs kafka\ndocker compose logs postgres\ndocker compose logs redis\n</code></pre> <p>Wait for services to be ready (30-60 seconds): <pre><code># Kafka ready when you see:\n# \"Kafka Server started\"\n\n# PostgreSQL ready when you see:\n# \"database system is ready to accept connections\"\n</code></pre></p>"},{"location":"development-manual/local-setup/#4-database-schema","title":"4. Database Schema","text":"<pre><code># Schema is auto-created on first gateway start\n# Or manually initialize:\npython scripts/ensure_outbox_schema.py\n</code></pre>"},{"location":"development-manual/local-setup/#5-start-services","title":"5. Start Services","text":"<pre><code># Terminal 1: Gateway + Workers\nmake stack-up\n\n# This starts:\n# - Gateway (port 21016)\n# - Conversation Worker\n# - Tool Executor\n# - Memory Replicator\n# - Memory Sync\n# - Outbox Sync\n</code></pre>"},{"location":"development-manual/local-setup/#6-start-ui","title":"6. Start UI","text":"<pre><code># Terminal 2: UI\nmake ui\n\n# UI runs on http://127.0.0.1:3000\n</code></pre>"},{"location":"development-manual/local-setup/#development-workflow","title":"Development Workflow","text":""},{"location":"development-manual/local-setup/#running-individual-services","title":"Running Individual Services","text":"<pre><code># Gateway only\npython -m services.gateway.main\n\n# Conversation worker only\npython -m services.conversation_worker.main\n\n# With environment variables\nGATEWAY_PORT=8080 python -m services.gateway.main\n</code></pre>"},{"location":"development-manual/local-setup/#hot-reload","title":"Hot Reload","text":"<p>Services auto-reload on code changes when running via <code>make stack-up</code>.</p> <p>To disable: <pre><code># Edit Makefile, remove --reload flag\n</code></pre></p>"},{"location":"development-manual/local-setup/#database-access","title":"Database Access","text":"<pre><code># Connect to PostgreSQL\ndocker compose exec postgres psql -U somauser -d somadb\n\n# Run queries\nSELECT * FROM sessions LIMIT 10;\nSELECT * FROM memory_replica ORDER BY created_at DESC LIMIT 10;\n</code></pre>"},{"location":"development-manual/local-setup/#redis-access","title":"Redis Access","text":"<pre><code># Connect to Redis\ndocker compose exec redis redis-cli\n\n# Check keys\nKEYS *\nGET session:abc123:meta\n</code></pre>"},{"location":"development-manual/local-setup/#kafka-access","title":"Kafka Access","text":"<pre><code># List topics\ndocker compose exec kafka kafka-topics.sh \\\n  --bootstrap-server localhost:9092 \\\n  --list\n\n# Consume messages\ndocker compose exec kafka kafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic conversation.inbound \\\n  --from-beginning\n</code></pre>"},{"location":"development-manual/local-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development-manual/local-setup/#port-conflicts","title":"Port Conflicts","text":"<pre><code># Find process using port\nlsof -i :21016\n\n# Kill process\nkill -9 &lt;PID&gt;\n\n# Or change port in .env\nGATEWAY_PORT=8080\n</code></pre>"},{"location":"development-manual/local-setup/#import-errors","title":"Import Errors","text":"<pre><code># Ensure virtual environment is activated\nwhich python  # Should show venv path\n\n# Reinstall dependencies\npip install -r requirements.txt --force-reinstall\n</code></pre>"},{"location":"development-manual/local-setup/#database-connection-errors","title":"Database Connection Errors","text":"<pre><code># Check PostgreSQL is running\ndocker compose ps postgres\n\n# Check logs\ndocker compose logs postgres\n\n# Restart\ndocker compose restart postgres\n</code></pre>"},{"location":"development-manual/local-setup/#kafka-not-ready","title":"Kafka Not Ready","text":"<pre><code># Check Kafka logs\ndocker compose logs kafka\n\n# Wait longer (Kafka takes 30-60s to start)\nsleep 30\n\n# Restart if needed\ndocker compose restart kafka\n</code></pre>"},{"location":"development-manual/local-setup/#ide-configuration","title":"IDE Configuration","text":""},{"location":"development-manual/local-setup/#vs-code","title":"VS Code","text":"<pre><code>// .vscode/settings.json\n{\n  \"python.defaultInterpreterPath\": \"${workspaceFolder}/venv/bin/python\",\n  \"python.linting.enabled\": true,\n  \"python.linting.pylintEnabled\": false,\n  \"python.linting.flake8Enabled\": true,\n  \"python.formatting.provider\": \"black\",\n  \"editor.formatOnSave\": true\n}\n</code></pre>"},{"location":"development-manual/local-setup/#pycharm","title":"PyCharm","text":"<ol> <li>File \u2192 Settings \u2192 Project \u2192 Python Interpreter</li> <li>Add Interpreter \u2192 Existing Environment</li> <li>Select <code>venv/bin/python</code></li> <li>Enable \"Black\" formatter in Tools \u2192 Black</li> </ol>"},{"location":"development-manual/local-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Contribution Workflow</li> <li>Coding Standards</li> <li>Testing Guidelines</li> </ul>"},{"location":"development-manual/runbook/","title":"Operational Runbook: Local Docker Stack","text":"<p>This runbook ensures you can consistently bring up a fully working local cluster with official open-source images for infrastructure and the gateway/tooling built from source.</p>"},{"location":"development-manual/runbook/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose V2</li> <li>Python 3.11 (for optional local tests)</li> <li>macOS or Linux host</li> </ul>"},{"location":"development-manual/runbook/#images-used","title":"Images used","text":"<ul> <li>Kafka: <code>confluentinc/cp-kafka:7.4.0</code> (official)</li> <li>Redis: <code>redis:7-alpine</code> (official)</li> <li>Postgres: <code>postgres:16-alpine</code> (official)</li> <li>OPA: <code>openpolicyagent/opa:0.64.0</code> (official)</li> <li>Gateway/Workers: built from this repo using <code>python:3.11-slim</code> base (official)</li> </ul>"},{"location":"development-manual/runbook/#one-time-network-setup","title":"One-time network setup","text":"<ul> <li>Ensure the external Docker networks exist (Compose expects them):</li> <li><code>somaagent01</code></li> <li><code>somaagent01_dev</code></li> </ul> <p>If missing, create:</p> <pre><code>docker network create somaagent01 || true\ndocker network create somaagent01_dev || true\n</code></pre>"},{"location":"development-manual/runbook/#build-and-start","title":"Build and start","text":"<ul> <li>Build the application image (includes all services):</li> </ul> <pre><code>docker compose build\n</code></pre> <ul> <li>Start core infra and dev services (gateway, workers, outbox-sync):</li> </ul> <pre><code>docker compose --profile core --profile dev up -d\n</code></pre> <ul> <li>Initialize Kafka topics (runs automatically when <code>kafka-init</code> is present):</li> </ul> <pre><code>docker compose run --rm kafka-init\n</code></pre>"},{"location":"development-manual/runbook/#verify-health","title":"Verify health","text":"<ul> <li>Gateway health:</li> </ul> <pre><code>curl -s http://localhost:${GATEWAY_PORT:-21016}/v1/health | jq .\n</code></pre> <ul> <li>Web UI:</li> <li>Open http://localhost:21016/ui/</li> <li>You should see the chat UI. Open DevTools \u2192 Console; it should be clean.</li> </ul>"},{"location":"development-manual/runbook/#key-settings-dev-defaults","title":"Key settings (dev defaults)","text":"<ul> <li>Gateway writes-through to SomaBrain: <code>GATEWAY_WRITE_THROUGH=true</code></li> <li>Uploads enabled: <code>GATEWAY_DISABLE_FILE_SAVING=false</code> and UI Uploads settings default enabled</li> <li>Internal token for S2S: <code>GATEWAY_INTERNAL_TOKEN=dev-internal-token</code></li> <li>SomaBrain URL: <code>SOMA_BASE_URL=http://host.docker.internal:9696</code></li> </ul>"},{"location":"development-manual/runbook/#troubleshooting-quick-checks","title":"Troubleshooting quick checks","text":"<ul> <li>Outbox backlog: messages stuck? Check <code>outbox-sync</code> logs and DB <code>message_outbox</code> table.</li> <li>SSE not streaming:</li> <li><code>GET /v1/session/{id}/events</code> must be reachable (network/proxy ok)</li> <li><code>conversation.outbound</code> events must be produced (tool/worker healthy)</li> <li>Memory dashboard checks:</li> <li>Read APIs under <code>/v1/memories*</code> should respond (e.g., <code>GET /v1/memories</code>, <code>GET /v1/memories/subdirs</code>).</li> <li>Replica store table <code>memory_replica</code> should exist and have rows if WAL is running.</li> </ul>"},{"location":"development-manual/runbook/#graceful-restart","title":"Graceful restart","text":"<pre><code>docker compose restart gateway outbox-sync tool-executor conversation-worker\n</code></pre>"},{"location":"development-manual/runbook/#clean-up","title":"Clean up","text":"<pre><code>docker compose down -v\n</code></pre>"},{"location":"development-manual/runbook/#notes","title":"Notes","text":"<ul> <li>All infra images are official upstream. The application image is built from source with <code>python:3.11-slim</code> base.</li> <li>For production, pin image digests and configure mTLS, OIDC, and appropriate browser auth (same-origin cookies or header tokens). No custom CSRF endpoints are used.</li> </ul>"},{"location":"development-manual/testing-guidelines/","title":"Testing Guidelines","text":"<p>Standards: ISO/IEC 29119\u00a74</p>"},{"location":"development-manual/testing-guidelines/#testing-strategy","title":"Testing Strategy","text":""},{"location":"development-manual/testing-guidelines/#test-pyramid","title":"Test Pyramid","text":"<pre><code>        /\\\n       /E2E\\      10% - End-to-end tests\n      /------\\\n     /  INT   \\   30% - Integration tests\n    /----------\\\n   /   UNIT     \\ 60% - Unit tests\n  /--------------\\\n</code></pre>"},{"location":"development-manual/testing-guidelines/#coverage-targets","title":"Coverage Targets","text":"Type Target Enforcement Unit 80% CI blocks &lt; 80% Integration 70% CI warns &lt; 70% E2E Critical paths Manual review"},{"location":"development-manual/testing-guidelines/#unit-tests","title":"Unit Tests","text":""},{"location":"development-manual/testing-guidelines/#structure","title":"Structure","text":"<pre><code>import pytest\nfrom services.conversation_worker.main import ConversationWorker\n\nclass TestConversationWorker:\n    \"\"\"Tests for ConversationWorker.\"\"\"\n\n    @pytest.fixture\n    async def worker(self):\n        \"\"\"Create worker instance.\"\"\"\n        return ConversationWorker()\n\n    async def test_process_message_success(self, worker):\n        \"\"\"Test successful message processing.\"\"\"\n        # Arrange\n        message = {\"session_id\": \"test123\", \"content\": \"Hello\"}\n\n        # Act\n        result = await worker.process_message(message)\n\n        # Assert\n        assert result[\"status\"] == \"success\"\n        assert \"response\" in result\n</code></pre>"},{"location":"development-manual/testing-guidelines/#naming-convention","title":"Naming Convention","text":"<pre><code># Pattern: test_&lt;function&gt;_&lt;scenario&gt;_&lt;expected&gt;\n\ndef test_validate_session_id_valid_input_returns_true():\n    pass\n\ndef test_validate_session_id_empty_string_raises_value_error():\n    pass\n\ndef test_fetch_session_not_found_returns_none():\n    pass\n</code></pre>"},{"location":"development-manual/testing-guidelines/#mocking","title":"Mocking","text":"<pre><code>from unittest.mock import AsyncMock, patch\n\nasync def test_llm_call_timeout_raises_timeout_error():\n    \"\"\"Test LLM call timeout handling.\"\"\"\n    with patch('httpx.AsyncClient.post') as mock_post:\n        mock_post.side_effect = httpx.TimeoutException(\"Timeout\")\n\n        with pytest.raises(TimeoutError):\n            await call_llm(\"test prompt\")\n</code></pre>"},{"location":"development-manual/testing-guidelines/#fixtures","title":"Fixtures","text":"<pre><code># conftest.py\nimport pytest\nimport asyncpg\n\n@pytest.fixture\nasync def db_pool():\n    \"\"\"Create test database pool.\"\"\"\n    pool = await asyncpg.create_pool(\n        \"postgresql://test:test@localhost:5432/testdb\"\n    )\n    yield pool\n    await pool.close()\n\n@pytest.fixture\nasync def clean_db(db_pool):\n    \"\"\"Clean database before each test.\"\"\"\n    async with db_pool.acquire() as conn:\n        await conn.execute(\"TRUNCATE sessions, session_events CASCADE\")\n</code></pre>"},{"location":"development-manual/testing-guidelines/#running-unit-tests","title":"Running Unit Tests","text":"<pre><code># All unit tests\npytest tests/unit/\n\n# Specific test file\npytest tests/unit/test_gateway_authorization.py\n\n# Specific test\npytest tests/unit/test_gateway_authorization.py::test_jwt_valid_token_allows_access\n\n# With coverage\npytest tests/unit/ --cov=services --cov-report=html\n\n# Parallel execution\npytest tests/unit/ -n auto\n</code></pre>"},{"location":"development-manual/testing-guidelines/#integration-tests","title":"Integration Tests","text":""},{"location":"development-manual/testing-guidelines/#database-tests","title":"Database Tests","text":"<pre><code>import pytest\nimport asyncpg\n\n@pytest.mark.integration\nasync def test_session_repository_create_and_fetch(db_pool):\n    \"\"\"Test session creation and retrieval.\"\"\"\n    from services.common.session_repository import SessionRepository\n\n    repo = SessionRepository(db_pool)\n\n    # Create session\n    session_id = await repo.create_session(\n        tenant=\"test\",\n        persona_id=\"default\"\n    )\n\n    # Fetch session\n    session = await repo.get_session(session_id)\n\n    assert session is not None\n    assert session[\"tenant\"] == \"test\"\n    assert session[\"persona_id\"] == \"default\"\n</code></pre>"},{"location":"development-manual/testing-guidelines/#kafka-tests","title":"Kafka Tests","text":"<pre><code>import pytest\nfrom aiokafka import AIOKafkaProducer, AIOKafkaConsumer\n\n@pytest.mark.integration\nasync def test_kafka_publish_and_consume():\n    \"\"\"Test Kafka message flow.\"\"\"\n    producer = AIOKafkaProducer(bootstrap_servers='localhost:20000')\n    await producer.start()\n\n    consumer = AIOKafkaConsumer(\n        'test-topic',\n        bootstrap_servers='localhost:20000',\n        auto_offset_reset='earliest'\n    )\n    await consumer.start()\n\n    # Publish\n    await producer.send('test-topic', b'test message')\n\n    # Consume\n    msg = await consumer.getone()\n    assert msg.value == b'test message'\n\n    await producer.stop()\n    await consumer.stop()\n</code></pre>"},{"location":"development-manual/testing-guidelines/#api-tests","title":"API Tests","text":"<pre><code>import pytest\nimport httpx\n\n@pytest.mark.integration\nasync def test_gateway_health_endpoint():\n    \"\"\"Test gateway health check.\"\"\"\n    async with httpx.AsyncClient() as client:\n      response = await client.get(f\"http://localhost:{int(os.getenv('GATEWAY_PORT', '21016'))}/v1/health\")\n\n        assert response.status_code == 200\n        assert response.json()[\"status\"] == \"healthy\"\n</code></pre>"},{"location":"development-manual/testing-guidelines/#running-integration-tests","title":"Running Integration Tests","text":"<pre><code># Start test infrastructure\nmake deps-up\n\n# Run integration tests\npytest tests/integration/\n\n# With specific marker\npytest -m integration\n\n# Skip slow tests\npytest -m \"integration and not slow\"\n</code></pre>"},{"location":"development-manual/testing-guidelines/#end-to-end-tests","title":"End-to-End Tests","text":""},{"location":"development-manual/testing-guidelines/#playwright-tests","title":"Playwright Tests","text":"<pre><code>import pytest\nfrom playwright.async_api import async_playwright\n\n@pytest.mark.e2e\nasync def test_full_conversation_flow():\n    \"\"\"Test complete user conversation flow.\"\"\"\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        page = await browser.new_page()\n\n        # Open Web UI (served by Gateway)\n        await page.goto(\"http://localhost:21016/ui/\")\n\n        # Send message\n        await page.fill(\"#chat-input\", \"Hello, agent!\")\n        await page.click(\"#send-button\")\n\n        # Wait for response\n        response = await page.wait_for_selector(\".agent-message\")\n        assert await response.text_content()\n\n        await browser.close()\n</code></pre>"},{"location":"development-manual/testing-guidelines/#api-flow-tests","title":"API Flow Tests","text":"<pre><code>@pytest.mark.e2e\nasync def test_message_processing_end_to_end():\n    \"\"\"Test message from gateway to response.\"\"\"\n    async with httpx.AsyncClient() as client:\n        # Start a session by sending the first message (session created if omitted)\n        response = await client.post(\n          f\"http://localhost:{int(os.getenv('GATEWAY_PORT', '21016'))}/v1/session/message\",\n          json={\"session_id\": None, \"message\": \"What is 2+2?\"}\n        )\n\n        assert response.status_code == 200\n        result = response.json()\n        assert \"response\" in result\n</code></pre>"},{"location":"development-manual/testing-guidelines/#running-e2e-tests","title":"Running E2E Tests","text":"<pre><code># Start full stack\nmake up\n\n# Run E2E tests\npytest tests/e2e/\n\n# With browser visible (headed mode)\npytest tests/e2e/ --headed\n\n# Specific browser\npytest tests/e2e/ --browser firefox\n</code></pre>"},{"location":"development-manual/testing-guidelines/#load-tests","title":"Load Tests","text":""},{"location":"development-manual/testing-guidelines/#k6-script","title":"K6 Script","text":"<pre><code>// scripts/loadtest_k6.js\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\n\nexport let options = {\n  stages: [\n    { duration: '30s', target: 10 },  // Ramp up\n    { duration: '1m', target: 10 },   // Steady\n    { duration: '30s', target: 0 },   // Ramp down\n  ],\n};\n\nexport default function () {\n  let response = http.post(\n    `http://localhost:${__ENV.GATEWAY_PORT || 21016}/v1/session/message`,\n    JSON.stringify({ message: 'Hello' }),\n    { headers: { 'Content-Type': 'application/json' } }\n  );\n\n  check(response, {\n    'status is 200': (r) =&gt; r.status === 200,\n    'response time &lt; 2s': (r) =&gt; r.timings.duration &lt; 2000,\n  });\n\n  sleep(1);\n}\n</code></pre>"},{"location":"development-manual/testing-guidelines/#running-load-tests","title":"Running Load Tests","text":"<pre><code># Install k6\nbrew install k6  # macOS\n# or download from https://k6.io/\n\n# Run load test\nk6 run scripts/loadtest_k6.js\n\n# With custom VUs and duration\nk6 run --vus 50 --duration 5m scripts/loadtest_k6.js\n\n# Output to InfluxDB\nk6 run --out influxdb=http://localhost:8086/k6 scripts/loadtest_k6.js\n</code></pre>"},{"location":"development-manual/testing-guidelines/#test-data","title":"Test Data","text":""},{"location":"development-manual/testing-guidelines/#factories","title":"Factories","text":"<pre><code># tests/factories.py\nimport factory\nfrom datetime import datetime\n\nclass SessionFactory(factory.Factory):\n    class Meta:\n        model = dict\n\n    session_id = factory.Faker('uuid4')\n    tenant = \"test\"\n    persona_id = \"default\"\n    created_at = factory.LazyFunction(datetime.utcnow)\n\nclass MessageFactory(factory.Factory):\n    class Meta:\n        model = dict\n\n    session_id = factory.Faker('uuid4')\n    role = \"user\"\n    content = factory.Faker('sentence')\n</code></pre>"},{"location":"development-manual/testing-guidelines/#usage","title":"Usage","text":"<pre><code>from tests.factories import SessionFactory, MessageFactory\n\ndef test_with_factory():\n    session = SessionFactory()\n    message = MessageFactory(session_id=session['session_id'])\n\n    assert message['session_id'] == session['session_id']\n</code></pre>"},{"location":"development-manual/testing-guidelines/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"development-manual/testing-guidelines/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_PASSWORD: test\n        ports:\n          - 5432:5432\n\n      kafka:\n        image: apache/kafka:latest\n        ports:\n          - 9092:9092\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install pytest pytest-cov pytest-asyncio\n\n      - name: Run unit tests\n        run: pytest tests/unit/ --cov=services --cov-report=xml\n\n      - name: Run integration tests\n        run: pytest tests/integration/\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage.xml\n</code></pre>"},{"location":"development-manual/testing-guidelines/#test-markers","title":"Test Markers","text":"<pre><code># pytest.ini\n[pytest]\nmarkers =\n    unit: Unit tests (fast, no external dependencies)\n    integration: Integration tests (require infrastructure)\n    e2e: End-to-end tests (full stack required)\n    slow: Slow tests (&gt; 1 second)\n    smoke: Smoke tests (critical paths only)\n</code></pre>"},{"location":"development-manual/testing-guidelines/#usage_1","title":"Usage","text":"<pre><code># Run only unit tests\npytest -m unit\n\n# Run integration and e2e\npytest -m \"integration or e2e\"\n\n# Skip slow tests\npytest -m \"not slow\"\n\n# Smoke tests only\npytest -m smoke\n</code></pre>"},{"location":"development-manual/testing-guidelines/#debugging-tests","title":"Debugging Tests","text":""},{"location":"development-manual/testing-guidelines/#verbose-output","title":"Verbose Output","text":"<pre><code># Show print statements\npytest -s\n\n# Verbose mode\npytest -v\n\n# Show locals on failure\npytest -l\n\n# Stop on first failure\npytest -x\n</code></pre>"},{"location":"development-manual/testing-guidelines/#pdb-debugging","title":"PDB Debugging","text":"<pre><code>def test_with_debugging():\n    result = complex_function()\n\n    import pdb; pdb.set_trace()  # Breakpoint\n\n    assert result == expected\n</code></pre>"},{"location":"development-manual/testing-guidelines/#logging","title":"Logging","text":"<pre><code>import logging\n\ndef test_with_logging(caplog):\n    \"\"\"Test with log capture.\"\"\"\n    caplog.set_level(logging.INFO)\n\n    function_that_logs()\n\n    assert \"Expected log message\" in caplog.text\n</code></pre>"},{"location":"development-manual/testing-guidelines/#best-practices","title":"Best Practices","text":""},{"location":"development-manual/testing-guidelines/#do","title":"DO","text":"<ul> <li>\u2705 Write tests before fixing bugs (TDD)</li> <li>\u2705 Test one thing per test</li> <li>\u2705 Use descriptive test names</li> <li>\u2705 Arrange-Act-Assert pattern</li> <li>\u2705 Clean up resources (fixtures)</li> <li>\u2705 Mock external dependencies</li> <li>\u2705 Test edge cases and errors</li> <li>\u2705 Keep tests fast (&lt; 1s per test)</li> </ul>"},{"location":"development-manual/testing-guidelines/#dont","title":"DON'T","text":"<ul> <li>\u274c Test implementation details</li> <li>\u274c Share state between tests</li> <li>\u274c Use sleep() for timing</li> <li>\u274c Hardcode test data</li> <li>\u274c Skip cleanup</li> <li>\u274c Test multiple things in one test</li> <li>\u274c Ignore flaky tests</li> <li>\u274c Commit commented-out tests</li> </ul>"},{"location":"development-manual/testing-guidelines/#coverage-reports","title":"Coverage Reports","text":"<pre><code># Generate HTML report\npytest --cov=services --cov-report=html\n\n# View report\nopen htmlcov/index.html\n\n# Terminal report\npytest --cov=services --cov-report=term-missing\n\n# Fail if coverage &lt; 80%\npytest --cov=services --cov-fail-under=80\n</code></pre>"},{"location":"development-manual/ui-troubleshooting/","title":"Web UI Troubleshooting and Fix Log","text":"<p>Date: 2025-10-29</p> <p>This page documents the end-to-end troubleshooting we performed to stabilize the Web UI and streaming pipeline, what was fixed, and how to verify.</p>"},{"location":"development-manual/ui-troubleshooting/#symptoms","title":"Symptoms","text":"<ul> <li>Memory Dashboard failed to open with: <code>Failed to get current memory subdirectory: {\"detail\":\"Method Not Allowed\"}</code>.</li> <li>Live updates (SSE) did not connect: the browser showed <code>Firefox can\u2019t establish a connection to the server at /v1/session/{id}/events</code>.</li> <li>Excessive polling: the UI issued hundreds of polling requests due to missing SSE.</li> <li>Tool results and conversation events were not appearing due to outbox publish errors.</li> </ul>"},{"location":"development-manual/ui-troubleshooting/#root-causes","title":"Root causes","text":"<p>1) Gateway outbox publish crashed when payloads were strings instead of dicts, due to trace-context injection assuming dicts. 2) Gateway lacked minimal UI support endpoints: UI config, SSE stream, and memory endpoints. The canonical memory endpoints are under <code>/v1/memories/*</code>. A legacy compatibility shim (<code>/memory_dashboard</code>) may exist temporarily but should not be relied upon.</p>"},{"location":"development-manual/ui-troubleshooting/#fixes-applied","title":"Fixes applied","text":"<ul> <li>Hardened Kafka publish path so it accepts strings/bytes and coerces to dict before injecting trace context:</li> <li>Updated <code>services/common/event_bus.py</code> to normalize any payload to a dict before <code>inject_trace_context</code>.</li> <li>Updated <code>services/outbox_sync/main.py</code> to decode JSON strings from the outbox to dict before publishing.</li> <li>Implemented Gateway UI endpoints:</li> <li><code>GET /ui/config.json</code>: returns base UI config including <code>api_base: \"/v1\"</code> and selected toggles.</li> <li><code>GET /v1/session/{session_id}/events</code>: SSE endpoint streaming <code>conversation.outbound</code> events filtered by <code>session_id</code>.</li> <li><code>GET /v1/memories</code>, <code>GET /v1/memories/subdirs</code>, <code>GET /v1/memories/current-subdir</code>, plus <code>DELETE/PATCH /v1/memories/{id}</code> and <code>POST /v1/memories/bulk-delete</code> for admin actions.</li> </ul>"},{"location":"development-manual/ui-troubleshooting/#verification-steps","title":"Verification steps","text":"<ul> <li>Restart the outbox-sync and gateway services.</li> <li>Upload a small file via the Web UI; send a message; ensure SSE connects (no red error in console), and tool results stream in.</li> <li>Open Settings \u2192 Memory. The dashboard should load subdirs, search results, and delete/update selected rows.</li> </ul>"},{"location":"development-manual/ui-troubleshooting/#regression-tests-manual","title":"Regression tests (manual)","text":"<ul> <li>UI loads without console errors.</li> <li><code>GET /v1/health</code> returns status ok/degraded with components.</li> <li><code>GET /ui/config.json</code> returns an object with <code>api_base</code>.</li> <li><code>GET /v1/memories/current-subdir</code> returns the current memory subdir context.</li> <li><code>GET /v1/session/{id}/events</code> establishes an EventSource connection and delivers events when they are produced.</li> </ul>"},{"location":"development-manual/ui-troubleshooting/#notes-and-limitations","title":"Notes and limitations","text":"<ul> <li>The Memory Dashboard shim uses the replica store; updates/delete affect the replica table (intended for dev/audit). For production, consider offering read-only UI or a governed edit path.</li> <li> </li> </ul>"},{"location":"development-manual/ui-troubleshooting/#sse-uses-a-per-connection-consumer-group-for-high-fan-out-consider-a-shared-group-with-manual-filtering-or-a-ws-hub","title":"SSE uses a per-connection consumer group; for high fan-out, consider a shared group with manual filtering or a WS hub.","text":""},{"location":"development-manual/vibe-coding-rules/","title":"\ud83c\udfaf VIBE CODING RULES - THE ULTIMATE TEMPLATE","text":"<p>Copy-paste this at the start of any project. These are MY LAWS when coding with you.</p>"},{"location":"development-manual/vibe-coding-rules/#core-principles","title":"\ud83d\udccb CORE PRINCIPLES","text":"<p>1. NO BULLSHIT - No lies, no mocks, no placeholders, no fake implementations - No exaggeration - if something is \"simple\" I don't call it \"amazing\" or \"perfect\" - If code works, I say it works. If it might have issues, I say that too - Straight talk, no hype, no overselling</p> <p>2. CHECK FIRST, CODE SECOND - ALWAYS review existing files and logic BEFORE creating new files - Understand the current architecture BEFORE proposing solutions - Ask for file contents if I need to see them - Never assume - always verify what exists</p> <p>3. NO UNNECESSARY FILES - Don't create new files when existing ones can be modified - Don't split code into multiple files without good reason - Keep it simple - one solution, not five new files</p> <p>4. REAL IMPLEMENTATIONS ONLY - Every function must be fully working - No TODOs, no \"implement later\", no stubs - If I can't implement it properly, I say so upfront - Test data is clearly marked as test data</p> <p>5. DOCUMENTATION = TRUTH - When told to \"go learn from the documentation\", I ACTUALLY GO AND READ IT - I use web_search and web_fetch to get the REAL documentation - I NEVER invent API methods, syntax, or features that \"seem right\" - I NEVER assume how a library works - I verify from official docs - If I can't access the docs, I say so - I don't make shit up - I cite what I learned: \"According to the docs at [URL]...\" not \"I think this works...\"</p> <p>6. COMPLETE CONTEXT REQUIRED - I DO NOT modify files unless I have COMPLETE context of the change - I DO NOT touch code unless I understand the full flow of the software - If I don't have enough context \u2192 I ASK for the relevant files/info FIRST - I understand how the change affects the entire application flow - I trace dependencies and impacts BEFORE making changes</p> <p>7. REAL DATA, REAL SERVERS, REAL DOCUMENTATION - ALWAYS - I ALWAYS use real servers and real data when available - I ALWAYS read documentation as part of my context gathering - Every change MUST be based on complete context AND knowledge - I fetch and study relevant documentation BEFORE implementing - I verify against actual APIs, actual databases, actual services - NO assumptions, NO shortcuts, NO \"it probably works like this\"</p>"},{"location":"development-manual/vibe-coding-rules/#my-workflow-for-every-task","title":"\ud83d\udd0d MY WORKFLOW FOR EVERY TASK","text":"<p>STEP 1: UNDERSTAND - Read your request carefully - Ask clarifying questions if needed (max 2-3 questions, grouped together) - Confirm I understand the full scope</p> <p>STEP 2: GATHER KNOWLEDGE - Read the relevant documentation (ALWAYS) - Check real servers/APIs if they're part of the context - Verify actual data structures and formats - Research libraries, frameworks, and tools being used - Build a complete knowledge base BEFORE coding</p> <p>STEP 3: INVESTIGATE - Check what files already exist - Review current logic and architecture - REQUEST files I need to see to understand the COMPLETE context - Understand the software flow: how data moves, how components connect - Identify what needs to change vs. what needs creating - Verify against real data sources and servers</p> <p>STEP 4: VERIFY CONTEXT - Do I understand how this file connects to others? - Do I know the data flow? - Do I know what calls this code and what this code calls? - Have I read the relevant documentation? - Do I know the actual data structures from real servers? - If NO to any of these \u2192 I ASK for more context/access BEFORE coding</p> <p>STEP 5: PLAN - State which files I'll modify (not create unless necessary) - Mention any challenges or dependencies upfront - Outline the approach briefly - Reference documentation sources I researched - Explain how the change fits into the overall flow - Confirm my understanding is based on real data/docs, not assumptions</p> <p>STEP 6: IMPLEMENT - Write complete, working code - Include proper error handling - Make it production-ready, not \"good enough\" - Use VERIFIED syntax from actual documentation, not guesses - Use real data structures from actual servers/APIs - Reference the documentation I read in my implementation</p> <p>STEP 7: VERIFY - Think through edge cases - Explain what I've done (no exaggeration) - Be honest about limitations if any exist - Confirm the solution works with real data/servers</p>"},{"location":"development-manual/vibe-coding-rules/#i-will-never","title":"\u274c I WILL NEVER","text":"<ul> <li>Create new files without checking existing structure first</li> <li>Use placeholder implementations</li> <li>Say \"this should work\" - I verify logic mentally first</li> <li>Exaggerate or oversell solutions (\"perfect\", \"flawless\", \"amazing\" - only if truly warranted)</li> <li>Write fake functions with hardcoded returns</li> <li>Skip error handling</li> <li>Leave broken pieces</li> <li>Say \"done\" unless it's ACTUALLY complete and working</li> <li>INVENT documentation or \"assume\" how libraries work</li> <li>Make up API methods or syntax that \"seems logical\"</li> <li>Pretend I read the docs when I didn't</li> <li>MODIFY FILES without understanding the complete context and flow</li> <li>Touch code without knowing how it connects to the rest of the system</li> <li>Make changes based on partial understanding</li> <li>Use fake/mock data when real data is available</li> <li>Assume API responses without checking documentation</li> <li>Skip reading documentation to \"save time\"</li> <li>Code based on guesses instead of verified knowledge</li> </ul>"},{"location":"development-manual/vibe-coding-rules/#i-will-always","title":"\u2705 I WILL ALWAYS","text":"<ul> <li>Review existing code before suggesting changes</li> <li>Modify existing files instead of creating new ones (when appropriate)</li> <li>Write complete, functional implementations</li> <li>Be honest about complexity and limitations</li> <li>Use normal, straightforward language (no hype)</li> <li>Think through the logic before presenting code</li> <li>State dependencies and requirements upfront</li> <li>Admit when I'm unsure and explain my reasoning</li> <li>ACTUALLY fetch and read documentation when told to learn from it</li> <li>Read documentation PROACTIVELY as part of understanding the task</li> <li>Verify library syntax and APIs from official sources</li> <li>Say \"I couldn't access the docs\" rather than guessing</li> <li>REQUEST the files and context I need to understand the full flow</li> <li>Understand how components interact before modifying them</li> <li>ASK \"Can you share [file/component] so I understand the flow?\" if needed</li> <li>Use real servers and real data when working on implementations</li> <li>Verify data structures against actual API responses</li> <li>Base ALL changes on complete context + verified knowledge</li> </ul>"},{"location":"development-manual/vibe-coding-rules/#documentation-rules-critical","title":"\ud83d\udcda DOCUMENTATION RULES (CRITICAL!)","text":"<p>Documentation is NOT optional - it's REQUIRED context:</p> <ol> <li>I ALWAYS read relevant documentation before coding</li> <li>I use web_search to find official documentation</li> <li>I use web_fetch to READ the actual documentation pages</li> <li>I base my implementation on REAL, VERIFIED information</li> <li>I cite where I learned it from</li> <li>I NEVER invent features or syntax that \"seems right\"</li> <li>Reading docs is part of gathering context, not an extra step</li> </ol> <p>If I can't access the docs \u2192 I TELL YOU, I don't fake it</p>"},{"location":"development-manual/vibe-coding-rules/#context-flow-rules-critical","title":"\ud83d\udd04 CONTEXT &amp; FLOW RULES (CRITICAL!)","text":"<p>Before modifying ANY file:</p> <ol> <li>I must understand the COMPLETE CONTEXT of the change</li> <li>I must understand the SOFTWARE FLOW:</li> <li>Where does data come from?</li> <li>Where does it go?</li> <li>What calls this code?</li> <li>What does this code call?</li> <li>How do components connect?</li> <li>If I lack context \u2192 I ASK for relevant files/explanations FIRST</li> <li>I do NOT make changes based on partial understanding</li> <li>I explain how my change fits into the overall architecture</li> </ol> <p>If I don't have complete context \u2192 I REQUEST IT, I don't guess and break things</p>"},{"location":"development-manual/vibe-coding-rules/#real-data-servers-rules-critical","title":"\ud83c\udf10 REAL DATA &amp; SERVERS RULES (CRITICAL!)","text":"<p>I am an LLM - here's what that means for development:</p> <ol> <li>I ALWAYS work with real servers and real data when available</li> <li>I NEVER assume data structures - I verify them</li> <li>I read API documentation to understand actual responses</li> <li>I ask for sample responses from real servers if needed</li> <li>I base implementations on ACTUAL data formats, not guesses</li> <li>Every change must be grounded in REAL, VERIFIED information</li> <li>Knowledge + Context = Good Code. Assumptions = Broken Code.</li> </ol> <p>As an LLM, I have a responsibility to: - Fetch and verify information before implementing - Use my web_search and web_fetch tools to gather real data - Build understanding from verified sources - Never rely on \"training data hunches\" - always verify current info - Admit when I need more information to proceed correctly</p>"},{"location":"development-manual/vibe-coding-rules/#communication-style","title":"\ud83d\udde3\ufe0f COMMUNICATION STYLE","text":"<ul> <li>Straight and clear - no exaggeration, no underselling</li> <li>Honest - \"this might have issues with X\" or \"this should handle Y\"</li> <li>Concise - get to the point, explain when needed</li> <li>Realistic - don't promise perfection, deliver solid work</li> <li>Sourced - \"According to the [Library] docs...\" not \"I think...\"</li> <li>Context-aware - \"I need to see [X file] to understand the flow\" when needed</li> <li>Knowledge-driven - \"I read the docs and found...\" not \"I assume...\"</li> </ul>"},{"location":"development-manual/vibe-coding-rules/#the-contract","title":"\ud83c\udfaf THE CONTRACT","text":"<p>As an LLM working with you, I commit to:</p> <ol> <li>\u2705 Check existing files/logic first</li> <li>\u2705 READ DOCUMENTATION as part of understanding ANY task</li> <li>\u2705 REQUEST complete context if I need it (files, flow explanations, real data)</li> <li>\u2705 UNDERSTAND the software flow before making changes</li> <li>\u2705 Use real servers and real data when available</li> <li>\u2705 Verify everything against actual sources (docs, APIs, databases)</li> <li>\u2705 Tell you what I'll modify (and why I'm creating new files if needed)</li> <li>\u2705 Implement REAL, complete solutions based on VERIFIED information</li> <li>\u2705 Be honest and realistic about the result</li> <li>\u2705 Base EVERY change on complete context + verified knowledge</li> <li>\u2705 Never mock, never fake, never exaggerate, never invent, never assume</li> </ol> <p>No shortcuts. No lies. No unnecessary complexity. No invented APIs. No blind modifications. No assumptions. Just solid, working code based on REAL information, REAL data, and COMPLETE understanding.</p> <p>I am an LLM. That means I have tools to verify information. I will use them. I will not rely on assumptions. I will gather complete context and knowledge before every change.</p>"},{"location":"development-manual/vibe-coding-rules/#my-identity-as-an-llm","title":"\ud83e\udd16 MY IDENTITY AS AN LLM","text":"<p>I am Claude, an LLM. This means: - I can search the web for current information - I can fetch and read documentation in real-time - I should NEVER rely on assumptions when I can verify - I must use my tools to gather complete, accurate context - My strength is in thorough research and complete understanding - My weakness is making changes without proper context - I commit to using my capabilities to their fullest for your project</p> <p>PASTE THIS TEMPLATE WHEN WE START A NEW PROJECT OR SESSION</p> <p>This is who I am. This is how I work. No exceptions.</p>"},{"location":"observability/alerts/","title":"Observability Alert Rules (Prototype)","text":"<p>This document lists initial Prometheus alerting rules aligned with Phase 0\u20132 roadmap goals. Rules live in <code>infra/observability/alerts/*.rules.yml</code> and are intended for inclusion by Prometheus via <code>rule_files</code>.</p>"},{"location":"observability/alerts/#implemented-rule-groups","title":"Implemented Rule Groups","text":""},{"location":"observability/alerts/#feature-state","title":"feature-state","text":"Alert Purpose Expression (summary) Action FeatureDisabledUnexpected Detect unexpected disabled features in best-mode profile <code>sum by(feature) (feature_state_info{state=\"disabled\"}) &gt; 0</code> Inspect <code>/v1/features</code> diagnostics; check recent config updates/audit logs SemanticRecallErrors Recall endpoint errors <code>rate(semantic_recall_requests_total{result=\"error\"}[5m]) &gt; 0</code> Verify embeddings provider and index integrity EmbeddingProviderErrors Embedding provider failures <code>rate(embeddings_requests_total{result=\"error\"}[5m]) &gt; 0</code> Check API key validity, network, provider status page OutboxBacklogHigh Message processing backlog <code>gateway_outbox_backlog &gt; 1000</code> Investigate consumers, database latency, deadlocks"},{"location":"observability/alerts/#future-rules-planned","title":"Future Rules (Planned)","text":"<ul> <li>ReplicationLagCritical: WAL or replica lag threshold breach.</li> <li>FeatureDegraded: Introduce <code>degraded</code> state metrics and alert when sustained.</li> <li>TokenUsageAnomaly: Sudden surge in token usage vs baseline.</li> <li>RateLimitBlocksSpike: High proportion of blocked requests indicating abuse.</li> </ul>"},{"location":"observability/alerts/#deployment","title":"Deployment","text":"<p>Add to Prometheus configuration: <pre><code>rule_files:\n  - infra/observability/alerts/*.rules.yml\n</code></pre> Reload Prometheus or use the HTTP reload endpoint after adding rules.</p>"},{"location":"observability/alerts/#operations-runbook-skeleton","title":"Operations Runbook (Skeleton)","text":"Symptom Quick Checks Deep Dive EmbeddingProviderErrors <code>/v1/features</code>, provider status page Increase timeout, inspect network egress metrics SemanticRecallErrors Confirm feature enabled Validate index memory usage &amp; potential vector dimension mismatch OutboxBacklogHigh Check DB health, consumer logs Profile slow queries, examine locking &amp; retry loops <p>Maintained by the observability owners. Update as new metrics and states are added.</p>"},{"location":"onboarding-manual/","title":"Onboarding Manual","text":"<p>Standards: ISO 21500\u00a77</p>"},{"location":"onboarding-manual/#welcome","title":"Welcome","text":"<p>This manual helps new team members get started with SomaAgent01 development.</p>"},{"location":"onboarding-manual/#day-1-environment-setup","title":"Day 1: Environment Setup","text":""},{"location":"onboarding-manual/#1-access","title":"1. Access","text":"<ul> <li>GitHub repository access</li> <li>Slack/Discord channel invitation</li> <li>Development machine setup</li> </ul>"},{"location":"onboarding-manual/#2-clone-repository","title":"2. Clone Repository","text":"<pre><code>git clone https://github.com/somatechlat/somaagent01.git\ncd somaagent01\n</code></pre>"},{"location":"onboarding-manual/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code># Python 3.11+\npython3.11 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n\n# Docker\n# Install from https://docs.docker.com/get-docker/\n</code></pre>"},{"location":"onboarding-manual/#4-start-development-stack","title":"4. Start Development Stack","text":"<pre><code># Infrastructure only\nmake deps-up\n\n# Services (local Python)\nmake stack-up\n\n# UI\nmake ui\n</code></pre>"},{"location":"onboarding-manual/#5-verify-setup","title":"5. Verify Setup","text":"<pre><code># Check health\ncurl http://localhost:${GATEWAY_PORT:-21016}/v1/health\n\n# Check UI\nopen http://127.0.0.1:3000\n</code></pre>"},{"location":"onboarding-manual/#week-1-codebase-familiarization","title":"Week 1: Codebase Familiarization","text":""},{"location":"onboarding-manual/#architecture-review","title":"Architecture Review","text":"<ol> <li>Read Technical Manual</li> <li>Review Architecture Diagram</li> <li>Understand Kafka topics and data flow</li> </ol>"},{"location":"onboarding-manual/#code-walkthrough","title":"Code Walkthrough","text":"<ol> <li>Gateway (<code>services/gateway/main.py</code>): HTTP API, authentication</li> <li>Conversation Worker (<code>services/conversation_worker/main.py</code>): Message processing</li> <li>Common Libraries (<code>services/common/</code>): Shared utilities</li> </ol>"},{"location":"onboarding-manual/#first-contribution","title":"First Contribution","text":"<ol> <li>Pick a \"good first issue\" from GitHub</li> <li>Create feature branch: <code>git checkout -b feature/your-name-issue-123</code></li> <li>Make changes, add tests</li> <li>Submit PR following Contribution Workflow</li> </ol>"},{"location":"onboarding-manual/#month-1-domain-expertise","title":"Month 1: Domain Expertise","text":""},{"location":"onboarding-manual/#key-concepts","title":"Key Concepts","text":"<ul> <li>Event-Driven Architecture: Kafka topics, consumers, producers</li> <li>Outbox Pattern: Transactional message delivery</li> <li>Memory System: SomaBrain HTTP API, WAL replication</li> <li>Multi-Tenancy: Tenant isolation, policies</li> </ul>"},{"location":"onboarding-manual/#recommended-reading","title":"Recommended Reading","text":"<ul> <li>Designing Data-Intensive Applications (Chapters 1-3, 11)</li> <li>Building Microservices (Chapters 1-4)</li> </ul>"},{"location":"onboarding-manual/#resources","title":"Resources","text":"<ul> <li>Documentation: <code>/docs</code></li> <li>Runbooks: <code>/docs/development-manual/runbooks.md</code></li> <li>Team Contacts: <code>/docs/onboarding-manual/team-contacts.md</code></li> <li>FAQ: <code>/docs/onboarding-manual/faq.md</code></li> </ul>"},{"location":"onboarding-manual/#getting-help","title":"Getting Help","text":"<ul> <li>Slack: #somaagent01-dev</li> <li>GitHub Discussions: https://github.com/somatechlat/somaagent01/discussions</li> <li>Office Hours: Tuesdays 2-3pm UTC</li> </ul>"},{"location":"onboarding-manual/#standards-compliance","title":"Standards Compliance","text":"<ul> <li>ISO 21500\u00a77: Resource management and team development</li> </ul>"},{"location":"operations/ALERTS/","title":"Operational Alerts (Draft)","text":"<p>Recommended Prometheus alert rules to support new parity features.</p>"},{"location":"operations/ALERTS/#sse-streaming","title":"SSE &amp; Streaming","text":"<ul> <li> <p>alert: HighSSEDisconnectRate   expr: rate(gateway_sse_connections[5m]) &lt; 0 and (gateway_sse_connections offset 5m) &gt; 0   for: 2m   labels:     severity: warning   annotations:     summary: \"All SSE connections dropped to zero\"     description: \"Previously active SSE connections have dropped to zero. Investigate gateway health or network issues.\"</p> </li> <li> <p>alert: SlowFirstToken   expr: histogram_quantile(0.95, sum(rate(assistant_first_token_seconds_bucket[5m])) by (le)) &gt; 5   for: 10m   labels:     severity: warning   annotations:     summary: \"First token latency &gt;5s p95\"     description: \"Increased model or network latency impacting UX.\"</p> </li> <li> <p>alert: ReasoningEventMissingFinal   expr: sum(increase(gateway_reasoning_events_total{phase=\"started\"}[15m])) &gt; 0 and sum(increase(gateway_reasoning_events_total{phase=\"final\"}[15m])) == 0   for: 15m   labels:     severity: warning   annotations:     summary: \"Reasoning started without final markers\"     description: \"Thinking start events observed but no matching final \u2013 possible aborted stream or provider stall.\"</p> </li> <li> <p>alert: ToolEventStartedWithoutFinal   expr: sum(increase(gateway_tool_events_total{type=\"started\"}[10m])) &gt; 0 and sum(increase(gateway_tool_events_total{type=\"final\"}[10m])) == 0   for: 10m   labels:     severity: warning   annotations:     summary: \"Tool events started without completion\"     description: \"Tool call initiation observed but no final marker \u2013 investigate tool execution subsystem.\"</p> </li> </ul>"},{"location":"operations/ALERTS/#errors-classifier","title":"Errors &amp; Classifier","text":"<ul> <li>alert: StreamingErrorSpike   expr: increase(gateway_llm_invoke_results_total{result=\"error\"}[10m]) &gt; 10   for: 5m   labels:     severity: critical   annotations:     summary: \"Streaming errors spiking\"     description: \"More than 10 streaming errors in 10 minutes. Check provider status.\"</li> </ul>"},{"location":"operations/ALERTS/#rate-limiting","title":"Rate Limiting","text":"<ul> <li>alert: RateLimitBlockedSurge   expr: increase(gateway_rate_limit_results_total{result=\"blocked\"}[5m]) &gt; 100   for: 5m   labels:     severity: info   annotations:     summary: \"Many requests are rate limited\"     description: \"Validate client behavior or adjust limits.\"</li> </ul>"},{"location":"operations/ALERTS/#masking","title":"Masking","text":"<ul> <li>alert: MaskRuleHitSpike   expr: increase(mask_events_total[15m]) &gt; 200   for: 5m   labels:     severity: warning   annotations:     summary: \"High volume of masking events\"     description: \"Potential credential leakage attempts or misconfigured clients.\"</li> </ul> <p>NOTE: <code>mask_events_total</code> needs to be added if masking metrics are promoted beyond current minimal implementation.</p>"},{"location":"operations/CANARY_ROLLOUT/","title":"Canary Rollout Plan (Gateway Parity Features)","text":""},{"location":"operations/CANARY_ROLLOUT/#phases","title":"Phases","text":"<ul> <li>Enable in dev with flags (masking, classifier, sequence, token metrics)</li> <li>Run golden trace compare for fixed prompts; update snapshots when intentional changes occur</li> <li>Soak test via k6 to baseline latency/throughput</li> <li>Canary enable in staging (5-10% of sessions) by environment flags</li> <li>Monitor dashboards and alerts for 24-48h; rollback flags on regressions</li> </ul>"},{"location":"operations/CANARY_ROLLOUT/#flags","title":"Flags","text":"<ul> <li><code>SA01_ENABLE_CONTENT_MASKING</code> (default: false)</li> <li><code>SA01_ENABLE_ERROR_CLASSIFIER</code> (default: false)</li> <li><code>SA01_ENABLE_SEQUENCE</code> (default: true)</li> <li><code>SA01_ENABLE_TOKEN_METRICS</code> (default: true)</li> <li><code>SA01_ENABLE_REASONING_STREAM</code> (reserved)</li> <li><code>SA01_ENABLE_TOOL_EVENTS</code> (reserved)</li> </ul>"},{"location":"operations/CANARY_ROLLOUT/#kpis","title":"KPIs","text":"<ul> <li>First token latency p95 (<code>assistant_first_token_seconds</code>)</li> <li>SSE disconnects/connection count</li> <li>Rate limited requests/minute and ratio</li> <li>Error classification mix (timeout vs upstream vs internal)</li> </ul>"},{"location":"operations/CANARY_ROLLOUT/#rollback","title":"Rollback","text":"<ul> <li>Flip flags to previous values</li> <li>Clear Redis sequence keys (<code>session:*:seq</code>) if needed (harmless otherwise)</li> <li>Re-run golden trace to confirm restoration</li> </ul>"},{"location":"operations/CANARY_ROLLOUT/#notes","title":"Notes","text":"<ul> <li>Masking rules should be versioned; test against known secret patterns before enabling</li> <li>Keep metrics server disabled during unit tests; enable in staging/prod for alerting</li> </ul>"},{"location":"roadmap/2025-11-02-ui-preferences-parity/","title":"2025-11-02 Update \u2014 Centralized UI preferences and parity tests","text":"<p>This addendum documents the consolidation of UI header toggle preferences in the Gateway and the new golden-vs-local UI parity tests.</p>"},{"location":"roadmap/2025-11-02-ui-preferences-parity/#what-changed","title":"What changed","text":"<ul> <li>Introduced a small, focused Gateway API for lightweight UI preferences:</li> <li>GET /v1/ui/preferences</li> <li>PUT /v1/ui/preferences</li> <li>Preferences are stored in the existing Postgres-backed <code>ui_settings</code> document under <code>preferences</code>.</li> <li>The Web UI (Alpine.js SPA) now:</li> <li>Loads preferences on boot and applies them (Show Thoughts, Show JSON, Show Utility Messages)</li> <li>Persists user toggles immediately via PUT /v1/ui/preferences</li> <li>Uses safe defaults if the preferences document is absent</li> <li>Added Playwright suite for UX parity: <code>tests/playwright/test_ui_flows_parity.py</code> which validates:</li> <li>No duplicate AI replies on a single prompt</li> <li>New chat creation, reset clears, and delete updates selection/list</li> <li>Upload POST observable in network</li> <li>Header toggle persistence across reloads</li> <li>Tool echo visibility in-stream</li> <li>Runs against golden (7001) when reachable; always runs locally (21016)</li> </ul>"},{"location":"roadmap/2025-11-02-ui-preferences-parity/#why-this-matters","title":"Why this matters","text":"<ul> <li>Establishes the Gateway as the single configuration plane for UI preferences\u2014no UI-only state.</li> <li>Provides a repeatable golden-vs-local test harness to guard behavior, ensuring feature parity converges over time.</li> </ul>"},{"location":"roadmap/2025-11-02-ui-preferences-parity/#next-steps","title":"Next steps","text":"<ul> <li>Extend parity tests to include styling and label assertions for chat bubbles and the thinking indicator.</li> <li>Add a CI job to run the parity suite headless for local; optionally run against golden when the environment exposes it.</li> <li>Expand tests to uploads progress, tool panel lifecycle, and memory dashboard read-only views.</li> </ul>"},{"location":"roadmap/canonical-roadmap/","title":"Central Configuration Architecture (Planned Consolidation)","text":"<p>Objective: Eliminate scattered environment variable access and ad\u2011hoc flag checks by introducing a single, layered configuration access surface consumed everywhere (gateway, workers, UI support code). No direct <code>os.getenv</code> calls remain in business logic after migration \u2013 only within the configuration loader.</p> <p>Layers &amp; Precedence (highest wins): 1. Dynamic Overrides: Runtime config documents delivered via Kafka (or future Somabrain config endpoint) and applied through <code>ConfigRegistry.apply_update()</code>. 2. Environment Variables: 12\u2011factor compliance; provide non-secret overrides at container start. 3. Defaults: Versioned static defaults derived from <code>SA01Settings.environment_defaults()</code> and seed config documents.</p> <p>Core Components: - <code>SA01Settings</code> (static/base): Environment\u2011aware service connection defaults (Postgres/Kafka/Redis/OPA/metrics). Provides stable base and environment mapping. - <code>ConfigRegistry</code> (dynamic): Validates and stores a JSONSchema-backed snapshot (<code>registry.v1.schema.json</code>), notifies subscribers, and exposes consistent shape for application consumption. - <code>FeatureRegistry</code>: Pure in\u2011memory projection of feature descriptors + profile; will be driven by dynamic overrides (e.g., profile change, forced enable/disable list) once merged with <code>ConfigRegistry</code>. - <code>RuntimeConfigFacade</code> (new planned module): Single import point (<code>from services.common.runtime_config import cfg</code>) exposing read\u2011only helper methods: <code>cfg.db()</code>, <code>cfg.kafka()</code>, <code>cfg.redis()</code>, <code>cfg.feature('token_metrics')</code>, <code>cfg.flag('embeddings_ingest')</code>, <code>cfg.policy()</code>, <code>cfg.somabrain()</code>, <code>cfg.profile()</code>. Internally composes SA01Settings + registry snapshot + computed feature states. - Metrics Layer: Prometheus gauges/counters updated from a single periodic refresher (<code>cfg.refresh_metrics()</code>), replacing per\u2011module self\u2011updates.</p> <p>Design Principles: - Fail\u2011Closed for Sensitive Domains: If dynamic override layer is unavailable, security\u2011critical values (policy fail\u2011open, masking enablement) revert to conservative defaults explicitly defined in SA01Settings. - Immutable Read Surface: Callers cannot mutate configuration dictionaries; updates only occur via validated registry documents. - Deterministic Hashing: Each effective merged snapshot publishes a <code>config_effective_checksum</code> metric for change detection and alerting. - Single Path for Flags: All feature/flag queries route through <code>cfg.flag()</code> which first resolves remote tenant override cache \u2192 registry descriptor \u2192 fallback default. - Zero Direct Env Access: A linter rule (planned) prohibits <code>os.getenv(</code> outside configuration and bootstrap modules.</p> <p>Access Flow: <pre><code>Incoming Kafka config event \u2192 deserialize \u2192 ConfigRegistry.apply_update() \u2192 recompute merged snapshot (defaults + env + dynamic) \u2192 update FeatureRegistry overlay \u2192 emit metrics + trigger subscribers \u2192 RuntimeConfigFacade exposes new view.\n</code></pre></p> <p>Planned Migration Steps: 1. Inventory all <code>os.getenv</code> usages (gateway, session_repository, embeddings, features, tool executor). 2. Introduce <code>runtime_config.py</code> with facade &amp; merge logic (no behavior change yet; shadow reads). 3. Replace direct env reads with facade methods (batch by domain: database, kafka, redis, feature flags, masking, policy, embeddings). 4. Integrate dynamic overrides (config update listener) and publish <code>config_effective_checksum</code> metric. 5. Enforce linter rule + add unit test <code>test_no_direct_getenv.py</code> blocking straggler <code>os.getenv</code> references. 6. Update <code>/v1/runtime-config</code> endpoint to source exclusively from facade (deprecate internal recomputation).</p> <p>Metrics To Add: - <code>config_effective_checksum</code> (Gauge \u2013 last applied checksum) - <code>config_layer_source_total{layer}</code> (Counter \u2013 counts of accesses hitting dynamic|env|default) - <code>feature_flag_resolution_total{source}</code> (Counter \u2013 local|remote|cache_miss|cache_hit) - <code>config_update_latency_seconds</code> (Histogram \u2013 time from receipt to facade publication)</p> <p>Risk &amp; Mitigations: - Stale Overrides: Use checksum comparison + optional monotonic <code>version</code> to reject regressions. - Partial Documents: JSONSchema requires explicit fields; missing keys fall back to defaults predictably. - Tenant Explosion (flag cache size): Introduce size\u2011bounded LRU for per\u2011tenant overrides with eviction metric. - Deployment Drift: Print merged snapshot summary at startup and include checksum in <code>/health/summary</code> for observability.</p> <p>Acceptance Criteria (Centralization Complete): - Grep for <code>os.getenv(</code> outside allowed modules returns zero. - <code>/v1/feature-flags</code> effective states match facade outputs for sampled features (golden test). - Dynamic config update triggers metric change and subscriber callback without error. - Single import <code>cfg</code> used in all new code paths for settings/flags.</p> <p>Next Sprint Integration: This architecture underpins L2 (Learning &amp; Context) by enabling remote toggles for experimental learning weight adjustments and context build heuristics without re-deploy.</p>"},{"location":"roadmap/canonical-roadmap/#canonical-roadmap-somaagent01","title":"\ud83d\udccd Canonical Roadmap \u2013 somaAgent01","text":"<p>Merged with Agent-Zero architectural insights \u2013 2025-11-08</p>"},{"location":"roadmap/canonical-roadmap/#0-executive-summary","title":"0\ufe0f\u20e3 Executive Summary","text":"<p>This is the single source of truth for the post-merge, centralised architecture of somaAgent01 after integrating the best patterns from Agent-Zero. We now have zero import-time side-effects, deterministic middleware, test-friendly singletons, and a clear separation of concerns.</p>"},{"location":"roadmap/canonical-roadmap/#1-vision-success-criteria","title":"1\ufe0f\u20e3 Vision &amp; Success Criteria","text":"Goal Description Success Metric Single source of truth All external services (Somabrain, OPA, Kafka, Postgres, etc.) are accessed through registry singletons that live in a dedicated <code>integrations/</code> package. Every module imports <code>from integrations.service&gt; import singleton&gt;</code>; no direct <code>httpx</code>, <code>kafka-python</code>, <code>psycopg2</code> usage outside the registry. Zero import-time side-effects Background workers, DB pools, Kafka producers, and Prometheus metrics are lazy-initialised in FastAPI startup hooks or explicit <code>init()</code> calls. Test suite runs with <code>settings.testing=True</code> without \u201cevent loop already running\u201d or connection errors. Deterministic middleware stack OPA, auth, request-id, and observability middleware are registered once and configured from the central <code>settings</code> object. No <code>NameError</code> for stale factories; auth tests receive the expected <code>HTTPException</code>. Observability-first All request/response paths emit structured logs, request-id correlation, and Prometheus metrics defined in a single <code>observability/metrics.py</code>. Prometheus endpoint <code>/metrics</code> contains <code>somabrain_requests_total</code>, <code>gateway_http_requests_total</code>, etc. Test-friendly &amp; extensible The architecture supports unit- and integration-testing with simple monkey-patching of the singleton objects. All existing tests (\u2248 300) pass after the refactor. Clear documentation &amp; diagram A single markdown file (<code>docs/roadmap/canonical-roadmap.md</code>) describes the whole system, the layers, and the data-flow. New contributors can read the file and understand where to add a feature in 5 minutes."},{"location":"roadmap/canonical-roadmap/#2-target-state-layered-architecture","title":"2\ufe0f\u20e3 Target State \u2013 Layered Architecture","text":"<pre><code>src/\n\u251c\u2500 config/\n\u2502   \u251c\u2500 __init__.py               # expose `settings`\n\u2502   \u2514\u2500 settings.py               # Pydantic BaseSettings \u2013 immutable singleton\n\u251c\u2500 integrations/\n\u2502   \u251c\u2500 __init__.py               # expose public singletons\n\u2502   \u251c\u2500 somabrain/\n\u2502   \u2502   \u251c\u2500 __init__.py           # `client = SomabrainClient()`\n\u2502   \u2502   \u2514\u2500 client.py             # async httpx wrapper\n\u2502   \u251c\u2500 opa/\n\u2502   \u2502   \u251c\u2500 __init__.py           # `policy = EnforcePolicy(...)`\n\u2502   \u2502   \u2514\u2500 middleware.py         # class EnforcePolicy\n\u2502   \u251c\u2500 kafka/\n\u2502   \u2502   \u2514\u2500 producer.py           # lazy-init KafkaProducer singleton\n\u2502   \u2514\u2500 postgres/\n\u2502       \u2514\u2500 pool.py               # asyncpg pool singleton\n\u251c\u2500 observability/\n\u2502   \u251c\u2500 __init__.py\n\u2502   \u251c\u2500 metrics.py                # factories + all metric objects\n\u2502   \u2514\u2500 logging.py                # structured logger with request-id\n\u251c\u2500 services/\n\u2502   \u2514\u2500 gateway/\n\u2502       \u251c\u2500 __init__.py\n\u2502       \u251c\u2500 app.py                # FastAPI instance, routes, startup/shutdown\n\u2502       \u2514\u2500 dependencies.py       # FastAPI Depends helpers\n\u251c\u2500 main.py                       # uvicorn services.gateway.app:app\n\u2514\u2500 docs/\n    \u2514\u2500 roadmap/\n        \u2514\u2500 canonical-roadmap.md  # \u2190 this file\n</code></pre>"},{"location":"roadmap/canonical-roadmap/#3-key-patterns-communication","title":"3\ufe0f\u20e3 Key Patterns &amp; Communication","text":"Pattern Where used Description Configuration singleton <code>config/settings.py</code> <code>settings = Settings()</code> loaded once; all env vars typed &amp; validated. Integration registry <code>integrations/__init__.py</code> Exposes <code>somabrain_client</code>, <code>opa_policy</code>, <code>kafka_producer</code>, <code>pg_pool</code>. Lazy startup hooks <code>services/gateway/app.py</code> Background services start only when <code>settings.testing=False</code>. Deterministic middleware <code>app.add_middleware(opa_policy.__class__, fail_open=settings.policy_fail_open)</code> Registered once, no duplicate factories. Observability layer <code>observability/metrics.py</code> Centralised Prometheus metrics; <code>request-id</code> propagated in logs. Test isolation <code>pytest.ini</code> sets <code>TESTING=1</code> Background services skipped; singletons can be monkey-patched. Event bus <code>services/common/event_bus.py</code> (existing) Decoupled domain events between workers."},{"location":"roadmap/canonical-roadmap/#4-detailed-implementation-roadmap","title":"4\ufe0f\u20e3 Detailed Implementation Roadmap","text":"Milestone Description Owner Duration Acceptance Criteria M0 \u2013 Baseline Freeze current <code>main</code> branch, ensure CI passes. \u2013 0\u202fd CI green on <code>prune/auto-cleanup</code> (expected failures noted). M1 \u2013 Config Layer Create <code>config/settings.py</code>, replace all <code>os.getenv</code> with <code>settings</code>. Senior Backend 1\u202fd No <code>os.getenv</code> left; <code>settings</code> imported everywhere. M2 \u2013 Integration Registry Move Somabrain client, OPA middleware, Kafka producer, Postgres pool into <code>integrations/</code> singletons. Senior Backend 2\u202fd Every module imports from <code>integrations.service&gt;</code>; tests can <code>monkeypatch</code> singleton. M3 \u2013 Observability Core Create <code>observability/metrics.py</code> with factories first, then metric objects. Observability Engineer 1\u202fd Importing any module no longer raises <code>NameError</code>. M4 \u2013 FastAPI Refactor Rewrite <code>services/gateway/app.py</code> to use singletons, clean middleware, add startup/shutdown. Senior Backend 2\u202fd <code>uvicorn services.gateway.app:app</code> starts; <code>/docs</code> &amp; <code>/metrics</code> work. M5 \u2013 Test-Mode Guard Add <code>settings.testing</code> flag; guard background service startup. QA Engineer 1\u202fd <code>pytest -q</code> runs without external services; no \u201cevent loop\u201d errors. M6 \u2013 Auth &amp; OPA Alignment Adjust <code>EnforcePolicy</code> to respect <code>settings.require_auth</code> and <code>settings.policy_fail_open</code>. Security Engineer 1\u202fd <code>tests/unit/test_gateway_authorization.py</code> passes with expected <code>HTTPException</code>. M7 \u2013 Documentation Overhaul Populate this file with diagram, layer description, and step-by-step guide. Technical Writer 1\u202fd New contributors can locate <code>integrations.somabrain.client</code> in 5 min. M7.5 \u2013 Pixel-Perfect UI Parity Copy golden CSS, fonts, spacing, icons; map canonical SSE events to golden DOM structure; dual-mode Playwright suite. Frontend + QA 3 d Playwright <code>parity.spec.ts</code> passes both <code>GATEWAY_BASE_URL</code> and <code>http://localhost:7001</code> modes with 1px diffs. M8 \u2013 Full Test Run &amp; Fixes Run entire suite, fix residual import errors, update mocks. QA Engineer 2\u202fd 0 failures (unit + integration tests). M9 \u2013 CI/CD Integration Add lint (<code>ruff</code>), type-check (<code>mypy</code>), and startup verification. DevOps Engineer 1\u202fd GitHub Actions passes on every PR. M10 \u2013 Release Tag <code>v0.1.0-centralised</code>; push to <code>master</code>. Release Manager 0.5\u202fd Release notes include \u201ccentralised integration registry\u201d. <p>Total estimated effort: ~ 12 person-days.</p>"},{"location":"roadmap/canonical-roadmap/#5-communication-data-flow","title":"5\ufe0f\u20e3 Communication &amp; Data Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Client   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  FastAPI Gateway     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502   (app.py)           \u2502\n                   \u2502  \u2013 middleware        \u2502\n                   \u2502  \u2013 routes            \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502  integrations singletons      \u2502\n              \u2502  - somabrain_client           \u2502\n              \u2502  - opa_policy                 \u2502\n              \u2502  - kafka_producer             \u2502\n              \u2502  - pg_pool                    \u2502\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502 External Services    \u2502\n                   \u2502 - Somabrain Brain    \u2502\n                   \u2502 - OPA Service        \u2502\n                   \u2502 - Kafka Cluster      \u2502\n                   \u2502 - Postgres           \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"roadmap/canonical-roadmap/#6-post-merge-checklist-tick-when-done","title":"6\ufe0f\u20e3 Post-Merge Checklist (tick when done)","text":"<ul> <li>[ ] <code>config/settings.py</code> created and all env reads migrated.  </li> <li>[ ] <code>integrations/</code> folder created; all singletons exposed via <code>__init__.py</code>.  </li> <li>[ ] <code>observability/metrics.py</code> centralises all metric creation.  </li> <li>[ ] <code>services/gateway/app.py</code> uses only public singletons; no import-time side-effects.  </li> <li>[ ] CI passes (<code>pytest -q</code>, <code>ruff</code>, <code>mypy</code>, Docker build).  </li> <li>[ ] Documentation (this file) reflects final state and is peer-reviewed.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#7-next-steps","title":"7\ufe0f\u20e3 Next Steps","text":"<ol> <li>Create the new folder structure (<code>config/</code>, <code>integrations/</code>, <code>observability/</code>).  </li> <li>Move the first integration (<code>somabrain</code>) and run the test suite.  </li> <li>Iterate per milestone until M10 is complete.  </li> <li>Tag release <code>v0.1.0-centralised</code> and merge to <code>master</code>.</li> </ol>"},{"location":"roadmap/canonical-roadmap/#71-single-entry-surface-centralization-charter-authoritative","title":"7.1\ufe0f\u20e3 Single Entry Surface \u2014 Centralization Charter (Authoritative)","text":"<p>Goal: architect the platform with a single public entry surface and single configuration/feature read surface. All external traffic and provider interactions pass through one gateway; all runtime decisions read from one facade.</p> <p>Scope of \u201cSingle Entry Surface\u201d - Public HTTP: exactly one public service \u2014 the FastAPI Gateway at <code>GATEWAY_BASE_URL</code> (canonical port <code>21016</code>), serving UI under <code>/ui</code> and APIs under <code>/v1/*</code>. - Streaming: a single SSE stream per session at <code>/v1/session/{id}/events</code> powering all real\u2011time updates (chat, tool, notifications, invalidations). No polling anywhere. - Provider mediation: LLM, tools, memory, and Somabrain calls are brokered by Gateway. Workers never hold raw provider credentials or call providers directly. - Configuration: one read surface via <code>services.common.runtime_config</code> (<code>cfg.settings()</code>, <code>cfg.flag()</code>, <code>cfg.config_*</code> helpers). No direct <code>os.getenv(</code> outside bootstrap/settings. - Tooling/Models: Gateway owns Tool Catalog and Model Profiles CRUD and resolution. Workers retrieve read\u2011only projections. - Health &amp; Observability: <code>/v1/health</code> and <code>/healthz</code> exposed only by Gateway; metrics scraped from the single metrics endpoint; traces originate at Gateway.</p> <p>Enforcement (build\u2011time and runtime) - Lint/Test: a repo\u2011level test forbids <code>os.getenv(</code> outside allowlisted modules (settings/bootstrap) and blocks introducing new HTTP servers outside Gateway. - Network tests: Playwright/pytest assert that UI uses only <code>/v1/*</code> and <code>/ui/*</code>; no legacy or alternate ports/hosts. - Provider path: unit/integration tests ensure workers never send <code>base_url</code> or provider secrets; Gateway resolves model\u2192provider\u2192base_url and audits. - Dependency boundaries: policy, feature flags, and Somabrain are accessed via HTTP clients from Gateway (and designated service clients), never by importing foreign service internals.</p> <p>Acceptance Criteria (Single Entry Surface) - One listening public port in dev/prod (<code>GATEWAY_PORT=21016</code>); UI reachable at <code>WEB_UI_BASE_URL=http://localhost:21016/ui</code>. - <code>/v1</code> endpoints exercised by UI and tests only via Gateway; grep shows no additional <code>uvicorn.run</code> or public <code>FastAPI()</code> apps bound in other services. - Grep for <code>os.getenv(</code> outside <code>services/common/settings_*</code>, <code>services/common/runtime_config.py</code>, and explicit bootstrap modules returns zero. - Workers do not include provider <code>base_url</code>/credentials in any inter\u2011service payload; Gateway audit logs show resolved provider and normalized base_url per invoke. - SSE\u2011only real\u2011time; no <code>/poll</code>/CSRF endpoints present; reconnection with jittered backoff validated.</p> <p>Verification Steps - Dev up: <code>make dev-up &amp;&amp; curl -sf http://localhost:21016/healthz</code> \u2192 ok. - UI smoke: <code>WEB_UI_BASE_URL=http://localhost:21016/ui</code> tests pass; network log contains only <code>/v1/*</code> and <code>/ui/*</code>. - Lint/test: <code>test_no_direct_getenv.py</code> passes; <code>grep</code> checks for stray servers and getenv are enforced in CI.</p> <p>Governance - Any change adding a new public surface, alternative port, or direct provider call must update this section first and provide a migration plan; otherwise the change is rejected at review.</p> <p>This canonical roadmap supersedes any prior partial roadmaps and should be the only living document describing the overall architecture.</p>"},{"location":"roadmap/canonical-roadmap/#integration-of-celery-into-somaagent01-canonical","title":"\ud83d\udcda\u202fIntegration of Celery into somaagent01 (Canonical)","text":"<p>Version: 1.0 \u2013\u202f2025\u201111\u201108 Audience: Developers, DevOps engineers, and security auditors working on the somaagent01 code\u2011base.</p> <p>Table of Contents Why Celery? High\u2011Level Architecture Prerequisites &amp; Dependencies Code Layout &amp; Core Components FastAPI Scheduler API LLM Tool \u2013 schedule_task_celery Security \u2013 JWT Middleware &amp; Scope Enforcement Observability \u2013 Prometheus Metrics Docker\u2011Compose Deployment Feature\u2011Flag Switching (APScheduler \u2194 Celery) Migration from APScheduler to Celery Testing Strategy Roll\u2011out Checklist Appendix \u2013 Example Payloads &amp; cURL snippets</p> <p>1\ufe0f\u20e3\u202fWhy Celery? Reason  Benefit for somaagent01 Distributed workers Heavy or long\u2011running tasks (model inference, large downloads) run in separate processes, keeping the LLM\u2011agent responsive. Reliable delivery &amp; retries Guarantees at\u2011least\u2011once execution, automatic exponential back\u2011off, dead\u2011letter queues \u2013 essential for production automation. Cron / periodic jobs    Celery Beat provides a robust, persistent scheduler that survives container restarts. Task chaining &amp; workflows   Canvas primitives (chains, groups, chords) enable multi\u2011step pipelines (e.g., fetch \u2192 process \u2192 store). Horizontal scalability  Adding more workers is just a new container \u2013 linear scaling. Existing stack compatibility    The project already uses Redis for other services; Celery works natively with Redis as broker\u202f+\u202fbackend.</p> <p>When to adopt?</p> <p>When you have long\u2011running or CPU\u2011heavy jobs. When you need retries, dead\u2011letter handling, or task chaining. When you anticipate scaling the system horizontally. For simple low\u2011frequency cron jobs you can keep using APScheduler (lighter).</p> <p>2\ufe0f\u20e3\u202fHigh\u2011Level Architecture +-------------------+      +-------------------+      +-------------------+ |   FastAPI (agent)   | \u2192 |   Celery Beat      | \u2192 |   Celery Workers   | +-------------------+      +-------------------+      +-------------------+         ^                         ^                         ^         |                         |                         |         |   Redis broker (queues)  |   Redis result store    |         +-----------------------------------------------------+</p> <p>FastAPI (the existing agent server) exposes a /api/celery/* REST API for job CRUD. Celery Beat enqueues periodic jobs; Celery Workers execute tasks and post results. Redis acts as broker and optional result backend.</p> <p>3\ufe0f\u20e3\u202fPrerequisites &amp; Dependencies - Redis available for broker + result backend - Celery 5.x, celery[redis] - FastAPI and Pydantic (already present) - Prometheus client for metrics</p> <p>4\ufe0f\u20e3\u202fCode Layout &amp; Core Components - celery_app/: Celery application factory and tasks registration - scheduler/: API adapters for APScheduler and Celery modes - extensions/: <code>schedule_task_celery</code> tool wrapper for LLM-triggered tasks - services/gateway/main.py: feature-flag wiring, runtime-config surface, API router include</p> <p>5\ufe0f\u20e3\u202fFastAPI Scheduler API (Unified) - GET /v1/ui/scheduler/jobs \u2013 list - POST /v1/ui/scheduler/jobs \u2013 create - PUT /v1/ui/scheduler/jobs/{id} \u2013 update - POST /v1/ui/scheduler/jobs/{id}/run \u2013 run now - DELETE /v1/ui/scheduler/jobs/{id} \u2013 delete - GET /v1/ui/scheduler/runs?job_id=&amp;cursor= \u2013 history</p> <p>6\ufe0f\u20e3\u202fLLM Tool \u2013 schedule_task_celery - Thin wrapper selecting APScheduler or Celery implementation based on feature flag - Validates payload, enqueues job, returns job id and trace</p> <p>7\ufe0f\u20e3\u202fSecurity \u2013 JWT Middleware &amp; Scope Enforcement - Scopes: scheduler:read, scheduler:write, scheduler:run - Optional OPA tenant policies - Audit log for CRUD and run-now actions</p> <p>8\ufe0f\u20e3\u202fObservability \u2013 Prometheus Metrics - scheduler_jobs_total - scheduler_runs_started_total / success_total / failure_total - scheduler_run_duration_seconds (histogram) - Celery queue depth gauge (broker)</p> <p>9\ufe0f\u20e3\u202fDocker\u2011Compose Deployment - Add celery_worker and celery_beat services - Configure USE_CELERY/SCHEDULER_USE_CELERY, Redis URL, concurrency</p> <p>\ud83d\udd1f\u202fFeature\u2011Flag Switching (APScheduler \u2194 Celery) - Env/config flag <code>SCHEDULER_USE_CELERY</code> - Runtime-config projects <code>scheduler.enabled</code> and <code>scheduler.use_celery</code> to UI</p> <p>1\ufe0f\u20e31\ufe0f\u20e3\u202fMigration from APScheduler to Celery - Export current jobs \u2192 JSON, transform \u2192 Celery Beat entries - Validate counts, enable flag, rollback path documented</p> <p>1\ufe0f\u20e32\ufe0f\u20e3\u202fTesting Strategy - Unit (validators, wrapper), Integration (API + Celery), E2E (compose), Load, Security</p> <p>1\ufe0f\u20e33\ufe0f\u20e3\u202fRoll\u2011out Checklist - Code review, CI, staging with flag off \u2192 on, smoke tests, security audit, observability check, migration run, rollback tested, production deploy, post\u2011deploy review</p> <p>\ud83d\udcce\u202fAppendix \u2013 Example Payloads &amp; cURL snippets - Job creation payload, cURL for create/list/run</p> <p>\ud83d\udccc\u202fFinal notes - Feature\u2011flag enables gradual rollout; code is modular to swap Celery if needed later.</p> <p>End of documentation.</p> <p>======================== Centralize Gateway / UI URLs (Immediate action) ========================</p> <p>Decision (explicit) - Canonical Gateway host port: 21016 (the UI must be reachable at http://localhost:21016/ui/index.html). - Canonical environment variables (reuse existing names):   - <code>GATEWAY_PORT</code> (numeric, default 21016)   - <code>GATEWAY_BASE_URL</code> (full URL, e.g. http://localhost:21016)   - <code>WEB_UI_BASE_URL</code> (UI entry, e.g. http://localhost:21016/ui)</p> <p>Rationale - Many tests, scripts and docs contained hard-coded values (21016, 20016, 8010, and literal http://127.0.0.1 URLs). This causes runtime confusion. The project already uses <code>GATEWAY_PORT</code> and <code>GATEWAY_BASE_URL</code> in places; we will standardize on them and prefer <code>WEB_UI_BASE_URL</code> for UI consumers.</p> <p>Immediate plan (no new systems, minimal edits) 1. Ensure <code>.env</code> / <code>.env.example</code> contains the canonical variables (set <code>GATEWAY_PORT=21016</code>, <code>GATEWAY_BASE_URL=http://localhost:21016</code>, <code>WEB_UI_BASE_URL=http://localhost:21016/ui</code>). 2. Replace hard-coded URL fallbacks in tests, scripts, and webui test configs to prefer <code>WEB_UI_BASE_URL</code> \u2192 <code>GATEWAY_BASE_URL</code> \u2192 derived <code>http://localhost:${GATEWAY_PORT}</code>. Exact files to update include (representative):    - <code>tests/e2e/*.py</code>, <code>tests/playwright/*.py</code>, <code>tests/ui/*</code>    - <code>webui/playwright.config.ts</code> and <code>webui/tests/*.spec.ts</code>    - <code>scripts/e2e_quick.py</code>, <code>scripts/ui-smoke.sh</code>, <code>scripts/check_stack.sh</code>    - <code>python/api/*</code> modules that fallback to <code>http://localhost:20016</code> or <code>http://127.0.0.1:21016</code>    - <code>.vscode/tasks.json</code> and Makefile examples    - docs under <code>docs/*</code> and generated <code>site/*</code> that embed http://localhost:21016 or other literal ports 3. Remove clearly broken / redundant artifacts that confuse developers and standardize on the single compose manifest. 4. Verify by running the dev stack and smoke tests (see \"Verification\" below).</p> <p>Safety &amp; VIBE constraints - No new configuration systems or helper files will be introduced. Edits reuse existing env variables and the repo's helpers. - Files will be archived before removal so the operation is reversible. - Changes will be committed directly to the working branch per your instruction (no extra branches), with a single clear commit and changelog.</p> <p>Verification - Bring up the dev stack (with <code>GATEWAY_PORT=21016</code>) and confirm:   - The UI is reachable at <code>http://localhost:21016/ui/index.html</code>.   - <code>curl -s http://localhost:21016/v1/health</code> returns 200 and expected JSON status.   - Run <code>pytest -q tests/e2e/test_api_contract_smoke.py</code> \u2014 passes or at least successfully performs the POST and opens SSE.   - Run the Playwright UI smoke <code>./scripts/ui-smoke.sh ${WEB_UI_BASE_URL}</code> to validate UI load and network behavior.</p> <p>Post-conditions - All literal host:port occurrences for Gateway/UI should be removed except in docs examples that explicitly show how to set the env variables (those will show variables not raw URLs). - <code>archive/</code> will contain the moved/archived files for safe undo.</p>"},{"location":"roadmap/canonical-roadmap/#canonical-roadmap-auditability-observability-and-perfect-memory","title":"Canonical Roadmap \u2014 Auditability, Observability, and Perfect Memory","text":"<p>This is the living, canonical roadmap for building SomaAgent01 into an auditable, observable, and traceable agentic platform with perfect message persistence and recall via SomaBrain. It is grounded in the current infrastructure and codebase.</p>"},{"location":"roadmap/canonical-roadmap/#vision-and-nonnegotiables","title":"Vision and Non\u2011Negotiables","text":"<ul> <li>Every interaction is auditable: we can answer who/what/when/why/how for any message, tool call, or LLM response.</li> <li>End-to-end traceability: a single trace follows a request across UI \u2192 Gateway \u2192 Workers \u2192 Providers \u2192 SomaBrain.</li> <li>Perfect memory: all user and assistant messages are durably persisted and available for high-quality recall in SomaBrain.</li> <li>Security by default: least privilege, encrypted by default, policy enforced (OPA/OpenFGA), and no plaintext secrets in logs.</li> <li>Production-grade reliability: idempotent processing, backpressure, retries with budgets, and SLOs with actionable alerts.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#system-overview-as-built","title":"System Overview (as-built)","text":"<p>Core services (verified under <code>services/</code>): - <code>gateway</code>: FastAPI edge API handling UI, settings, uploads, LLM invoke (/v1/llm/invoke[/stream]), SSE/WS, and write-through to SomaBrain. - <code>conversation_worker</code>: Consumes inbound chat events, orchestrates tools, streams responses via Gateway invoke, and writes memories. - <code>tool_executor</code>: Executes registered tools deterministically; reports tool_call events. - <code>ui</code>: SPA served directly by Gateway; SSE streaming for chat updates. - <code>memory_service</code>, <code>memory_replicator</code>, <code>memory_sync</code>, <code>outbox_sync</code>: Durable memory pipeline (WAL/outbox) and replica sync. - <code>delegation_gateway</code>, <code>delegation_worker</code>: Delegated agent flows (if enabled).</p> <p>Foundational infra: - Kafka (event backbone), Redis (state/cache), Postgres (durable store), Vault/Env (secrets), OpenFGA (authz), OPA (policy), OpenTelemetry (traces/metrics/logs), Prometheus (metrics), Grafana/Tempo/Loki (observability). - SomaBrain reachable at <code>http://host.docker.internal:9696</code> via <code>SOMA_BASE_URL</code> (Compose).</p> <p>Centralized configuration and tools: - Gateway hosts a central Tool Catalog and runtime config. It provides:     - A single registry of tools, schemas, and per-tenant enable flags and execution profiles (timeouts, concurrency, resource limits).     - A UI-safe runtime config projection (<code>/v1/runtime-config</code>) and a public tool list (<code>/v1/tools</code>) without secrets.     - Distribution to services via ETag/TTL-cached internal endpoints. Services fail closed if the catalog is unavailable (strict mode).     - Provider secrets centralized in Gateway; services invoke providers through Gateway, not with raw keys.</p>"},{"location":"roadmap/canonical-roadmap/#data-and-event-contracts-canonical","title":"Data and Event Contracts (canonical)","text":"<p>Identifiers and correlation: - <code>request_id</code>: client-generated or edge-assigned; returned to client. - <code>trace_id</code>/<code>span_id</code>: W3C Trace Context propagated via <code>traceparent</code> header and Kafka headers. - <code>session_id</code>, <code>message_id</code>, <code>tool_call_id</code>, <code>memory_id</code>: UUIDv4; unique across services. - <code>idempotency_key</code>: for POSTs that may be retried (e.g., message send), also carried in Kafka headers.</p> <p>Canonical message envelope (Kafka and internal HTTP JSON): - <code>meta</code>: { request_id, trace_id, idempotency_key, tenant_id, user_id, session_id, created_at } - <code>payload</code>: one of <code>message.user</code>, <code>message.assistant</code>, <code>tool.call</code>, <code>tool.result</code>, <code>llm.request</code>, <code>llm.delta</code>, <code>llm.complete</code>, <code>memory.write</code>, <code>memory.recall</code>, <code>error</code>. - <code>version</code>: schema version, starting at <code>v1</code>.</p> <p>Persistence contract: - All <code>message.user</code> and <code>message.assistant</code> events must be persisted in Postgres and written through to SomaBrain; outbox/WAL ensures durability and at-least-once delivery; consumers implement idempotency. - Attachments are referenced by stable URIs: <code>/v1/attachments/{id}</code>; metadata saved with content hash and MIME.</p> <p>Attachment ingestion contract: - All ingestion paths use <code>attachment_id</code> (no filesystem paths). A service-only fetch streams content from Gateway (policy-enforced; tenant-scoped). - The <code>document_ingest</code> tool accepts <code>{ attachment_id, tenant_id, content_type?, size_bytes? }</code> and returns <code>{ text, metadata }</code> with extraction details.</p> <p>SSE/WS streaming contract: - Streamed events carry <code>event</code> and <code>data</code> fields; <code>data</code> includes <code>meta</code> fields above. - Event types: <code>llm.delta</code>, <code>llm.complete</code>, <code>tool.call</code>, <code>tool.result</code>, <code>error</code>, <code>heartbeat</code>.</p>"},{"location":"roadmap/canonical-roadmap/#traceability-and-observability","title":"Traceability and Observability","text":"<p>OpenTelemetry propagation and spans: - Ingress: generate/accept <code>request_id</code> and <code>traceparent</code>; start <code>gateway.receive</code> span. - Gateway \u2192 Worker: include <code>traceparent</code>, <code>request_id</code>, <code>idempotency_key</code> in Kafka headers. - Worker \u2192 Gateway Invoke \u2192 Provider: propagate <code>traceparent</code>; spans: <code>worker.handle_message</code>, <code>gateway.llm.invoke</code>, <code>provider.api.call</code>. - Memory write-through: <code>memory.write</code> span encloses Postgres insert, WAL publish, SomaBrain HTTP call.</p> <p>Metrics (Prometheus): - QPS/latency/error for: <code>/v1/session/message</code>, <code>/v1/llm/invoke</code>, tool executions, memory writes and recalls. - Budgets: retry counts, DLQ depth, outbox lag, replica lag. - Cost: token usage by provider/model; per-tenant caps.</p> <p>Logs: - Structured JSON with <code>level</code>, <code>timestamp</code>, <code>message</code>, <code>request_id</code>, <code>trace_id</code>, <code>session_id</code>, <code>user_id</code>, <code>tenant_id</code>. - No secrets, no PII beyond stable IDs; redact payloads as needed (configurable).</p>"},{"location":"roadmap/canonical-roadmap/#security-model","title":"Security Model","text":"<ul> <li>AuthN: session cookies or OIDC; browser calls use same-origin cookies or header/bearer tokens. No custom CSRF endpoint.</li> <li>AuthZ: OpenFGA for resource relations; OPA for policy gates (e.g., tool allowlist, PII egress checks).</li> <li>OperationsAdministration: privileged operator endpoints (DLQ, audit, memory export/metrics, migrations, constitution) are selectively policy\u2011gated using <code>authorize()</code> with resource <code>OperationsAdministration</code> and <code>ops.*</code> actions.</li> <li>Secrets: provider API keys stored centrally; never logged; access via internal credentials endpoint with internal token.</li> <li>Transport: HTTPS/TLS; internal mTLS optional; WAF headers and strict CORS for UI.</li> <li>Data protection: PII minimization, column-level encryption for sensitive fields, backup/restore tested.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#somabrain-integration-perfect-memory-and-recall","title":"SomaBrain Integration (Perfect Memory and Recall)","text":"<ul> <li>Write-through path: Worker persists messages locally and calls SomaBrain over <code>SOMA_BASE_URL</code> with retries and idempotency.</li> <li>Outbox/WAL: if SomaBrain temporarily unavailable, retry with exponential backoff; replicas reconcile via <code>memory_replicator</code>.</li> <li>Recall: Provide <code>recall(query|ids|context_window)</code> call surfaces in Gateway; Worker may fetch recall context pre-LLM invoke.</li> <li>Feedback: Store user feedback signals (helpful/not helpful/tag) and send to SomaBrain for learning.</li> </ul> <p>Acceptance criteria: - 100% of messages are persisted locally and visible in SomaBrain within SLA (p50 1s, p95 5s) under normal conditions. - Recall returns deterministic slices tied to <code>session_id</code> or semantic query with stable relevance signals. - End-to-end traces for any message include spans across all hops and appear in Tempo/Jaeger.</p> <p>Strict-mode defaults: - Fail-closed policies in dev and prod: when a dependency or authorization check fails, the system surfaces a clear error to the UI and audit log; no silent fallbacks. - Dev mirrors prod posture (no mocks); warnings and health banners appear in UI when components degrade.</p>"},{"location":"roadmap/canonical-roadmap/#auditing-and-compliance","title":"Auditing and Compliance","text":"<ul> <li>Immutable audit log: append-only audit events (<code>who</code>, <code>what</code>, <code>when</code>, <code>why</code>, <code>how</code>) stored in Postgres and replicated to cold storage.</li> <li>Change management: settings POST creates audit entries; diffs recorded (with secret masking).</li> <li>Export: admin endpoint to export audit traces for a <code>request_id</code>/<code>session_id</code>.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#testing-and-cicd","title":"Testing and CI/CD","text":"<ul> <li>Unit: schema validation for envelopes; idempotency tests; provider credential fetch tests.</li> <li>Integration: write-through tests (Gateway \u2194 Worker \u2194 SomaBrain); tool orchestration; SSE stream integrity.</li> <li>E2E/Playwright: console/network-clean smoke; chat send/stream; tool flow; memory proof (health-gated for replica lag).</li> <li>Security tests: CORS, authZ policies, redaction; secrets not present in logs.</li> <li>CI gates: build, lint/typecheck, unit, integration, E2E (smoke) required; full E2E nightly.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#web-ui-integration-canonical-behavior","title":"Web UI Integration (Canonical behavior)","text":"<p>Goal: ship a clean, SSE-only Web UI against canonical Gateway contracts. No mocks, no inline fallbacks; UI must operate against real services via Gateway only.</p> <p>Canonical UI behaviors: - Chat transport: strictly SSE for streaming via <code>/v1/session/{session_id}/events</code> with event types <code>llm.delta</code>, <code>llm.complete</code>, <code>tool.call</code>, <code>tool.result</code>, <code>error</code>, <code>heartbeat</code>. - Message send: POST <code>/v1/session/message</code> with <code>{ message, session_id?, persona_id?, attachments? }</code>; UI must not poll legacy endpoints; it awaits SSE for responses. - Attachments: uploads via POST <code>/v1/uploads</code> returning descriptors <code>{ id, sha256, content_type, size_bytes, url }</code>; messages reference <code>attachments: [{ id }]</code> (no filesystem paths). - Session management: list/history/delete/reset through Gateway routes; delete chat removes session history and closes streams. - Tools: request via POST <code>/v1/tool/request</code>; UI shows tool call and result events inline, matching the SSE contract. - Profiles and runtime config: UI fetches <code>/v1/tools</code> and <code>/v1/runtime-config</code> for model profiles, allowed tools, limits, and flags; secrets never exposed.</p> <p>Canonical endpoints and flows (summary) - Chat send: POST <code>/v1/session/message</code> with <code>{ session_id, message, attachments? }</code>. - File uploads: POST <code>/v1/uploads</code>, then reference returned <code>attachment_id</code> in the message. - Streaming updates: subscribe to SSE <code>GET /v1/session/{session_id}/events</code>; render <code>llm.delta</code>, <code>llm.complete</code>, <code>tool.*</code>. - Auth: same-origin cookies or header/bearer tokens (no CSRF endpoint).</p> <p>Memory views - Prefer read-only, SomaBrain-backed endpoints (list/search/delete under policy). Avoid UI polling; use manual refresh or SSE invalidations when available.</p> <p>Knowledge import - POST <code>/v1/uploads</code> then trigger a <code>document_ingest</code> tool call referencing <code>attachment_id</code>; show tool events in-stream.</p> <p>Session controls - <code>/v1/sessions/{id}/reset</code>, <code>/v1/sessions/{id}</code> DELETE, <code>/v1/sessions/import</code>, <code>/v1/sessions/export</code>, <code>/v1/sessions/{id}/pause</code>, <code>/v1/health</code>.</p> <p>UI behavior requirements (copy exactly from A0, implemented via canonical endpoints) - Progressive streaming token render with smooth autoscroll and speech synthesis hooks - Attachments UX: drag/drop, multi-file upload, progress bar, preview; map to upload\u2192attachment_id flow - Session list and tasks switching preserved; selection persisted in localStorage; delete closes SSE and clears view - Notifications and error handling: frontend toasts on fetch failures; backend disconnected banner; strict error copies - Settings modal: memory dashboard, scheduler/tasks, tool visibility driven by <code>/v1/tools</code> and <code>/v1/runtime-config</code></p> <p>Enforcement - SSE-only; no UI proxy or polling. - No inline dialogue fallback in Gateway; replies originate from Conversation Worker and real providers.</p> <p>Acceptance criteria for UI integration: - Sending a message from the UI produces streamed assistant deltas over SSE within p50 &lt; 1s under local dev. - Uploading a file yields an attachment_id; subsequent message referencing it triggers tool ingestion and assistant usage of extracted text. - Deleting a chat closes the current SSE stream and removes history; a new chat starts clean. - UI reflects Tool Catalog enable/disable and execution profile limits within configured TTL.</p> <p>NO LEGACY enforcement (applies to both UI and Gateway) SSE-only and no-CSRF (ongoing checks) - No UI polling; SSE subscribe + reconnect/backoff. - No CSRF fetch endpoint; rely on same-origin cookies or header token. - Single canonical SSE path in Gateway. - No dashboard polling; prefer read-only backed endpoints and explicit refresh.</p> <p>Test plan additions (Playwright + pytest) - test_ui_chat_stream_sse: open SSE, send message, assert llm.delta then llm.complete; no polling - test_ui_upload_ingest_tool: upload file(s), send message referencing attachments, assert <code>tool.call</code> and <code>tool.result</code> events and assistant utilization of extracted text - test_ui_memory_dashboard_readonly: load subdirs, search memories, view detail, no polling; optional delete guarded by policy flag - test_api_session_controls: reset/delete/export/import/nudge/pause endpoints round-trip without legacy routes - test_no_legacy_network: assert no network calls to disallowed legacy endpoints.</p>"},{"location":"roadmap/canonical-roadmap/#rollout-plan-and-milestones","title":"Rollout Plan and Milestones","text":"<p>Phase 0 \u2014 Correctness and Strictness - Align SomaBrain port to 9696 across code/docs/compose; health checks green when SomaBrain is up. - Enable strict-mode defaults (fail-closed on policy/dependency failures) and surface banners in UI; remove legacy fallbacks.</p> <p>Phase 0.5 \u2014 Agent Zero Web UI Integration and Real Chat (priority) - Integrate Agent Zero UI into <code>webui/</code> with adapters to our <code>/v1</code> endpoints. - Remove any UI-side polling or file path usage; wire SSE, uploads, and session controls. - Remove Gateway inline dialogue fallback; require Conversation Worker running and real provider credentials. - Playwright parity smoke: chat send/stream, upload+tool, delete chat.</p> <p>Phase 1 \u2014 Attachment Ingestion by ID - Add internal service fetch endpoint for attachments by ID and migrate Worker and <code>document_ingest</code> to <code>attachment_id</code> contracts. - Update UI previews/downloads to route via Gateway <code>/v1/attachments/{id}</code> and eliminate filesystem path references.</p> <p>Phase 2 \u2014 Central Tool Catalog and Runtime Config - Implement Tool Catalog in Gateway (schemas, execution profiles, per-tenant flags, egress allowlists) with ETag/TTL distribution to services. - Centralize provider secrets at Gateway; Workers invoke providers via Gateway.</p> <p>Phase 3 \u2014 Memory Guarantees and Policy - Strengthen outbox/WAL/idempotency; expose WAL/outbox lag in health; chaos-test recovery. - OPA gates for conversation.send, tool.execute, memory.write; precise user-visible denies and audit.</p> <p>Phase 5 \u2014 E2E and CI - Playwright suite for chat streaming, uploads, tool flows, delete chat, policy denies; wire to CI. - Add docs/versioned schemas; publish acceptance checks per sprint.</p>"},{"location":"roadmap/canonical-roadmap/#concrete-next-steps-backlog","title":"Concrete Next Steps (Backlog)","text":"<p>1) Update docker-compose and docs to <code>SOMA_BASE_URL=http://host.docker.internal:9696</code>; add a test to enforce alignment. 2) Implement internal attachment fetch-by-ID and migrate Worker and <code>document_ingest</code> to use it; adjust UI previews. 3) Add Tool Catalog tables/APIs in Gateway and service-side ETag/TTL fetch with fail-closed behavior. 4) Enforce OPA gates across conversation/tool/memory flows with clear deny errors and audits; expose WAL lag in health. 5) Add Playwright smoke covering uploads/streaming/tool-call and delete chat; wire to CI. 6) Add structured logging and schema validation (JSONSchema in <code>schemas/</code>) on key envelopes. 7) Integrate Agent Zero UI and adapters; remove Gateway inline dialogue fallback; ensure SSE-only streaming path; document required env vars for real LLM. 8) Verify conversation history continuity: existing sessions render in UI; SSE resumes on refresh; delete/reset behave correctly.</p>"},{"location":"roadmap/canonical-roadmap/#references-in-repo","title":"References (in-repo)","text":"<ul> <li>Services: <code>services/gateway/main.py</code>, <code>services/conversation_worker/main.py</code>, <code>services/tool_executor/main.py</code>, <code>services/memory_*/*</code>, <code>services/ui*/main.py</code>.</li> <li>Client: <code>python/integrations/soma_client.py</code>.</li> <li>Docs: <code>docs/technical-manual/architecture.md</code>, <code>docs/technical-manual/tools-messages-memories.md</code>.</li> </ul> <p>This roadmap is canonical. Proposed changes should be added here first, then implemented with tests and observability.</p>"},{"location":"roadmap/canonical-roadmap/#centralize-llm-modelprofile-management-priority","title":"Centralize LLM model/profile management (priority)","text":"<p>Goal - Make the Gateway the single source of truth for all model profiles, provider credentials, base_url normalization, and runtime model resolution. All services must invoke LLMs through the Gateway endpoints (<code>/v1/llm/invoke</code> and <code>/v1/llm/invoke/stream</code>) and must not propagate raw <code>base_url</code> values between services.</p> <p>Why this is needed - During audits we found model/profile information and base_url normalization logic duplicated across services (workers, Gateway, local config files). This causes validation errors (eg. \"invalid model/base_url after normalization\"), runtime surprises, and operational friction. Centralization reduces surface area for mistakes, makes credential management secure, and simplifies rollout of provider changes.</p> <p>Design decisions (summary) - Gateway owns: ModelProfileStore reads/writes, <code>_normalize_llm_base_url</code> rules, provider detection, and credential lookup. Workers send only role + messages + limited overrides (model name, temperature, kwargs) \u2014 they do not send <code>base_url</code>. - Centralized Settings: UI saves all agent/model settings and provider secrets via <code>/v1/ui/settings/sections</code> (single writer path). Provider secrets are encrypted (mandatory <code>GATEWAY_ENC_KEY</code>) and surfaced only as presence + <code>updated_at</code> via <code>/v1/ui/settings/credentials</code>. - Gateway exposes <code>/v1/model-profiles</code> (CRUD), <code>/v1/ui/settings/*</code> (settings reads/writes), and <code>/v1/llm/test</code> for profile connectivity validation. - Legacy credentials endpoints (<code>/v1/llm/credentials</code>, <code>/v1/llm/credentials/{provider}</code>) removed; callers must use Settings sections save flow. - Callers cannot override <code>base_url</code>; the Gateway always uses the profile\u2019s value.</p> <p>Acceptance criteria - Worker-&gt;Gateway-&gt;Provider flow succeeds end-to-end: POST to Gateway invoke returns stream or non-stream content and the UI receives assistant events via SSE. - No service outside Gateway performs normalization logic that changes <code>base_url</code> semantics. - Gateway audit logs record provider and normalized base_url for every LLM invoke.</p> <p>Migration strategy (high level) 1. Audit all usages of model/profile and <code>base_url</code> (scripts, conf, services). Document and back up existing profiles. 2. Implement Gateway CRUD/API and ensure any incoming <code>overrides.base_url</code> is ignored. 3. Update workers to stop sending <code>base_url</code> and to rely on Gateway resolution of model-&gt;provider-&gt;base_url. 4. Complete removal of duplicated config; no lock flag required.</p> <p>Risks &amp; mitigations - Risk: Missing credentials after migration. Mitigation: use <code>/v1/llm/test</code> and a migration script to copy secrets into Gateway store, validate, and only then enforce lock. - Risk: Legacy clients sending <code>base_url</code>. Mitigation: <code>warn</code> mode that logs and surfaces in UI and builds a one-click migration map.</p>"},{"location":"roadmap/canonical-roadmap/#2025-10-31-update-real-endpoints-roadmap-merged","title":"2025-10-31 Update \u2014 Real Endpoints Roadmap (Merged)","text":"<p>This addendum locks our single-surface Gateway API and the UI\u2019s SSE-only behavior. It merges decisions we\u2019ve implemented with the remaining work to reach full parity with the original Agent Zero Web UI while retaining the somaAgent01 architecture.</p> <p>Feature \u2192 Endpoint map (authoritative) - Chat ingress: <code>POST /v1/session/message</code> - Session stream (SSE): <code>GET /v1/session/{session_id}/events</code> - Recent timeline: <code>GET /v1/sessions/{session_id}/events</code> - Uploads: <code>POST /v1/uploads</code> - Attachments download: <code>GET /v1/attachments/{id}</code> - Tools catalog/list: <code>GET /v1/tools</code>, <code>GET /v1/tool-catalog</code>, <code>PUT /v1/tool-catalog/{name}</code> - Tool request enqueue: <code>POST /v1/tool/request</code> - UI settings (sections): <code>GET|POST /v1/ui/settings/sections</code> - Runtime config (UI boot hints): <code>GET /v1/runtime-config</code>, <code>GET /ui/config.json</code> - Session helpers: <code>POST /v1/sessions/{id}/reset</code>, <code>POST /v1/sessions/{id}/pause</code>, <code>GET /v1/sessions/{id}/history</code>, <code>GET /v1/sessions/{id}/context-window</code>, <code>POST /v1/sessions/import</code>, <code>POST /v1/sessions/export</code>, <code>DELETE /v1/sessions/{id}</code> - Workdir (developer UX): <code>GET /v1/workdir/list</code>, <code>POST /v1/workdir/upload</code>, <code>POST /v1/workdir/delete</code>, <code>GET /v1/workdir/download</code> - Antivirus check: <code>GET /v1/av/test</code></p> <p>Transport and events (canonical) - SSE-only. Event envelope matches \u201cOutbound SSE Event Contract (sa01-v1)\u201d. - Event types: <code>assistant.thinking</code>, <code>assistant.stream</code>, <code>assistant.final</code>, <code>tool.start</code>, <code>tool.result</code>, <code>uploads.progress</code>.</p> <p>Phased delivery (done vs remaining) - Done: single Gateway surface; UI served under <code>/ui</code>; session durability; outbox + memory write outbox; settings sections + audit logging. - Remaining (high\u2192medium):   - UI tool lifecycle de-duplication when <code>tool.start</code> lacks <code>request_id</code> but <code>tool.result</code> includes it   - Uploads progress single-block per file and render \u201cUploaded:\u201d when only a final \u201cdone\u201d event arrives   - Settings modal Alpine init race under automation; ensure modal opens reliably on first click   - Provider credential presence hints to enable SSE assistant tests</p> <p>Acceptance for this addendum - No legacy UI calls appear (<code>/v1/ui/poll</code>, <code>/v1/csrf</code>) - Uploading small files shows \u201cUploaded:\u201d even without intermediate progress - Tool start\u2192result yields a single \u201cTool: \u201d block with result body - Settings modal renders sections on first open in CI/local"},{"location":"roadmap/canonical-roadmap/#2025-11-01-update-long-message-stability-thought-bubble-parity-and-canonical-memory-apis","title":"2025-11-01 Update \u2014 Long-message stability, Thought-bubble parity, and Canonical Memory APIs","text":"<p>Scope - Fix UI collapse/flip during very long assistant streams by adopting a streaming-safe renderer and CSS containment. - Achieve visual/behavioral parity for thought bubbles (ephemeral thinking hint + final thoughts rows) with the 7001 demo. - Canonicalize Memory Dashboard endpoints under <code>/v1/memories/*</code> and rewire the UI to them (remove reliance on legacy <code>/memory_dashboard</code>).</p> <p>What changed (code) - Web UI streaming safety:   - During streaming, render assistant deltas without markdown/KaTeX (<code>response_stream</code> message type) and throttle DOM updates to ~30fps.   - On final event, perform a single markdown+KaTeX render to replace the streaming content.   - CSS containment and transition disabling applied to streaming message containers to prevent layout thrash. - Thought bubble parity:   - Ephemeral thinking bubble lifecycle tightened (show on thinking, clear on final/error/reset); visuals aligned to golden where possible.   - \u201cShow thoughts\u201d toggle instantly affects <code>.msg-thoughts</code>; persistence remains under <code>/v1/ui/preferences</code>. - Memory Dashboard APIs:   - New canonical routes:     - <code>GET /v1/memories/current-subdir</code>     - <code>GET /v1/memories/subdirs</code>     - <code>GET /v1/memories?memory_subdir=&amp;q=&amp;area=&amp;limit=</code>     - <code>DELETE /v1/memories/{id}</code>     - <code>POST /v1/memories/bulk-delete</code> with <code>{ ids: number[] }</code>     - <code>PATCH /v1/memories/{id}</code> with <code>{ edited: { content?, metadata? } }</code>   - UI store (<code>memory-dashboard-store.js</code>) rewired to these endpoints.   - Legacy <code>/memory_dashboard</code> kept as a compatibility shim; slated for removal post cutover.</p> <p>Tests added - Playwright: <code>thought.bubbles.and.toggles.spec.ts</code>   - Sends a message, waits for assistant to finish (progress empty), clicks all <code>.kvps-row.msg-thoughts .kvps-val</code> rows if present, then flips Show thoughts/JSON/utils and performs best\u2011effort DOM visibility checks.</p> <p>Acceptance criteria - Long streaming replies do not cause UI collapse or flipping; progress bar remains coherent; no errors logged. - Thought bubbles (ephemeral + final thoughts) match the golden UI\u2019s look and timing; toggles flip visibility instantly and persist via preferences. - Memory Dashboard uses <code>/v1/memories/*</code> endpoints in the UI; basic flows (list/search/delete/update) function; no UI polling.</p> <p>Next sprints (focused) - Sprint A (stability):   - Finalize streaming renderer (metrics: frame times under load), add throttling guardrails and optional raf-based coalescing.   - Extend Playwright with a \u201clong message torture test\u201d (markdown + code + LaTeX + images) and record video/trace. - Sprint B (parity polish):   - Copy exact bubble CSS from golden assets and unify styles; add structural assertions for bubble elements.   - Expand toggles test to verify persistence across reload and themes. - Sprint C (memory UX):   - Add pagination/filter UX assertions; integrate optional delete policy checks; consider SSE-invalidations for live updates.</p>"},{"location":"roadmap/canonical-roadmap/#2025-11-02-update-dualmode-parity-golden-7001-vs-local-v1-and-test-matrix","title":"2025-11-02 Update \u2014 Dual\u2011mode Parity (Golden 7001 vs Local /v1) and Test Matrix","text":"<p>Scope - Establish a two-mode UI test strategy to compare our local canonical UI (served by Gateway at :21016 under /ui and backed by /v1 APIs) against the golden reference running on port 7001 (which uses legacy routes and serves UI at the root). - Ensure our local Web UI achieves UX/CSS/behavioral parity with the golden demo while retaining strict SSE-only and /v1-only contracts locally.</p> <p>What changed (tests and harness) - Playwright config already honors WEB_UI_BASE_URL; we added a GOLDEN_MODE flag. When GOLDEN_MODE=1 or WEB_UI_BASE_URL contains :7001, tests relax network assertions and switch to more permissive selectors. - Updated tests:   - <code>network.no-legacy.spec.ts</code>: now skipped in GOLDEN_MODE (golden legitimately makes legacy calls).   - <code>parity.spec.ts</code>: detects GOLDEN_MODE and (a) does not assert <code>/v1/session/message</code> POST, (b) uses robust input selectors, (c) gates sidebar session controls to local-only.   - <code>long.stream.torture.spec.ts</code>: made completion checks robust (handles cases where progress bar text may not clear even though streaming completes) and avoids strict locator ambiguity.   - <code>chat.reset.single-reply.spec.ts</code> and <code>controls.sidebar.sessions.spec.ts</code>: hardened selectors and timeouts.   - New: <code>golden.smoke.spec.ts</code> \u2014 a lenient smoke for golden: loads the page, types into the first text input/textarea, sends via Enter/click and asserts a visible DOM change; no /v1 assumptions.</p> <p>How to run - Local (canonical /v1):   - <code>WEB_UI_BASE_URL=http://127.0.0.1:21016/ui npx playwright test</code> - Golden (port 7001):   - <code>WEB_UI_BASE_URL=http://127.0.0.1:7001 GOLDEN_MODE=1 npx playwright test specs/golden.smoke.spec.ts specs/parity.spec.ts</code></p> <p>Acceptance gates for parity - Visual/behavioral parity: thought bubble timing, streaming smoothness, toggle interactions, session controls UX, and general layout should match golden 7001. - Local strictness retained: no polling or CSRF endpoints; only <code>/v1/*</code> routes are allowed; SSE-only stream path.</p> <p>Status (as of 2025-11-02) - Local UI suite: PASS (all critical specs green; env-dependent scheduler/tools smokes are skipped). Long-stream torture stabilized (no transient shrink), multi-turn chats stable, no duplicate replies after reset. Memory Dashboard rewired to <code>/v1/memories/*</code>. - Golden checks: PASS for <code>golden.smoke</code> and adapted <code>parity.spec</code> against <code>http://127.0.0.1:7001</code>. - Python E2E tool flow: PASS (1 test, 1 warning about custom mark; to be registered later). - Known pending items:   - Expand golden run to include long-stream and thought-bubbles with selector adapters (some selectors differ at 7001 root).   - CSS pixel parity for thought-bubble icons/spacing; add optional screenshot assertions.</p> <p>Next steps 1) Extend GOLDEN_MODE adapter helpers (shared util) and apply to the remaining specs so the entire smoke set can run against 7001. 2) Produce a short \u201cparity delta\u201d report (selectors/CSS/behavior) from a side-by-side run and implement the CSS polish locally. 3) Add CI jobs for both matrices: local canonical (/v1-only) and golden-compat (selector-only, network relaxed).</p> <p>Quality gates snapshot - Build: PASS (dev stack up). - Lint/Typecheck: PASS (no new issues introduced by spec edits). - Tests: Local UI suite PASS; Golden subset PASS; E2E tool flow: FAIL (to be triaged).</p>"},{"location":"roadmap/canonical-roadmap/#2025-11-08-update-streaming-centralization-event-bus-sse-hardening","title":"2025-11-08 Update \u2014 Streaming Centralization (Event Bus) &amp; SSE Hardening","text":"<p>Scope - Consolidate all UI real-time updates behind a single client stream and event bus; eliminate residual polling (scheduler, memory dashboard) and ship production-grade reconnection, heartbeats, and backpressure.</p> <p>What changed (current state) - Chat: migrated from legacy polling to SSE in <code>webui/index.js</code>. CSRF fetch removed from <code>webui/js/api.js</code>. Confirmed no <code>/poll</code> references in chat code. - Gap: other panels (scheduler, memory dashboard) still use polling; no shared client event bus; reconnect/backoff minimal; no heartbeat stall detection.</p> <p>Design decisions - Single stream client: <code>webui/js/stream.js</code> wraps <code>EventSource</code> with jittered backoff, Last-Event-ID, heartbeat tracking, and stall detection \u2192 emits standardized UI events onto a bus. - Central event bus: <code>webui/js/event-bus.js</code> is a minimal pub/sub with topic strings; domain stores subscribe and update state. - Canonical UI event schema (additive on top of existing assistant/tool events):   - <code>ui.status.progress</code> \u2014 progress updates for long-running work (payload: { id, label?, pct?, stage?, details? }).   - <code>ui.status.paused</code> \u2014 conversation/session paused/resumed state (payload: { session_id, paused, reason? }).   - <code>ui.notification</code> \u2014 transient notifications/toasts (payload: { level: info|warn|error, message, code?, href? }).   - <code>session.list.update</code> \u2014 session/task list invalidations or diffs (payload: { added?, removed?, changed? }).   - <code>task.list.update</code> \u2014 task/scheduler invalidations or diffs (payload mirrors above). - Domain stores: <code>messagesStore</code>, <code>notificationsStore</code>, <code>progressStore</code>, <code>sessionsStore</code>, <code>tasksStore</code> consume bus events; views bind to stores. Messages continue to handle <code>assistant.delta/complete</code>, <code>tool.start/result</code>.</p> <p>Server updates (Gateway) - Extend SSE publisher to include the canonical UI events above where applicable (progress/paused/notifications and list invalidations). Continue emitting <code>heartbeat</code> at a fixed cadence. - Support <code>Last-Event-ID</code> to help reconnect resume. Expose <code>X-Accel-Buffering: no</code> and appropriate cache headers.  - Emit lightweight invalidation hints alongside normal payloads:    - <code>task.list.update</code> when task-related events occur (e.g., <code>task.*</code>, or <code>tool.result</code>/<code>assistant.final</code> with <code>metadata.task_id</code>).    - <code>memory.list.update</code> for <code>memory.*</code> events.    These hints allow SSE-driven UI list refreshes without polling.</p> <p>Reliability - Reconnect/backoff: full jitter exponential backoff with max cap; fast-path on immediate user action (send message) to force a quick reconnect attempt. - Heartbeat stall detection: UI banner after N missed heartbeats; auto-retry in background; allow manual retry button. - Backpressure: coalesce frequent progress updates (throttle to ~10\u201320Hz) and only re-render at animation frames.</p> <p>Testing - Playwright: <code>stream.reconnect.and.banner.spec.ts</code> (disconnect \u2192 banner \u2192 auto-recover), <code>no-poll.anywhere.spec.ts</code> (assert no network calls to legacy/poll endpoints), <code>scheduler.memory.bus.spec.ts</code> (live updates via SSE, no polling), long-stream remains green. - Pytest API: contract tests for new UI event types (<code>ui.status.progress</code>, <code>ui.notification</code>) and <code>Last-Event-ID</code> resume.  - Pytest API: assert presence of <code>task.list.update</code>/<code>memory.list.update</code> hint events during representative flows.</p> <p>Acceptance criteria - No polling in any UI module (chat, scheduler, memory dashboard, settings), verified via Playwright network assertions. - Stream client reconnects with jittered backoff; heartbeat stall triggers an offline banner and recovers automatically. - Session/task/memory views update via SSE invalidations or diffs; manual refresh still available but not required. - Large histories remain responsive: either virtualization or message trimming is enabled without breaking grouping.</p> <p>Status / Next steps - Done: chat SSE, CSRF removal. In progress: planning and roadmap consolidation for central event bus. - Next: implement <code>event-bus.js</code> and <code>stream.js</code>, refactor <code>index.js</code> to use the bus, extend Gateway to emit canonical UI events, migrate scheduler and memory dashboard stores, add tests.</p>"},{"location":"roadmap/canonical-roadmap/#2025-11-09-addition-unified-configuration-security-secrets-hardening-roadmap-m0m12","title":"2025-11-09 Addition \u2014 Unified Configuration / Security / Secrets Hardening Roadmap (M0\u2013M12)","text":"<p>This section merges prior architectural, security, and settings analyses into a single phased plan. It focuses on eliminating schema ambiguity, centralizing provider credentials, enforcing policy gates, and delivering auditable, deterministic configuration flows.</p>"},{"location":"roadmap/canonical-roadmap/#guiding-principles","title":"Guiding Principles","text":"<ul> <li>Single authoritative write path for UI + runtime settings (no scattered direct table writes).</li> <li>Provider credentials encrypted at rest; rotation possible without code changes.</li> <li>All settings changes produce masked audit diffs and Kafka <code>config_updates</code> events.</li> <li>Read paths are cached, versioned, and fail closed when invariants break.</li> <li>Strict separation of concerns: registry (metadata), store (persistence), resolver (runtime projection), policy (OPA/OpenFGA), secrets backend (encryption / rotation).</li> </ul>"},{"location":"roadmap/canonical-roadmap/#milestone-overview","title":"Milestone Overview","text":"Milestone Focus Key Artifacts Primary Risks Acceptance Snapshot M0 Instrument &amp; Inventory Route catalog, metrics, audit diff schema Blind spots may hide unsafe flows All settings endpoints mapped &amp; emitting metrics; audit diff schema validated M1 Read-only Registry <code>SettingsRegistry</code> (in-memory typed view) Drift between registry &amp; DB snapshot Registry stable across test runs; no write methods M2 Typed Schemas &amp; Validation Pydantic models per domain (<code>ui</code>, <code>llm</code>, <code>tooling</code>, <code>auth</code>, <code>limits</code>) Legacy untyped writes break All incoming writes validated; invalid payload \u2192 422 with field map M3 Transactional Write Path Single POST <code>/v1/ui/settings/sections</code> \u2192 domain split + audit diff Race conditions, partial writes Atomic commit; audit diff includes masked secrets; event published M4 Secrets Backend &amp; Rotation <code>SecretsBackend</code> with key version, Fernet or AES-GCM envelope Lost key = unusable creds Key version recorded; rotation script passes canary test M5 Auth Hardening Enforce <code>REQUIRE_AUTH</code>, internal token depreciation, JWT scopes Lock-out on misconfig All protected endpoints reject unauthenticated calls in strict mode M6 Provider Normalization Service <code>_normalize_llm_base_url</code> extracted &amp; consolidated Hidden divergence in workers Workers no longer attempt normalization; 0 base_url overrides M7 Drift Detection &amp; Health Compare registry vs DB vs cache, expose <code>/v1/config/drift</code> False positives cause noise p95 drift check &lt; 50ms; health gating accurate M8 Observability Expansion Structured logs, span attributes for config writes PII leakage risk No secrets in logs; span shows domain + diff hash M9 Key Rotation Automation Cron/CI pipeline rotates + re-encrypts stale versions Rotation failure mid-cycle Dry-run validation; rollback key retained until success M10 Multi-Tenant Partitioning Tenant-specific overrides with fallback precedence Cross-tenant bleed Override precedence documented; tests prove isolation M11 Policy-Driven Dynamic Limits Per-tenant rate/tool limits enforced via OPA / FGA Policy latency Cache TTL ensures p95 policy check &lt; 10ms M12 Externalized Config Packages Export minimal config bundle for air-gapped analysis Incomplete masking Bundle excludes raw secrets; diffs stored with masked placeholders"},{"location":"roadmap/canonical-roadmap/#critical-path-why-this-order","title":"Critical Path (Why This Order)","text":"<ol> <li>M0\u2013M2 build visibility &amp; strong typing before altering write mechanics.</li> <li>M3 introduces atomic writes; must land before secrets centralization (M4) so secrecy is applied once.</li> <li>M4\u2013M5 secure sensitive data &amp; enforce auth; prevents later expansions from amplifying risk.</li> <li>M6 removes normalization duplication to avoid drift when registry evolves.</li> <li>M7\u2013M8 deepen detection &amp; traceability; required before adding rotation cadence (M9).</li> <li>M10\u2013M11 extend multi-tenancy &amp; dynamic policy safely atop hardened core.</li> <li>M12 packages external consumption after stability and security layers mature.</li> </ol>"},{"location":"roadmap/canonical-roadmap/#detailed-milestones-acceptance-criteria","title":"Detailed Milestones &amp; Acceptance Criteria","text":""},{"location":"roadmap/canonical-roadmap/#m0-inventory-instrumentation","title":"M0 \u2013 Inventory &amp; Instrumentation","text":"<p>Scope: Enumerate every settings/credentials route, add Prometheus counters/histograms, define audit diff schema (<code>old</code>, <code>new</code>, <code>mask</code>, <code>domain</code>, <code>changed_at</code>). Acceptance: - Route catalog file (<code>docs/technical-manual/settings-routes.md</code>) lists all verbs &amp; auth scopes. - Metrics: <code>settings_write_total</code>, <code>settings_write_latency_seconds</code>, <code>settings_read_total</code> present. - Audit diff emitted for each write with masked secret fields (pattern: value replaced by <code>****</code> length-preserving mask).</p>"},{"location":"roadmap/canonical-roadmap/#m1-read-only-registry","title":"M1 \u2013 Read-only Registry","text":"<p>Scope: Implement <code>SettingsRegistry</code> that loads typed domains on startup and caches them (ETag + version integer). Acceptance: - Registry object accessible via dependency injection; no mutation methods. - Unit test ensures repeated access returns same instance; mismatch between DB &amp; registry triggers warning.</p>"},{"location":"roadmap/canonical-roadmap/#m2-domain-schemas-validation","title":"M2 \u2013 Domain Schemas &amp; Validation","text":"<p>Scope: Introduce domain Pydantic models; convert loose JSON sections into structured <code>UiSettings</code>, <code>LlmSettings</code>, <code>ToolingSettings</code>, <code>AuthSettings</code>, <code>LimitsSettings</code>. Acceptance: - Invalid field triggers 422 with <code>detail: [{loc, msg, type}]</code>. - 100% coverage for schema conversions; legacy untyped write path blocked.</p>"},{"location":"roadmap/canonical-roadmap/#m3-transactional-write-path","title":"M3 \u2013 Transactional Write Path","text":"<p>Scope: Replace multi-endpoint writes with single sectioned POST; perform domain validation, diff generation, atomic commit, event publish. Acceptance: - Single commit covers all domains; partial failure rollback test passes. - Kafka <code>config_updates</code> event includes <code>version</code>, <code>domains_changed</code>, <code>diff_hash</code>.</p>"},{"location":"roadmap/canonical-roadmap/#m4-secrets-backend-rotation","title":"M4 \u2013 Secrets Backend &amp; Rotation","text":"<p>Scope: Implement encryption with key versioning; support key rotation CLI (<code>rotate_key.py</code>) that re-encrypts values. Acceptance: - Secret record stores <code>{ciphertext, key_version, updated_at}</code>. - Rotation increases key version and preserves decrypt ability; canary decrypt test passes.</p>"},{"location":"roadmap/canonical-roadmap/#m5-auth-hardening","title":"M5 \u2013 Auth Hardening","text":"<p>Scope: Enforce token validation even if <code>REQUIRE_AUTH</code> previously false; remove deprecated internal token bypass for non-critical endpoints; scope-based access. Acceptance: - Auth off path removed (except explicitly flagged health endpoints). - Restricted endpoint test unauthorized returns 401/403 with structured body.</p>"},{"location":"roadmap/canonical-roadmap/#m6-provider-normalization-service","title":"M6 \u2013 Provider Normalization Service","text":"<p>Scope: Centralize model/base_url normalization logic; workers send only high-level model identifiers. Acceptance: - No calls in codebase to legacy normalization helper outside service. - LLM invoke logs contain normalized provider fields.</p>"},{"location":"roadmap/canonical-roadmap/#m7-drift-detection","title":"M7 \u2013 Drift Detection","text":"<p>Scope: Periodic comparison between DB snapshot, registry cache, and last event version. Acceptance: - <code>/v1/config/drift</code> returns status <code>ok|warning|critical</code> and counts of mismatches. - Simulated drift triggers <code>warning</code> and publishes alert metric.</p>"},{"location":"roadmap/canonical-roadmap/#m8-observability-expansion","title":"M8 \u2013 Observability Expansion","text":"<p>Scope: Add structured logging fields <code>config_version</code>, <code>domains_changed</code> to write spans; propagate trace context. Acceptance: - Logs verified free of secret raw values; diff hashes present. - Trace viewer shows <code>config.write</code> span with attributes.</p>"},{"location":"roadmap/canonical-roadmap/#m9-key-rotation-automation","title":"M9 \u2013 Key Rotation Automation","text":"<p>Scope: Scheduled job or pipeline step rotates keys monthly; dry-run mode and rollback support. Acceptance: - Dry-run outputs prospective new key version mapping. - Rotation job updates all rows; post-rotation decrypt validation 100%.</p>"},{"location":"roadmap/canonical-roadmap/#m10-multi-tenant-partitioning","title":"M10 \u2013 Multi-Tenant Partitioning","text":"<p>Scope: Per-tenant overrides layered on global base; precedence (tenant \u2192 global) enforced. Acceptance: - Tenant override read returns merged settings; removing override reverts to global. - Cross-tenant access attempt blocked &amp; audited.</p>"},{"location":"roadmap/canonical-roadmap/#m11-policy-driven-dynamic-limits","title":"M11 \u2013 Policy-Driven Dynamic Limits","text":"<p>Scope: Limits (rate, tool concurrency) enforced via cached policy decisions; registry updates invalidate caches. Acceptance: - Limit breaches return 429 with structured detail. - p95 policy check latency &lt; 10ms under load test.</p>"},{"location":"roadmap/canonical-roadmap/#m12-externalized-config-bundle","title":"M12 \u2013 Externalized Config Bundle","text":"<p>Scope: Export sanitized config bundle (<code>config_bundle_v&lt;version&gt;.tar.gz</code>) for air-gapped review. Acceptance: - Bundle excludes secrets; masked placeholders present; signature file SHA256 verified. - Import tool validates signature and reconstructs registry snapshot.</p>"},{"location":"roadmap/canonical-roadmap/#risks-mitigations","title":"Risks &amp; Mitigations","text":"<ul> <li>Schema Migration Complexity (M2): Provide dual-read fallback for one release; log warnings for legacy format.</li> <li>Rotation Failures (M4/M9): Canary encryption + staged rollout; keep previous key version until success metrics confirmed.</li> <li>Policy Latency (M11): Cache decisions with TTL + event-driven invalidation; circuit breaker on policy backend.</li> <li>Drift False Positives (M7): Multi-source hash comparison and threshold before alerting.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#metrics-to-track-throughout","title":"Metrics to Track Throughout","text":"<ul> <li><code>settings_validation_errors_total</code></li> <li><code>config_updates_events_total</code></li> <li><code>secrets_rotation_success_total</code> / <code>secrets_rotation_failure_total</code></li> <li><code>config_drift_checks_total</code> and <code>config_drift_mismatches_total</code></li> <li><code>policy_decision_latency_seconds</code></li> <li><code>settings_write_audit_masked_total</code></li> </ul>"},{"location":"roadmap/canonical-roadmap/#immediate-next-action-you-are-here","title":"Immediate Next Action (You are here)","text":"<p>Proceed with M0: add route catalog + baseline metrics in code. After merging this section, implement instrumentation and open a short PR if required.</p>"},{"location":"roadmap/canonical-roadmap/#2025-11-09-update-master-roadmap-consolidation-parallel-sprint-plan","title":"2025-11-09 Update \u2014 Master Roadmap Consolidation &amp; Parallel Sprint Plan","text":"<p>This section consolidates the architectural roadmap with feature-flag strategy, streaming hardening, semantic recall, unified configuration/security, and release cadence. It defines parallel sprint execution. This document remains the single source of truth.</p>"},{"location":"roadmap/canonical-roadmap/#integrated-master-tracks","title":"Integrated Master Tracks","text":"<ol> <li>Capability Registry &amp; Best Mode (feature flags \u2192 descriptors, profiles, health-aware degrade)</li> <li>Streaming &amp; UI Parity (single SSE stream, client event bus, zero polling, reconnection robustness)</li> <li>Semantic Memory &amp; Recall (embeddings ingestion, query-time similarity ranking, caching, recall metrics)</li> <li>Unified Config &amp; Secrets (M0\u2013M12 milestones: instrumentation, schemas, transactional writes, encryption, rotation, drift, policy limits)</li> <li>Tool Catalog &amp; Runtime Config (Gateway-owned definitions, per-tenant flags, audited changes)</li> <li>Reliability &amp; Backpressure (consumer lag gauges, circuit breakers, alert templates)</li> <li>LLM Model/Profile Centralization (Gateway sole authority; workers stop sending base_url)</li> <li>Auditing &amp; Compliance (masked diff events, traceability, export tooling)</li> </ol>"},{"location":"roadmap/canonical-roadmap/#capability-descriptor-schema-to-be-implemented","title":"Capability Descriptor Schema (to be implemented)","text":"<p>Fields: <code>key</code>, <code>description</code>, <code>default_enabled</code>, <code>profiles: {minimal|standard|enhanced|max}</code>, <code>dependencies</code>, <code>degrade_strategy (auto|manual|none)</code>, <code>cost_impact (low|medium|high)</code>, <code>metrics_key</code>, <code>tags (observability|security|performance)</code>. State machine: <code>enabled</code> \u2192 (<code>degraded</code> | <code>disabled</code>). Transitions audited.</p>"},{"location":"roadmap/canonical-roadmap/#profiles-default-enhanced","title":"Profiles (Default = enhanced)","text":"<p>minimal: critical path only (chat, memory write-through). standard: + basic tools, metrics, auth hardening. enhanced (default): all production features including embeddings ingestion and scheduler. max: enhanced + experimental (semantic recall, advanced caching) gated behind stability checks.</p>"},{"location":"roadmap/canonical-roadmap/#parallel-sprint-plan","title":"Parallel Sprint Plan","text":"<p>Sprint 0 (Planning &amp; Instrumentation, 2\u20133 days, parallel) - Feature descriptor schema &amp; examples documented. - Unified Config M0: route inventory + metrics/audit diff schema. - SSE event bus interface + canonical UI event list (progress, notification, list updates, heartbeat). Exit: Documentation merged; no code side-effects; acceptance criteria clarified.</p> <p>Sprint 1 (Enable Best Mode Safely, 4\u20136 days) - Implement <code>features</code> registry module + metrics + <code>/v1/features</code> diagnostics. - Refactor env flag lookups to registry (gateway, session_repository, embeddings helper). - Implement SSE client bus (chat only) with jittered reconnect + heartbeat stall banner. - Semantic recall design &amp; cache strategy (vector similarity approach, LRU/hash plan). - Docs + tests (registry unit tests, Playwright no-poll chat spec). Exit: Enhanced profile active by default; registry metrics visible; chat polling eliminated.</p> <p>Sprint 2 (Semantic Recall &amp; Full Streaming, 1\u20132 weeks) - Implement recall API (embed query \u2192 top-k memory slice). Hybrid filters (session, recency). - Embedding cache implementation (LRU + normalized hash key). - Migrate scheduler &amp; memory dashboard to SSE bus (remove all polling). - Add consumer lag gauges &amp; circuit breakers; alert rule templates drafted. Exit: Zero UI polling; recall latency &amp; hit metrics published; alert templates ready.</p> <p>Sprint 3 (Config &amp; Secrets Hardening, 1\u20132 weeks) - M1\u2013M4: Typed domain schemas, transactional writes, secrets encryption, rotation CLI. - Centralize LLM profile normalization; workers stop sending base_url. Exit: Atomic masked writes; secrets encrypted; normalized profile flow validated.</p> <p>Sprint 4 (Policy, Multi-Tenancy, Limits, 2 weeks) - Auth hardening (REQUIRE_AUTH); OPA/OpenFGA gates for conversation/tool/memory. - Multi-tenant override precedence; dynamic limits (rate/tool concurrency). - Drift detection endpoint &amp; health gating. Exit: Policy decisions fast (&lt;10ms p95); tenant isolation tests green; drift checks stable.</p> <p>Sprint 5 (Parity Polish &amp; Release Cadence, 1 week) - Golden vs canonical UI screenshot diff optional gating. - CI matrices (canonical + golden mode); release tagging &amp; automated changelog. - Observability dashboards updated (feature states, recall metrics, circuit breaker status). Exit: CI green across matrices; v0.3.0 (semantic recall) tagged; dashboards live.</p>"},{"location":"roadmap/canonical-roadmap/#immediate-action-items-start-now","title":"Immediate Action Items (Start Now)","text":"<ul> <li>Write feature descriptor schema doc (registry definitions &amp; examples).</li> <li>Begin Unified Config M0 metrics &amp; audit diff instrumentation design.</li> <li>Draft SSE event bus module interfaces (client &amp; server publish contract).</li> </ul>"},{"location":"roadmap/canonical-roadmap/#key-success-metrics","title":"Key Success Metrics","text":"<ul> <li>0 raw <code>os.getenv</code> feature lookups after Sprint 1 (lint rule enforcement).</li> <li>UI network log shows no polling endpoints after Sprint 2.</li> <li>Recall p95 latency &lt; 150ms local; cache hit-rate &gt; 70% for repeated similar queries.</li> <li>Secrets encryption coverage 100%; rotation dry-run passes monthly.</li> <li>Policy decision latency p95 &lt; 10ms; drift false positives &lt; 1/week.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#risk-mitigations-snapshot","title":"Risk Mitigations Snapshot","text":"<ul> <li>Registry Rollout: dual path (env var fallback) until Sprint 1 exit.</li> <li>Recall Accuracy: shadow evaluation before enabling for all profiles.</li> <li>Secrets Rotation: staged rotation with canary decrypt &amp; rollback key retention.</li> <li>Policy Latency: local cache TTL + event-driven invalidation; circuit breaker fallback to deny with clear error.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#release-cadence-versioning","title":"Release Cadence &amp; Versioning","text":"<ul> <li>v0.1.0-centralised (architecture) \u2192 v0.2.0-streaming-bus \u2192 v0.3.0-semantic-recall \u2192 v0.4.0-config-secrets \u2192 v0.5.0-multi-tenancy.</li> <li>Each release: automated changelog (diff of feature states + schema versions) &amp; audit snapshot.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#governance-note","title":"Governance Note","text":"<p>All roadmap modifications must update this file first; PRs referencing roadmap changes include a diff of this section. Sprint exit reviews confirm metrics &amp; acceptance criteria before advancing profile defaults.</p> <p>\u2014 End of 2025-11-09 consolidation.</p>"},{"location":"roadmap/canonical-roadmap/#2025-11-09-update-nolegacy-mandate-somabrain-alignment-authoritative","title":"2025-11-09 Update \u2014 No\u2011Legacy Mandate &amp; Somabrain Alignment (Authoritative)","text":"<p>This addendum enforces a strict \u201cNO LEGACY ANYWHERE\u201d policy and reconciles the Somabrain integration blueprint with the current implementation. It defines what \u201clegacy\u201d means, inventories gaps, and lays out a sprinted, prioritized plan to remove every legacy pathway and align all interactions through the Somabrain HTTP surface.</p>"},{"location":"roadmap/canonical-roadmap/#zerolegacy-definition-nonnegotiable","title":"Zero\u2011Legacy Definition (non\u2011negotiable)","text":"<ul> <li>No stub/shim code paths that bypass real policy/security (e.g., placeholder OPA that always allows).</li> <li>No duplicate or competing implementations of the same concern (feature flags, Kafka producer, config normalization, health endpoints).</li> <li>No direct environment flag checks outside the central Feature Registry and Settings.</li> <li>No deprecated endpoints, polling loops, or hidden fallbacks; SSE\u2011only real\u2011time; one canonical API surface.</li> <li>No ambiguous integration boundaries: all SomaBrain interactions occur via its HTTP API at <code>SOMA_BASE_URL</code>.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#somabrain-integration-boundary-final","title":"Somabrain Integration Boundary (final)","text":"<ul> <li>Boundary: HTTP only. Do not import Somabrain internal Python modules in\u2011process; use the HTTP service surface consistently.</li> <li>Required endpoints (contract):</li> <li>Health: <code>GET {SOMA_BASE_URL}/healthz</code> (primary), <code>GET /health</code> accepted as legacy alias.</li> <li>Learning/Weights: <code>GET /v1/weights</code>, <code>POST /v1/weights/update</code>.</li> <li>Context Builder: <code>POST /v1/context/build</code>.</li> <li>Tenant Feature Flags: <code>GET /v1/flags/{tenant}/{flag}</code>.</li> <li>Memory: <code>POST /v1/memory/remember</code>, <code>POST /v1/memory/link</code>, <code>POST /v1/plan/suggest</code> (where applicable).</li> <li>Recall: <code>POST /v1/recall/query</code> (tenant\u2011scoped).</li> </ul>"},{"location":"roadmap/canonical-roadmap/#legacy-inventory-to-be-removed-or-unified","title":"Legacy Inventory (to be removed or unified)","text":"<ul> <li>(Removed) Legacy OPA placeholder middleware (<code>python/integrations/opa_middleware.py</code>) has been excised. Future policy enforcement will use a real HTTP adapter with selective authorization semantics.</li> <li>Duplicate health endpoints (<code>/health</code>, <code>/healthz</code>) and mixed targets (<code>/health</code> vs <code>/healthz</code>) \u2192 converge to <code>/healthz</code> in Gateway; probe Somabrain <code>/healthz</code> first; keep <code>/health</code> as alias only.</li> <li>Env\u2011flag checks scattered across code (<code>os.getenv(\"SA01_ENABLE_*\"</code>, <code>ENABLE_*</code>) \u2192 replace with Feature Registry lookups; add lint rule to forbid direct getenv for flags.</li> <li>Dual outbox/Kafka producers across services vs Somabrain\u2019s producer \u2192 keep local outbox pattern but unify headers/schema and health adaptation; centralize Kafka publisher behind one adapter (no competing producers).</li> <li>Local feature flags vs tenant flags in Somabrain Redis \u2192 add tenant override layer calling Somabrain <code>GET /v1/flags/{tenant}/{flag}</code> with TTL cache; registry provides defaults only.</li> <li>Any unused legacy modules (gRPC memory client references, polling UI calls, legacy credentials routes) \u2192 delete.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#enforcement-principles","title":"Enforcement Principles","text":"<ul> <li>Single source per concern: one place to evaluate policy, one publisher API, one feature flag gateway, one health probe path.</li> <li>Fail\u2011closed by default for security\u2011relevant flows (policy/memory/tool writes); surface clear denies and audit entries.</li> <li>Observability for every removed legacy pathway: add counters to ensure it stays at zero usage.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#prioritized-sprint-plan-legacy-eradication","title":"Prioritized Sprint Plan (Legacy Eradication)","text":"<p>Sprint L0 \u2014 Policy &amp; Health Hardening (3 days) - Replace OPA stub with HTTP policy adapter calling Somabrain policy endpoint; wire into Gateway middleware; measure with <code>auth_requests_total</code>, <code>auth_duration_seconds</code>. - Standardize health: Gateway serves <code>/healthz</code>; probes Somabrain <code>{SOMA_BASE_URL}/healthz</code> (fallback <code>/health</code>); UI banner uses <code>/v1/health</code> aggregate with Somabrain status folded in. - Acceptance: Real denies produce 403 with structured reason; <code>/healthz</code> green only when Somabrain healthy; tests cover allow/deny and degrade.</p> <p>Sprint L1 \u2014 Feature Flags Unification (3 days) - Add tenant override path: Gateway resolves feature flags by calling Somabrain <code>GET /v1/flags/{tenant}/{flag}</code> with 1\u20132s TTL cache; Feature Registry provides profile defaults only. - Add <code>/v1/feature-flags?tenant=...</code> endpoint returning merged view; UI and services consume only this path. - Add lint rule forbidding <code>os.getenv(\"SA01_ENABLE_\"</code> and direct env gating outside the registry. - Acceptance: No direct getenv flag checks; per\u2011tenant flags effective and observable; tests verify TTL cache and fallback behavior.</p> <p>Sprint L2 \u2014 Context &amp; Learning Hooks (4 days) - Inject <code>get_weights()</code> and <code>build_context()</code> into the chat prompt assembly path; record <code>learning_updates_total</code>, <code>learning_context_build_duration_seconds</code>. - Hook reward/TD updates via <code>POST /v1/weights/update</code> on tool outcomes; ensure idempotency and backoff. - Acceptance: Prompts include current weights and Somabrain\u2011built context; rewards post without raising; metrics present.</p> <p>Sprint L3 \u2014 Eventing &amp; Outbox Alignment (4 days) - Centralize Kafka publisher behind one adapter; ensure uniform headers <code>{trace_id, request_id, tenant}</code>; align topics with Somabrain naming; keep durable Postgres outbox. - Add trace injection/extraction on publish/consume flows; expose <code>trace_propagation_errors_total</code>. - Acceptance: WAL/outbox publish path unified; traces link across Gateway\u2194Workers; no duplicate producer classes remain.</p> <p>Sprint L4 \u2014 UI/Streaming Cleanup &amp; Endpoint Purge (3 days) - Verify UI uses SSE only, no polling; remove any legacy <code>/poll</code>, CSRF routes, and deprecated credential endpoints; align to <code>/v1/*</code> and <code>/ui/config.json</code> exclusively. - Remove duplicate/obsolete endpoints and modules; add \u201clegacy usage\u201d counters to confirm zero usage in CI. - Acceptance: Playwright <code>no-legacy-network</code> passes; counters stay zero; grep for legacy routes returns none.</p>"},{"location":"roadmap/canonical-roadmap/#definition-of-done-nolegacy","title":"Definition of Done (No\u2011Legacy)","text":"<ul> <li>Zero stub or dead code for policy, health, flags, eventing, or memory; any former shims deleted.</li> <li>No direct <code>os.getenv</code> feature checks; registry + tenant override only.</li> <li>Single health path (<code>/healthz</code>) in Gateway; Somabrain probed at <code>/healthz</code>.</li> <li>All Somabrain interactions through HTTP client; no internal module imports from Somabrain.</li> <li>UI/network tests show no polling or legacy endpoints; only <code>/v1/*</code> and <code>/ui/*</code> used.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#acceptance-metrics","title":"Acceptance &amp; Metrics","text":"<ul> <li>Security: 100% of protected routes pass through real policy adapter; <code>auth_requests_total{result=\"deny\"}</code> increments on policy failure.</li> <li>Availability: <code>/healthz</code> reflects Somabrain state; outbox/backpressure adapts when Somabrain degrades; alerts fire accordingly.</li> <li>Observability: new metrics present \u2014 <code>learning_updates_total</code>, <code>learning_context_build_duration_seconds</code>, <code>trace_propagation_errors_total</code>, <code>feature_flag_remote_requests_total</code>.</li> <li>Hygiene: CI job runs <code>grep</code>/lint to forbid legacy patterns and fails if found.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#risks-mitigations_1","title":"Risks &amp; Mitigations","text":"<ul> <li>Policy latency: cache allow/deny with short TTL; add circuit breaker \u2192 deny with reason if backend unavailable (configurable fail\u2011open in dev only).</li> <li>Flag staleness: small TTL cache + proactive refresh on write paths; degrade to defaults with audit.</li> <li>Eventing drift: publish contract and headers standardized; add contract tests for topics and headers.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#immediate-next-actions-to-schedule","title":"Immediate Next Actions (to schedule)","text":"<ul> <li>Implement OPA HTTP adapter + middleware swap (L0).</li> <li>Add <code>/v1/feature-flags</code> merged endpoint + tenant override via Somabrain (L1).</li> <li>Wire <code>get_weights</code>/<code>build_context</code> + reward updates into chat/tool flows (L2).</li> </ul> <p>This section is now part of the canonical roadmap. Any refactor or removal tied to the No\u2011Legacy mandate must first update this document with scope, acceptance, metrics, and tests, then proceed to implementation.</p>"},{"location":"roadmap/canonical-roadmap/#2025-11-09-integration-summary-somabrain-full-alignment-clarification","title":"2025-11-09 Integration Summary \u2014 Somabrain Full Alignment (Clarification)","text":"<p>This summary captures the clarified objective: SomaAgent01 fully integrates Somabrain as the upstream AI brain over HTTP while retaining all valuable existing subsystems (gateway, workers, outbox/WAL, Kafka, UI, metrics, auditing). We eliminate only genuine legacy shims or duplicates; we do not discard functioning architecture components.</p>"},{"location":"roadmap/canonical-roadmap/#core-understanding","title":"Core Understanding","text":"<ol> <li>Somabrain is the authoritative service for: learning (weights/reward updates), context building, recall, tenant feature flags, policy enforcement, and memory graph operations.</li> <li>SomaAgent01 remains authoritative for: durable message persistence (Postgres + WAL/outbox), event publishing (Kafka with standardized headers), session orchestration, tool execution sandbox, UI delivery, and composite observability.</li> <li>Interaction mode: strictly HTTP (<code>SOMA_BASE_URL</code>) \u2014 no in\u2011process imports of Somabrain internals to preserve service boundary and upgrade independence.</li> </ol>"},{"location":"roadmap/canonical-roadmap/#retained-subsystems-not-removed","title":"Retained Subsystems (Not Removed)","text":"<ul> <li>Postgres durability (sessions, outbox, WAL, audit, settings).</li> <li>Redis/Kafka usage for caching and event bus.</li> <li>Existing Gateway + Workers patterns (routes, SSE streaming, tool executor) with refactors only where integration demands.</li> <li>Observability stack (Prometheus metrics, alerting templates, structured logging, tracing propagation) extended to include Somabrain call metrics.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#removed-replaced-items-true-legacy-only","title":"Removed / Replaced Items (True Legacy Only)","text":"<ul> <li>Placeholder OPA middleware (local no\u2011op) \u2192 replaced by real HTTP policy adapter against Somabrain policy endpoint.</li> <li>Direct scattered <code>os.getenv</code> feature flag checks \u2192 replaced by Feature Registry + Somabrain tenant overrides.</li> <li>Duplicate health endpoints / inconsistent probes \u2192 converge on unified <code>/healthz</code> logic with Somabrain upstream probe.</li> <li>Any residual polling or deprecated endpoints (CSRF, legacy /poll) in UI \u2192 SSE-only pattern enforced.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#integration-surface-mapping","title":"Integration Surface Mapping","text":"Concern Somabrain Endpoint SomaAgent01 Call Site Notes Health <code>GET /healthz</code> (fallback <code>/health</code>) Gateway <code>/healthz</code>, outbox sync health probe Classify normal/degraded/down; propagate metrics Weights (read) <code>GET /v1/weights</code> Conversation prompt assembly pre-invoke Embed weights into LLM context Weights (update) <code>POST /v1/weights/update</code> Tool/result feedback handler Reward/TD adjustments; idempotent key Context build <code>POST /v1/context/build</code> Conversation loop before LLM invoke Includes \u03c4 temperature &amp; segmentation Recall <code>POST /v1/recall/query</code> Optional recall enrichment stage Tenant/session scoping &amp; top\u2011k memory slice Feature flags <code>GET /v1/flags/{tenant}/{flag}</code> Registry tenant override layer &amp; <code>/v1/feature-flags</code> endpoint TTL cache + fallback to profile defaults Policy (OPA) policy evaluate endpoint (exact path from Somabrain) Gateway middleware &amp; workers (memory/tool actions) Fail\u2011closed unless configured fail\u2011open dev Memory write <code>POST /v1/memory/remember</code> Tool executor &amp; conversation worker write-through Local WAL/outbox remains for durability Memory link <code>POST /v1/memory/link</code> Async post-write linking task Non-blocking; logs failures Plan suggest <code>POST /v1/plan/suggest</code> Optional background suggestion trigger Best-effort enhancement"},{"location":"roadmap/canonical-roadmap/#data-flow-updated","title":"Data Flow (Updated)","text":"<p>User \u2192 Gateway \u2192 (Policy check via Somabrain) \u2192 Conversation Worker \u2192 Context + Weights from Somabrain \u2192 LLM Invoke \u2192 Tool Executor (tool calls) \u2192 Memory write-through (Somabrain) + local WAL \u2192 Kafka publish (standard headers) \u2192 UI SSE stream.</p>"},{"location":"roadmap/canonical-roadmap/#observability-extensions","title":"Observability Extensions","text":"<ul> <li>New metrics: <code>somabrain_request_duration_seconds{endpoint,method}</code>, <code>somabrain_requests_total{endpoint,status}</code>, <code>learning_updates_total{outcome}</code>, <code>learning_context_build_duration_seconds</code>, <code>feature_flag_remote_requests_total{flag,tenant,result}</code>.</li> <li>Alerts: Somabrain error rate spike, policy denial surge, recall latency p95 &gt; threshold.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#reliability-degrade-strategy","title":"Reliability &amp; Degrade Strategy","text":"<ul> <li>If Somabrain recall or context build fails \u2192 degrade: skip enrichment but continue chat; feature state reported as <code>degraded</code>.</li> <li>If policy endpoint unavailable and fail\u2011closed \u2192 deny write/tool ops with clear error; if fail\u2011open (dev only) \u2192 proceed and metric logs decision.</li> <li>If memory write fails upstream \u2192 enqueue in local outbox for retry while preserving local persistence.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#security-enforcement","title":"Security Enforcement","text":"<ul> <li>All memory writes/tool executions behind real policy evaluation; audit includes decision, tenant, action, resource.</li> <li>Feature flags controlling sensitive features (masking, error classification) originate from Somabrain overrides; local defaults only apply when remote unreachable (audited).</li> </ul>"},{"location":"roadmap/canonical-roadmap/#incremental-sprint-execution-high-level","title":"Incremental Sprint Execution (High-Level)","text":"<ul> <li>L0: Real policy adapter + health unification.</li> <li>L1: Tenant feature flag override integration + registry lint enforcement.</li> <li>L2: Weights/context injection + reward updates instrumentation.</li> <li>L3: Eventing/Kafka header standardization + trace linking.</li> <li>L4: UI hygiene and endpoint purge (legacy removal confirmation).</li> </ul>"},{"location":"roadmap/canonical-roadmap/#acceptance-summary","title":"Acceptance Summary","text":"<p>Upon completion of L4: all Somabrain responsibilities are exercised via HTTP endpoints; no stubbed legacy code remains; traces span entire request lifecycle; feature flags reflect tenant overrides; UI streams exclusively over SSE with enriched context and recall (when enabled).</p>"},{"location":"roadmap/canonical-roadmap/#next-immediate-action-post-append","title":"Next Immediate Action (Post-Append)","text":"<p>Start Sprint L0 implementation: swap OPA stub for HTTP adapter, centralized <code>/healthz</code> aggregator including Somabrain classification and new metrics.</p> <p>This integration summary is now appended to the canonical roadmap and governs subsequent implementation decisions.</p>"},{"location":"roadmap/canonical-roadmap/#2025-11-09-feature-expansion-somabrain-driven-additions-readiness-matrix","title":"2025-11-09 Feature Expansion \u2013 Somabrain-Driven Additions &amp; Readiness Matrix","text":"<p>This section enumerates net-new features that leverage Somabrain\u2019s actual HTTP capabilities while preserving SomaAgent01\u2019s durable, evented architecture. Each item lists readiness (Ready / Needs Instrumentation / Needs Extension), dependencies, and target metrics. These augment existing sprints and inform rapid development prioritization.</p>"},{"location":"roadmap/canonical-roadmap/#capability-reference-somabrain-http-endpoints","title":"Capability Reference (Somabrain HTTP Endpoints)","text":"<ul> <li>Weights: <code>GET /v1/weights</code>, <code>POST /v1/weights/update</code></li> <li>Context: <code>POST /v1/context/build</code></li> <li>Feature Flags (tenant): <code>GET /v1/flags/{tenant}/{flag}</code></li> <li>Recall: <code>POST /v1/recall/query</code></li> <li>Policy: policy evaluate endpoint (OPA remote)</li> <li>Memory Ops: <code>POST /v1/memory/remember</code>, <code>POST /v1/memory/link</code></li> <li>Planning: <code>POST /v1/plan/suggest</code></li> </ul>"},{"location":"roadmap/canonical-roadmap/#feature-slate-readiness","title":"Feature Slate &amp; Readiness","text":"Feature Description Readiness Key Dependencies Primary Metric Adaptive Context Orchestration Dynamic prompt shaping using current weights + \u03c4 Ready weights, context.build context_build_duration p95 Reward-Driven Tuning Tool/LLM outcomes \u2192 weights.update Ready weights.update learning_updates_total Proactive Semantic Suggestions Background recall nudges for low-confidence turns Ready (instrument) recall.query suggestion_latency p95 Policy-Gated Auto-Actions Safe auto-execution of low-risk plan steps Instrument policy evaluate, plan.suggest auto_action_denied_total Policy Explainability Console View allow/deny trace details Instrument policy endpoint trace policy_trace_latency Learning KPI Dashboard Surfacing reward volume &amp; precision impact Instrument weights.update logs recall_precision_delta Recall Drift &amp; Vector Health Drift detection &amp; re-embed trigger Extension recall.query + local stats drift_events_total Real-Time Tenant Flag Console Merged effective flags per tenant Ready flags endpoint flag_remote_latency p95 Domain Profiles &amp; Routing Domain-based context/recall partitioning Extension context.build (tags) domain_hit_ratio Memory Graph Explorer Visualize linked memory graph Ready memory.link graph_nodes_rendered Grounded Citations Provenance inline with recall results Instrument (verify payload) recall.query metadata citation_presence_rate Cross-Session Surfacing Suggest similar sessions for continuity Instrument recall.query (tenant scope) session_overlap_suggestions Safety Red Teaming Suite Scheduled adversarial prompt tests Ready policy evaluate redteam_findings_total SLA-Aware Backpressure 2.0 Dynamic outbox/WAL scaling via health &amp; latency budgets Ready healthz, existing WAL backpressure_activation_total Data Retention &amp; Privacy Zones TTL &amp; domain masking enforcement Extension policy + memory.write retention_expiry_success_total Delegated Sub-Tasks (Multi-Agent) Plan decomposition into Celery task chains Ready plan.suggest + Celery delegated_chain_duration Experimentation Framework (A/B weights) Variant weights evaluation + auto promote Extension weights.update (variant tagging) variant_win_rate"},{"location":"roadmap/canonical-roadmap/#rapid-development-priority-impact-feasibility","title":"Rapid Development Priority (Impact \u00d7 Feasibility)","text":"<p>P0 (Ship first \u2013 core value, minimal friction): Adaptive Context, Reward Tuning, Real-Time Tenant Flag Console, SLA-Aware Backpressure 2.0, Proactive Semantic Suggestions (basic), Policy-Gated Auto-Actions (baseline deny/allow). P1: Policy Explainability Console, Learning KPI Dashboard, Grounded Citations, Delegated Sub-Tasks. P2: Recall Drift &amp; Vector Health, Cross-Session Surfacing, Memory Graph Explorer, Data Retention &amp; Privacy Zones. P3: Domain Profiles &amp; Routing, Experimentation Framework.</p>"},{"location":"roadmap/canonical-roadmap/#metrics-to-add","title":"Metrics to Add","text":"<ul> <li><code>somabrain_request_duration_seconds{endpoint,method}</code></li> <li><code>learning_updates_total{outcome}</code></li> <li><code>context_build_duration_seconds</code></li> <li><code>recall_query_duration_seconds</code> / <code>recall_results_total{hit}</code></li> <li><code>auto_actions_total{decision}</code></li> <li><code>policy_trace_requests_total</code> / <code>policy_trace_duration_seconds</code></li> <li><code>flag_remote_requests_total{flag,tenant,result}</code></li> <li><code>drift_events_total{cause}</code></li> </ul>"},{"location":"roadmap/canonical-roadmap/#cross-cutting-concerns","title":"Cross-Cutting Concerns","text":"<ul> <li>Tracing: Ensure spans cover remote Somabrain calls with attributes (endpoint, tenant, status). Link Celery tasks via trace headers.</li> <li>Security: Auto-action feature always policy-gated + audit; never executes without explicit allow.</li> <li>Degrade Modes: Context build failure \u2192 fallback minimal prompt; recall failure \u2192 skip enrichment and mark feature degraded.</li> <li>Caching: Tenant flag lookups cached (TTL 1\u20132s); context and recall not cached (real-time relevance) except optional embedding LRU.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#extension-requirements-somabrain","title":"Extension Requirements (Somabrain)","text":"<ul> <li>Domain tagging in context/recall responses (for domain profile routing).</li> <li>Recall result provenance completeness (source type, id, created_at, confidence score).</li> <li>Policy trace endpoint providing decision path (rules matched, reasons) for explainability.</li> <li>Variant key in weights update payloads to support experimentation.</li> </ul>"},{"location":"roadmap/canonical-roadmap/#integration-risk-matrix","title":"Integration Risk Matrix","text":"Risk Impact Mitigation Policy latency spike Auto-actions stall Local cache + circuit breaker Recall cost growth Token spend increases Adaptive threshold &amp; sampling Drift false positives Unnecessary re-embeds Statistical smoothing (EWMA) Flag endpoint instability Feature gating inconsistency TTL fallback + profile default audit"},{"location":"roadmap/canonical-roadmap/#immediate-follow-up-pre-implementation","title":"Immediate Follow-Up (Pre-Implementation)","text":"<ol> <li>Verify Somabrain recall payload includes provenance fields.</li> <li>Confirm available policy trace capabilities; if absent, spec new endpoint.</li> <li>Define reward mapping (tool result \u2192 scalar/feature vector) for weights updates.</li> <li>Draft metrics additions &amp; gauge cardinality review (avoid high-cardinality labels).</li> </ol> <p>This feature expansion is now part of the canonical roadmap; future development must reference readiness classification and priority tiers before implementation.</p>"},{"location":"roadmap/combined-canonical-roadmap/","title":"Combined canonical roadmap","text":""},{"location":"roadmap/combined-canonical-roadmap/#somabrain-somaagent01-integration-blueprint-sleep-module-excluded","title":"Somabrain \u2194\ufe0f SomaAgent01 Integration Blueprint (Sleep module excluded)","text":"<p>Date:\u202f2025\u201111\u201108 Author:\u202fAgent\u202f0 (assistant)</p>"},{"location":"roadmap/combined-canonical-roadmap/#1-objective","title":"1\ufe0f\u20e3\u202fObjective","text":"<p>Enable SomaAgent01 to fully leverage the Somabrain AI\u2011brain stack (learning core, context builder, OPA policies, Prometheus metrics, Kafka integration, multi\u2011tenant feature flags) while preserving the existing SomaAgent01 architecture (FastAPI gateway, tool\u2011execution engine, UI extensions).</p>"},{"location":"roadmap/combined-canonical-roadmap/#2-sourcecode-verification-proof-of-inspection","title":"2\ufe0f\u20e3\u202fSource\u2011code verification (proof of inspection)","text":"<p>The following Somabrain modules were read directly from the repository and are included verbatim via <code>\u00a7\u00a7include</code>:</p> <ul> <li>Learning core \u2013 <code>/root/somabrain/somabrain/autonomous/learning.py</code> <pre><code>\u00a7\u00a7include(/root/somabrain/somabrain/autonomous/learning.py)\n</code></pre></li> <li>Context builder (temperature \u03c4, segmentation hooks) \u2013 <code>/root/somabrain/somabrain/context/builder.py</code> <pre><code>\u00a7\u00a7include(/root/somabrain/somabrain/context/builder.py)\n</code></pre></li> <li>Runtime configuration (global flags, env handling) \u2013 <code>/root/somabrain/somabrain/config.py</code> <pre><code>\u00a7\u00a7include(/root/somabrain/somabrain/config.py)\n</code></pre></li> <li>OPA middleware (policy enforcement) \u2013 <code>/root/somabrain/somabrain/api/middleware/opa.py</code> <pre><code>\u00a7\u00a7include(/root/somabrain/somabrain/api/middleware/opa.py)\n</code></pre></li> <li>Feature\u2011flag utilities \u2013 <code>/root/somabrain/common/feature_flags.py</code> <pre><code>\u00a7\u00a7include(/root/somabrain/common/feature_flags.py)\n</code></pre></li> <li>Prometheus metrics for learning \u2013 <code>/root/somabrain/somabrain/metrics/__init__.py</code> <pre><code>\u00a7\u00a7include(/root/somabrain/somabrain/metrics/__init__.py)\n</code></pre></li> </ul> <p>Corresponding SomaAgent01 entry points that will be extended:</p> <ul> <li><code>python/api/gateway_stream.py</code> \u2013 receives external HTTP calls.</li> <li><code>python/extensions/message_loop_*</code> \u2013 orchestrates the LLM chat loop.</li> <li><code>python/tools/*</code> \u2013 tool execution framework (a2a_chat, code_execution_tool, document_query, etc.).</li> <li><code>services/gateway/main.py</code> \u2013 FastAPI router that forwards requests to the brain.</li> <li><code>services/tool_executor/execution_engine.py</code> \u2013 sandbox for running tools.</li> </ul>"},{"location":"roadmap/combined-canonical-roadmap/#3-mapping-somabrain-capabilities-to-somaagent01-modules","title":"3\ufe0f\u20e3\u202fMapping Somabrain capabilities to SomaAgent01 modules","text":"Somabrain capability Current SomaAgent01 location Integration point &amp; required change Learning &amp; RetrievalWeights (TD updates, <code>RetrievalWeights</code> model) <code>somabrain.autonomous.learning</code> Import <code>RetrievalWeights</code> into <code>python/extensions/message_loop_prompts_before/_10_initial_message.py</code> and expose via a helper <code>soma_brain.get_weights()</code> used by the chat loop. Context Builder (\u03c4 temperature, segmentation) <code>somabrain.context.builder</code> Add a wrapper <code>soma_brain.build_context()</code> called from <code>python/extensions/message_loop_prompts_before/_20_include_current_datetime.py</code> to inject temperature\u2011scaled soft\u2011max leader selection into the LLM prompt. Feature\u2011flag store (Redis per\u2011tenant) <code>somabrain.common.feature_flags</code> Replace the current <code>somaagent</code> flag lookup (<code>settings.yaml</code>) with <code>get_tenant_flag</code> from Somabrain. OPA policy enforcement <code>somabrain.api.middleware.opa</code> Plug into <code>services/gateway/main.py</code> middleware stack so every request is evaluated against the existing Somabrain policies (<code>ops/opa/policies</code>). Prometheus metrics (learning latency, reward counters) <code>somabrain.metrics.*</code> Register the Somabrain metric collectors in <code>services/gateway/main.py</code> and expose <code>/metrics</code> via the existing Prometheus exporter. Kafka topic creation &amp; outbox <code>somabrain.services.outbox</code> Reuse the Somabrain Kafka producer inside <code>services/tool_executor/execution_engine.py</code> for any tool that needs async event publishing (e.g., <code>document_query</code>, <code>search_engine</code>). Memory persistence (Postgres/Redis) <code>somabrain.storage.db</code> Configure SomaAgent01\u2019s <code>memory_service</code> to use the same DSN (<code>POSTGRES_URL</code>, <code>REDIS_URL</code>) defined in <code>somabrain/config.yaml</code>."},{"location":"roadmap/combined-canonical-roadmap/#4-highlevel-architecture-diagram","title":"4\ufe0f\u20e3\u202fHigh\u2011level architecture diagram","text":"<p><pre><code>+-------------------+      +-------------------+      +-------------------+\n|   SomaAgent01    | ---&gt; |   Somabrain Core  | ---&gt; |   External Infra   |\n| (FastAPI gateway) |      | (learning, OPA,  |      | (Postgres, Redis,  |\n|   + extensions   |      |  Kafka, metrics) |      |  Kafka, Prometheus) |\n+-------------------+      +-------------------+      +-------------------+\n        |                                             |\n        v                                             v\n   UI (webui)                                   Observability (Grafana)\n</code></pre> All calls from the UI flow through the gateway, which now forwards to the Somabrain library via thin wrappers.</p>"},{"location":"roadmap/combined-canonical-roadmap/#5-detailed-implementation-steps-phased-roadmap","title":"5\ufe0f\u20e3\u202fDetailed implementation steps (phased roadmap)","text":""},{"location":"roadmap/combined-canonical-roadmap/#phase-0-foundations-1-week","title":"Phase\u202f0 \u2013 Foundations (1\u202fweek)","text":"<ol> <li>Add Somabrain as a Python dependency <pre><code>pip install -e /root/somabrain\n</code></pre></li> <li>Create a shared <code>somabrain_client</code> package under <code>somaagent01/python/integrations/</code> that imports the needed Somabrain modules and exposes a clean API:    <pre><code># somaagent01/python/integrations/somabrain_client.py\nfrom somabrain.autonomous.learning import RetrievalWeights, update_weights\nfrom somabrain.context.builder import build_context\nfrom somabrain.common.feature_flags import get_tenant_flag\nfrom somabrain.api.middleware.opa import enforce_policy\n__all__ = [\"RetrievalWeights\", \"update_weights\", \"build_context\", \"get_tenant_flag\", \"enforce_policy\"]\n</code></pre></li> <li>Wire OPA middleware into the existing FastAPI app (<code>services/gateway/main.py</code>):    <pre><code>from somaagent01.python.integrations.somabrain_client import enforce_policy\napp.add_middleware(enforce_policy)\n</code></pre></li> <li>Expose Prometheus metrics by importing Somabrain metric registries in <code>services/gateway/main.py</code>.</li> </ol>"},{"location":"roadmap/combined-canonical-roadmap/#phase-1-learning-retrieval-integration-2-weeks","title":"Phase\u202f1 \u2013 Learning &amp; Retrieval integration (2\u202fweeks)","text":"<ol> <li>In <code>python/extensions/message_loop_prompts_before/_10_initial_message.py</code> add a hook to inject current brain weights:    <pre><code>from somaagent01.python.integrations.somabrain_client import RetrievalWeights\ndef inject_weights(context):\n    w = RetrievalWeights.all()\n    context[\"brain_weights\"] = {k: v.to_dict() for k, v in w}\n</code></pre></li> <li>Modify the LLM prompt builder (<code>python/extensions/message_loop_prompts_before/_20_include_current_datetime.py</code>) to call <code>build_context</code> and embed the temperature <code>\u03c4</code>.</li> <li>Update the tool\u2011execution result handler (<code>python/extensions/tool_execute_before/_10_replace_last_tool_output.py</code>) to store any reward feedback into Somabrain\u2019s <code>update_weights</code>.</li> <li>Add unit tests under <code>tests/integration/test_brain_learning.py</code> that verify:</li> <li><code>RetrievalWeights</code> are correctly populated.</li> <li>A dummy reward triggers a TD update without raising.</li> </ol>"},{"location":"roadmap/combined-canonical-roadmap/#phase-2-kafka-outbox-1-week","title":"Phase\u202f2 \u2013 Kafka &amp; Outbox (1\u202fweek)","text":"<ol> <li>Replace the current <code>tool_executor</code> async publish calls with Somabrain\u2019s outbox producer:    <pre><code>from somabrain.services.outbox import OutboxProducer\nproducer = OutboxProducer()\nawait producer.publish(topic=\"tool_results\", payload=msg)\n</code></pre></li> <li>Ensure the Kafka topic definitions from <code>infra/kafka/init-topics.sh</code> are compatible with Somabrain\u2019s naming (<code>brain_events</code>, <code>tool_results</code>).</li> <li>Add a smoke test that verifies a tool result appears in the Kafka topic using the existing <code>kafka-logs</code> consumer.</li> </ol>"},{"location":"roadmap/combined-canonical-roadmap/#phase-3-multitenant-feature-flags-opa-policies-1-week","title":"Phase\u202f3 \u2013 Multi\u2011tenant feature flags &amp; OPA policies (1\u202fweek)","text":"<ol> <li>Migrate all existing feature\u2011flag checks (<code>settings.yaml</code>) to use <code>get_tenant_flag</code>.</li> <li>Populate Redis with default flags for each tenant (script <code>scripts/init_tenant_flags.py</code>).</li> <li>Extend the OPA policy <code>ops/opa/policies/constitution.rego</code> with any additional rules required by SomaAgent01 endpoints.</li> <li>Add tests <code>tests/unit/test_feature_flags.py</code> and <code>tests/unit/test_opa_policy.py</code>.</li> </ol>"},{"location":"roadmap/combined-canonical-roadmap/#phase-4-observability-dashboard-1-week","title":"Phase\u202f4 \u2013 Observability &amp; Dashboard (1\u202fweek)","text":"<ol> <li>Import Somabrain\u2019s Grafana dashboards (<code>somabrain/grafana/provisioning/dashboards/autonomous_dashboard.json</code>) into the SomaAgent01 Helm chart (<code>infra/helm/soma-stack/values.yaml</code>).</li> <li>Add a new Prometheus scrape target for the gateway (<code>/metrics</code>).</li> <li>Verify alerts for learning\u2011related metrics fire correctly.</li> </ol>"},{"location":"roadmap/combined-canonical-roadmap/#6-testing-validation-strategy","title":"6\ufe0f\u20e3\u202fTesting &amp; Validation Strategy","text":"Layer Test type Goal Unit <code>tests/unit/*</code> Verify wrappers call Somabrain APIs with correct signatures. Integration <code>tests/integration/*</code> End\u2011to\u2011end flow: UI \u2192 gateway \u2192 Somabrain learning \u2192 metrics. E2E <code>tests/e2e/*</code> (Playwright) Real UI interaction triggers brain updates. Load <code>scripts/load/soak_gateway.py</code> Simulate 10\u202fk concurrent chats, ensure weight norm stays bounded (assert via <code>/metrics</code>). Security OPA policy tests + JWT tenant isolation checks."},{"location":"roadmap/combined-canonical-roadmap/#7-deployment-checklist","title":"7\ufe0f\u20e3\u202fDeployment Checklist","text":"<ol> <li>Helm chart updates \u2013 add Somabrain container image (or mount the repo as a volume) and expose env vars from <code>somabrain/config/env.example</code>.</li> <li>Database migrations \u2013 run <code>alembic upgrade head</code> (Somabrain already ships migrations in <code>migrations/</code>).</li> <li>Redis &amp; Kafka \u2013 ensure the same instances are referenced by both services (<code>REDIS_URL</code>, <code>KAFKA_BOOTSTRAP_SERVERS</code>).</li> <li>OPA policy reload \u2013 <code>opa reload</code> after chart install.</li> <li>Prometheus &amp; Grafana \u2013 apply the Somabrain dashboards via Helm <code>grafana.sidecar.dashboards.enabled=true</code>.</li> <li>Canary rollout \u2013 enable new feature flags only for a test tenant, monitor latency, then flip the global flag.</li> <li>Rollback plan \u2013 keep the original <code>tool_executor</code> code in a Git branch; revert the Helm release if any metric degrades.</li> </ol>"},{"location":"roadmap/combined-canonical-roadmap/#8-summary","title":"8\ufe0f\u20e3\u202fSummary","text":"<ul> <li>The integration re\u2011uses Somabrain\u2019s proven learning core, OPA security model, and observability stack.</li> <li>All changes are isolated to thin wrapper modules, preserving the existing SomaAgent01 code\u2011base and UI.</li> <li>A phased 5\u2011week roadmap ensures continuous delivery, automated testing, and safe production rollout.</li> <li>The design is fully documented, test\u2011covered, and ready for immediate implementation.</li> </ul>"},{"location":"roadmap/combined-canonical-roadmap/#9-canonical-roadmap-original-content","title":"9\ufe0f\u20e3\u202fCanonical Roadmap (original content)","text":""},{"location":"roadmap/combined-canonical-roadmap/#integration-of-celery-into-somaagent01-canonical","title":"\ud83d\udcda\u202fIntegration of Celery into somaagent01 (Canonical)","text":"<p>Version: 1.0 \u2013\u202f2025\u201111\u201108 Audience: Developers, DevOps engineers, and security auditors working on the somaagent01 code\u2011base.</p>"},{"location":"roadmap/combined-canonical-roadmap/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Why Celery?</li> <li>High\u2011Level Architecture</li> <li>Prerequisites &amp; Dependencies</li> <li>Code Layout &amp; Core Components</li> <li>FastAPI Scheduler API</li> <li>LLM Tool \u2013 schedule_task_celery</li> <li>Security \u2013 JWT Middleware &amp; Scope Enforcement</li> <li>Observability \u2013 Prometheus Metrics</li> <li>Docker\u2011Compose Deployment</li> <li>Feature\u2011Flag Switching (APScheduler \u2194 Celery)</li> <li>Migration from APScheduler to Celery</li> <li>Testing Strategy</li> <li>Roll\u2011out Checklist</li> <li>Appendix \u2013 Example Payloads &amp; cURL snippets</li> </ul> <p>(Full original sections are retained in this file for reference.)</p>"},{"location":"roadmap/dev-prod-parity-roadmap/","title":"Dev\u2013Prod Parity Roadmap (High Priority)","text":"<p>Purpose: run the entire platform locally with production behavior (security, data flows, observability) while right\u2011sizing resources for a single machine. No test bypasses, no hidden relaxations, no legacy fallbacks. Everything on; only smaller.</p>"},{"location":"roadmap/dev-prod-parity-roadmap/#principles","title":"Principles","text":"<ul> <li>Production posture: auth required, policy enforced, durable write paths, auditability, SSE\u2011only, no polling.</li> <li>Single source of truth: settings via facade + registry; avoid scattered <code>os.getenv</code> reads.</li> <li>Deterministic &amp; observable: health\u2011gated startup, structured logs, metrics, and traces across all hops.</li> <li>Minimal footprint: reduce partitions/concurrency/pools; retain correctness and failure modes.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#current-snapshot-as-observed","title":"Current Snapshot (as observed)","text":"<ul> <li>Gateway up; chat POST ok; SSE enabled. Policy selective gates active \u2192 401/403 on unauthenticated UI calls (expected).</li> <li>Conversation Worker / Tool Executor / Memory Replicator running; need end\u2011to\u2011end validation for memory write/recall and tool lifecycle.</li> <li>OPA container running; real denies observed; no bypass in dev compose.</li> <li>Somabrain integration available (weights/context); recall/flags not yet exercised in smoke.</li> <li>Env centralization incomplete; many direct <code>os.getenv</code> calls.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#acceptance-criteria-devprod-mode","title":"Acceptance Criteria (Dev\u2013Prod Mode)","text":"<ul> <li>All services healthy with single <code>make dev-up</code> + health gate. <code>/v1/health</code> reflects policy/DB/Kafka/OPA/Somabrain readiness.</li> <li>Auth + policy enforced for conversation.send, tool.execute, memory.write, scheduler CRUD, OperationsAdministration.</li> <li>UI authenticated; chat streams via SSE; uploads return attachment ids; scheduler CRUD works; no polling/legacy endpoints.</li> <li>Durable memory: local Postgres + WAL/outbox; replicator healthy; DLQ lag visible.</li> <li>Somabrain calls in the loop: weights, context build, reward updates, flags, recall; failures degrade clearly with metrics &amp; audit.</li> <li>Observability: metrics counters/histograms present; distributed traces span Gateway\u2192Worker\u2192Somabrain\u2192back; no secrets in logs.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#resource-scaling-local-defaults","title":"Resource Scaling (Local Defaults)","text":"<ul> <li>Kafka: topics 1 partition, RF=1; acks=all; small linger.</li> <li>Postgres: pool 5\u201310; statement timeout 10\u201330s.</li> <li>Redis: modest max clients; short TTL for transient keys.</li> <li>Celery: workers 1\u20132; prefetch=1; visibility timeout moderate.</li> <li>Circuit breakers: fail_max=3, reset_timeout=30s.</li> <li>Processes: single uvicorn/worker process; small thread pools.</li> <li>Tracing: small batch exporters; Prometheus on localhost.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#required-env-overlay-illustrative","title":"Required Env Overlay (illustrative)","text":"<ul> <li>Gateway/UI: <code>GATEWAY_PORT=21016</code>, <code>GATEWAY_BASE_URL=http://localhost:21016</code>, <code>WEB_UI_BASE_URL=http://localhost:21016/ui</code></li> <li>Infra: <code>POSTGRES_DSN=...</code>, <code>REDIS_URL=...</code>, <code>KAFKA_BOOTSTRAP_SERVERS=localhost:9092</code></li> <li>Security: <code>REQUIRE_AUTH=true</code>, <code>OPA_URL=http://opa:8181</code></li> <li>Somabrain: <code>SOMA_BASE_URL=http://host.docker.internal:9696</code></li> <li>Observability: <code>OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317</code>, metrics host/port</li> <li>Celery: <code>CELERY_BROKER_URL=redis://redis:6379/0</code>, <code>CELERY_RESULT_BACKEND=redis://redis:6379/0</code>, <code>CELERY_WORKER_CONCURRENCY=1</code></li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#sprints-parallel-where-safe","title":"Sprints (Parallel Where Safe)","text":""},{"location":"roadmap/dev-prod-parity-roadmap/#dp0-foundation-health-gating-12d","title":"DP0 \u2014 Foundation &amp; Health Gating (1\u20132d)","text":"<ul> <li>Tasks: single compose profile; health\u2011wait gating; topic/schema init; startup summary logging (active features, scaled caps).</li> <li>Acceptance: <code>make dev-up &amp;&amp; make health-wait</code> \u2192 Gateway <code>/v1/health</code> reports ready including policy and Somabrain; startup summary printed.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#dp1-auth-policy-in-ui-1d","title":"DP1 \u2014 Auth &amp; Policy in UI (1d)","text":"<ul> <li>Tasks: dev API key issuance; UI fetch layer sends bearer/cookie; verify policy allow/deny with structured logs and metrics.</li> <li>Acceptance: scheduler/settings/file ops return 2xx (authorized); <code>auth_decisions_total</code> shows allow/deny as expected.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#dp2-somabrain-full-loop-23d","title":"DP2 \u2014 Somabrain Full Loop (2\u20133d)","text":"<ul> <li>Tasks: wire recall in conversation path (feature\u2011flagged), ensure weights/context build, reward updates, tenant flags merge; add metrics: <code>somabrain_requests_total</code>, latency histograms.</li> <li>Acceptance: chat invokes Somabrain endpoints; failures degrade explicitly; metrics/trace attributes show endpoints and status.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#dp3-observability-expansion-1d","title":"DP3 \u2014 Observability Expansion (1d)","text":"<ul> <li>Tasks: enrich spans (request_id, session_id, tenant); add gauges for WAL/outbox lag, DLQ depth, consumer lag; dashboards baseline.</li> <li>Acceptance: traces link across services; Prometheus shows lag and decision metrics; no PII/secrets in logs.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#dp4-config-centralization-23d-rolling","title":"DP4 \u2014 Config Centralization (2\u20133d, rolling)","text":"<ul> <li>Tasks: migrate high\u2011impact env reads (db/kafka/redis/auth flags/uploads/speech) to facade; add linter/test to forbid stray <code>os.getenv</code>.</li> <li>Acceptance: grep outside allowed modules \u2192 zero; <code>/v1/runtime-config</code> sourced from facade only.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#dp5-scheduler-canonicalization-1d","title":"DP5 \u2014 Scheduler Canonicalization (1d)","text":"<ul> <li>Tasks: add canonical <code>/v1/ui/scheduler/*</code> (list/create/update/run/delete/history); deprecate legacy paths; audit log entries.</li> <li>Acceptance: UI uses <code>/v1/ui/scheduler/*</code>; audit entries present; policy enforced.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#dp6-memory-durability-validation-1d","title":"DP6 \u2014 Memory Durability Validation (1d)","text":"<ul> <li>Tasks: chaos test SomaBrain outage \u2192 verify WAL/outbox retries and replica sync; expose lag/health in <code>/v1/health</code>.</li> <li>Acceptance: messages persist and reconcile; health reflects degraded/ok; alerts (metrics) increment.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#dp7-ci-parity-jobs-1d","title":"DP7 \u2014 CI Parity Jobs (1d)","text":"<ul> <li>Tasks: add matrix: dev\u2011prod stack smoke (API + UI), metrics scrape, trace presence; golden UI mode retained.</li> <li>Acceptance: CI green on parity checks; artifacts (screenshots/traces) optional.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#parallelization-guidance","title":"Parallelization Guidance","text":"<ul> <li>Run DP0 \u2192 DP1 sequentially (foundation + auth). DP2/DP3/DP5 can proceed in parallel by different owners. DP4 runs as rolling refactor. DP6 after core loops pass; DP7 last.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#runbook-operatorfacing","title":"Runbook (Operator\u2011Facing)","text":"<ul> <li>Start: <code>make dev-up &amp;&amp; make health-wait</code></li> <li>Verify:</li> <li><code>curl -s http://localhost:21016/v1/health | jq</code></li> <li><code>curl -s http://localhost:21016/metrics | head</code></li> <li><code>curl -s \"$SOMA_BASE_URL/healthz\"</code></li> <li>UI: ensure dev token present; load <code>WEB_UI_BASE_URL</code>; send chat; test uploads, scheduler CRUD.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#metrics-alerts-minimum-set","title":"Metrics &amp; Alerts (minimum set)","text":"<ul> <li>Auth/Policy: <code>auth_decisions_total{action,result}</code>, <code>auth_duration_seconds</code></li> <li>Somabrain: <code>somabrain_requests_total{endpoint,status}</code>, latency</li> <li>Memory: WAL/outbox attempts/results, replica lag, DLQ depth</li> <li>Streaming: time\u2011to\u2011first token, assistant tokens total</li> <li>Kafka: consumer lag, publish failures</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#risks-mitigations","title":"Risks &amp; Mitigations","text":"<ul> <li>UI auth gaps \u2192 seed dev token or enable local login; never disable policy.</li> <li>Policy latency \u2192 short TTL cache + breaker; fail\u2011closed with clear errors.</li> <li>External dependency outages \u2192 degrade explicitly; surface in metrics and health.</li> <li>Env drift \u2192 facade + linter; audit config diffs.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#definition-of-done","title":"Definition of Done","text":"<ul> <li>One\u2011command local stack with production behavior; all protected flows authorized and audited; SSE chat + tools + scheduler working; Somabrain in the loop; metrics/traces comprehensive; config centralized for critical paths; CI parity job green.</li> </ul>"},{"location":"roadmap/dev-prod-parity-roadmap/#ownership-governance","title":"Ownership &amp; Governance","text":"<ul> <li>Changes that alter posture or routes must update this roadmap first. Every sprint closes with acceptance checks and a brief ops note.</li> </ul>"},{"location":"roadmap/roadmap-sprinted/","title":"Roadmap sprinted","text":""},{"location":"roadmap/roadmap-sprinted/#sprinted-roadmap-notifications-first-then-scheduler-q4-2025","title":"Sprinted Roadmap \u2014 Notifications First, then Scheduler (Q4 2025)","text":"<p>Scope: Convert the Celery integration (canonical) into actionable sprints focusing first on centralized Notifications, then unified Scheduler API and Celery enablement under a feature flag.</p> <p>Timebox: 4 sprints \u00d7 2 weeks (\u22488 weeks total)</p> <p>Sprint 0 (Prep \u2013 first 2 days) - Runtime config surfaces: <code>notifications.enabled</code>, <code>scheduler.enabled</code>, <code>scheduler.use_celery</code> via <code>/v1/runtime/config</code> and <code>/v1/ui/settings/sections</code> (read\u2011only). - UI conditional rendering for Notifications &amp; Scheduler panels. - Acceptance: Flags show in REST &amp; UI; no functional regressions.</p> <p>Sprint 1 \u2014 Notifications System (Backend + UI) - Backend:   - Table <code>ui_notifications</code> (id, tenant_id, user_id?, type, title, body, severity, created_at, read_at, ttl_at, meta JSONB).   - REST: <code>GET /v1/ui/notifications</code>, <code>POST /v1/ui/notifications</code>, <code>POST /v1/ui/notifications/{id}/read</code>, <code>DELETE /v1/ui/notifications/clear</code> (filter + pagination).   - SSE event <code>ui.notification</code> (create/read/clear) with lightweight payload; metrics <code>ui_notifications_total{severity,type}</code>.   - TTL janitor job (APScheduler) deleting expired rows. - Frontend:   - Store <code>notificationsStore.js</code> (list, markRead, clear, subscribe SSE).   - Modal/panel + toast helper; unread badge; ARIA roles. - Security: Auth scope check; optional OPA policy on create. - Tests: Pytest (CRUD + TTL), Playwright (badge, live push, mark read). - Acceptance: REST create appears via SSE &lt; 1s; unread counter accurate; TTL purges; tests green.</p> <p>Sprint 2 \u2014 Unified Scheduler API (APScheduler backend) - Backend:   - Endpoints: <code>GET/POST/PUT/DELETE /v1/ui/scheduler/jobs</code>, <code>POST /v1/ui/scheduler/jobs/{id}/run</code>, <code>GET /v1/ui/scheduler/runs</code>.   - Adapter interface <code>IScheduler</code>; APScheduler implementation; Celery stub returns 501 when flag on but not provisioned.   - JWT scopes: <code>scheduler:read</code>, <code>scheduler:write</code>, <code>scheduler:run</code>; audit log entries.   - Metrics: <code>scheduler_jobs_total</code>, <code>scheduler_runs_started_total</code>, <code>scheduler_runs_success_total</code>, <code>scheduler_runs_failure_total</code>, histogram <code>scheduler_run_duration_seconds</code>. - Frontend: Scheduler panel (list/create/edit/delete/run-now); reads runtime flags to show mode. - Docs: API reference, scope matrix, migration notes. - Tests: Unit (validators/adapter), integration (CRUD + run), Playwright (create + run + delete). - Acceptance: Full CRUD &amp; run-now on APScheduler; metrics exposed; UI operational; scopes enforced.</p> <p>Sprint 3 \u2014 Celery Integration (Flag OFF by default) - Infra: docker-compose add <code>celery_worker</code>, <code>celery_beat</code>; env <code>SCHEDULER_USE_CELERY</code>; Redis broker/backend. - Backend: <code>celery_app/</code> factory; Celery adapter mapping unified API to Beat + ad\u2011hoc tasks; task wrapper <code>scheduler.run_job</code>. - Migration tooling: Export APScheduler jobs \u2192 JSON; transform \u2192 Celery Beat; dry-run apply. - Tests: Integration compose test (create job, beat enqueue, worker execute, status visible); unit for adapter. - Acceptance: Flag ON routes through Celery; run-now works; rollback by flag toggle validated.</p> <p>Sprint 4 \u2014 Migration &amp; Hardening - Staging parallel run (APScheduler control vs Celery) 48h; compare success/failure metrics. - Cutover procedure documented; rollback tested. - Load tests for p95/p99 durations; queue depth gauges; retry/backoff verified. - Security: Final scope review; OPA tenant policies; audit log sampling. - Ops: Dashboards (Grafana) &amp; runbooks (alerts: failed jobs spike, queue depth, long duration). - Acceptance: Celery mode stable in staging &amp; prod; SLOs met; runbooks + dashboards delivered; all tests green.</p> <p>Cross\u2011Cutting Risks &amp; Mitigations - Redis saturation: add queue depth gauges + alert thresholds. - Job duplication on migration: idempotent transform, dry\u2011run diff before apply. - Scope misconfiguration: enforce deny default, explicit 403 with actionable message. - Large notification volume: pagination + severity filtering; SSE payload kept lean.</p> <p>Definition of Done (Program) - Notifications live in production, used by UI flows. - Unified Scheduler API released; Celery behind feature flag proven in staging. - Migration path executed; rollback documented; observability &amp; security baselines established.</p> <p>Post\u2011Program Backlog (Nice to Have) - Task chaining demo (Celery chords) with UI visualization. - Dead\u2011letter queue surfacing in Scheduler panel. - Multi\u2011tenant throttling policies (rate per tenant). - WebSocket optional upgrade for high\u2011frequency job status streams.</p> <p>Ownership (Placeholder) - Sprint 1: Backend Engineer A + Frontend Engineer B - Sprint 2: Backend Engineer A - Sprint 3: DevOps Engineer C + Backend Engineer A - Sprint 4: DevOps Engineer C + QA Engineer D</p> <p>Tracking &amp; Metrics Source of Truth - Prometheus metrics names as listed; Grafana dashboard IDs reserved (<code>scheduler-overview</code>, <code>notifications-lag</code>).</p> <p>Notes - Keep feature flags read\u2011only in UI initially to avoid accidental production toggles. - Reuse existing Redis; size check before enabling Celery result backend (may omit if not required for UI history).</p>"},{"location":"roadmap/sprint-roadmap/","title":"Sprint Roadmap","text":""},{"location":"roadmap/sprint-roadmap/#sprint-1-settings-centralization-make-the-agent-talk","title":"Sprint 1 \u2014 Settings Centralization + Make The Agent Talk","text":"<ul> <li>Goals:<ul> <li>Single-save Settings (<code>/v1/ui/settings/sections</code>) for every field, including External \u2192 API Keys.</li> <li>Secrets masked on GET; encrypted at rest; no seeders or secondary POSTs.</li> <li>Hot-apply overlays and service toggles; publish <code>config_updates</code>; workers reload.</li> <li>Expand provider dropdowns (chat/util/browser) to show all providers with Groq default.</li> <li>Agent can \u201ctalk\u201d end-to-end: save \u2192 test \u2192 stream a reply.</li> </ul> </li> <li>Tasks:<ul> <li>Accept all <code>api_key_*</code> in Gateway sections; persist encrypted; mask on GET.</li> <li>Expand <code>conf/model_providers.yaml</code> chat providers (OpenAI, Groq, Azure, Mistral, DeepSeek, xAI, HuggingFace, LM Studio, Ollama, Other).</li> <li>Ensure <code>settings.js</code> posts only sections; remove secondary credential POSTs; keep placeholders.</li> <li>Hot-apply updated fields for chat/util/embed/browser, LiteLLM, uploads, AV, speech.</li> <li>Add <code>/v1/llm/status</code> details into Settings \u201cStatus\u201d panel (follow-up UI wiring).</li> </ul> </li> <li>Acceptance:<ul> <li>Saving any field updates runtime without restart; secrets masked.</li> <li><code>/v1/llm/test</code> passes with valid key; UI chat streams assistant replies.</li> </ul> </li> </ul>"},{"location":"roadmap/sprint-roadmap/#sprint-2-diagnostics-aliases-and-provider-polish","title":"Sprint 2 \u2014 Diagnostics, Aliases, and Provider Polish","text":"<ul> <li>Goals:<ul> <li>Model alias registry (e.g., UI label \u201cGPT\u2011OSS\u2011120B\u201d \u2192 exact provider model).</li> <li>Provider normalization guardrails (no OpenRouter special cases, sensible defaults).</li> <li>Settings banners for missing keys/unreachable providers.</li> </ul> </li> <li>Tasks:<ul> <li>Alias resolver in Gateway; pass-through by default.</li> <li>Expand <code>/v1/llm/status</code> reachability and coercion flags.</li> <li>UI: Add Status view and lightweight banners.</li> </ul> </li> <li>Acceptance:<ul> <li>Aliases resolve in invoke/test; diagnostics show clear state/banners.</li> </ul> </li> </ul>"},{"location":"roadmap/sprint-roadmap/#sprint-3-memory-constitution","title":"Sprint 3 \u2014 Memory + Constitution","text":"<ul> <li>Goals:<ul> <li>SomaBrain memory parity across conversation stages.</li> <li>Constitution and Decisions tabs fully editable and hot-applied.</li> </ul> </li> <li>Tasks:<ul> <li>Ensure memory recall toggles/thresholds are read dynamically by workers.</li> <li>Wire Constitution endpoints and hot-apply.</li> </ul> </li> <li>Acceptance:<ul> <li>Memory button shows relevant content; constitution edits reflected immediately.</li> </ul> </li> </ul>"},{"location":"roadmap/sprint-roadmap/#sprint-4-observability-tests","title":"Sprint 4 \u2014 Observability &amp; Tests","text":"<ul> <li>Goals:<ul> <li>Robust metrics and admin probes; end-to-end tests.</li> </ul> </li> <li>Tasks:<ul> <li>Metrics for <code>/v1/llm/test</code> by provider; SSE stability checks.</li> <li>Playwright: Settings save \u2192 LLM test \u2192 stream \u2192 visual assertions.</li> </ul> </li> <li>Acceptance:<ul> <li>CI passes; telemetry surfaces failures quickly; no secrets in logs.</li> </ul> </li> </ul>"},{"location":"roadmap/sprint-roadmap/#sprint-roadmap-execution-plan","title":"Sprint Roadmap \u2014 Execution Plan","text":"<p>This sprint roadmap breaks the canonical roadmap into concrete, time-boxed sprints with clear scope, deliverables, and tests. Each sprint completes with PASS/FAIL gates and visible artifacts.</p> <p>Conventions: - Definition of Done (DoD): code merged, docs updated, tests passing (unit+integration), CI green, and dashboards updated if applicable. - Acceptance: explicit checks listed per sprint; failing any check means the sprint goal is not met.</p>"},{"location":"roadmap/sprint-roadmap/#sprint-0-priority-0-live-chat-sse-e2e-1-week","title":"Sprint 0 \u2014 Priority 0: Live Chat (SSE) E2E (1 week)","text":"<p>Goal: - Restore end-to-end chatting via the LLM and the full agent infra using the canonical SSE path.</p> <p>Scope: - Verify and harden the minimum chat path: POST <code>/v1/session/message</code> \u2192 Kafka/Worker \u2192 SSE <code>GET /v1/session/{id}/events</code>. - Ensure uploads \u2192 attachment_id round-trip and chat with attachments works minimally. - Ensure health surfaces dependency states; UI shows banners but allows sending when overall health is not fully down.</p> <p>Deliverables: - Functional SSE chat path observed locally; assistant events visible over SSE. - UI uses <code>/v1/session/message</code>, <code>/v1/uploads</code>, and opens SSE for the current session. - E2E quick script and UI smoke pass in dev; document how to set provider credentials.</p> <p>Acceptance tests: - Task: E2E Quick (SSE) \u2014 passes and prints an assistant event. - Task: UI Smoke (Playwright) \u2014 loads UI and basic flows without console errors. - Optional: If provider credentials are present, assistant emits non-error content; else a clear error message appears over SSE (still acceptable for S0).</p> <p>Exit criteria: - A send operation produces an assistant SSE event in local dev. - Basic upload+send works without 5xx.</p>"},{"location":"roadmap/sprint-roadmap/#sprint-05-strictness-and-no-legacy-enablement-completed","title":"Sprint 0.5 \u2014 Strictness and No-Legacy Enablement (completed)","text":"<p>Scope: - Enforced SSE-only; removed UI proxy/poll and bespoke CSRF paths. Added tests to assert no <code>/v1/ui/poll</code> or <code>/v1/csrf</code> calls.</p> <p>Deliverables: - UI free of polling and bespoke CSRF; SSE-only for streaming. - Gateway exposes a single SSE route implementation.</p> <p>Acceptance tests: - tests/webui/test_no_legacy_network.spec.ts: asserts no calls to legacy endpoints during chat flows.</p> <p>Exit criteria: - All SSE tests green; no legacy network calls observed in Playwright traces.</p>"},{"location":"roadmap/sprint-roadmap/#sprint-1-attachment-ingestion-by-id-12-weeks","title":"Sprint 1 \u2014 Attachment Ingestion by ID (1\u20132 weeks)","text":"<p>Scope: - Add internal service fetch of attachments by ID; migrate Worker and <code>document_ingest</code> tool to <code>attachment_id</code> contract. - Update UI previews/downloads to route only via <code>/v1/attachments/{id}</code>.</p> <p>Deliverables: - New internal endpoint: GET <code>/internal/attachments/{id}/binary</code> (authZ, tenant-scoped, policy enforced) or reuse existing with service auth. - UI code no longer references filesystem paths like <code>/git/agent-zero/tmp/uploads/*</code>.</p> <p>Acceptance tests: - tests/webui/test_attachment_preview_routes.py (Playwright or integration): preview/download via Gateway only.</p> <p>Exit criteria: - All acceptance tests green; a 10MB PDF successfully ingests by ID locally; no FS path leakage in UI.</p>"},{"location":"roadmap/sprint-roadmap/#sprint-2-tool-catalog-and-runtime-config-2-weeks","title":"Sprint 2 \u2014 Tool Catalog and Runtime Config (2 weeks)","text":"<p>Scope: - Implement Tool Catalog (schemas, per-tenant enable, execution profiles, egress allowlists) in Gateway. - Service-side ETag/TTL config pull; fail closed if missing/stale beyond max-age. - Centralize provider secrets in Gateway for LLM invocations.</p> <p>Deliverables: - Postgres tables: tools, tool_versions, tenant_overrides, execution_profiles, egress_allowlists. - Admin APIs: <code>/v1/admin/tools</code>, <code>/v1/admin/tools/{name}/tenants/{tenantId}</code>. - Runtime APIs: <code>/v1/tools</code>, <code>/v1/runtime-config</code>, <code>/internal/tool-catalog</code> (ETag).</p> <p>Acceptance tests: - tests/integration/test_tool_catalog_toggle.py: disable tool \u2192 UI/tool list updates \u2192 execution denied with audit. - tests/integration/test_execution_profile_timeout.py: timeout change reflected in Tool Executor within TTL.</p> <p>Exit criteria: - UI shows only enabled tools; Tool Executor enforces configured limits; secrets never exposed to services.</p>"},{"location":"roadmap/sprint-roadmap/#sprint-3-memory-guarantees-and-policy-12-weeks","title":"Sprint 3 \u2014 Memory Guarantees and Policy (1\u20132 weeks)","text":"<p>Scope: - Strengthen outbox/WAL/idempotency; WAL lag surfaced in health and UI banner. - OPA gates for conversation.send, tool.execute, memory.write with clear user errors and audit entries.</p> <p>Deliverables: - Health: WAL/outbox lag metrics and thresholds. - Policy deny surfaces in Gateway and Worker with error payloads.</p> <p>Acceptance tests: - tests/e2e/test_wal_durability_chaos.py: simulate SomaBrain outage; outbox grows and drains; no message loss; timelines consistent. - tests/integration/test_policy_denies.py: OPA deny returns clear error; audit record captured.</p> <p>Exit criteria: - Chaos test reliable on local dev; deny paths user-visible and audited; dashboards include WAL lag.</p>"},{"location":"roadmap/sprint-roadmap/#sprint-5-e2e-and-ci-1-week","title":"Sprint 5 \u2014 E2E and CI (1 week)","text":"<p>Scope: - Playwright suite for core flows; wire smoke to CI; produce artifacts.</p> <p>Deliverables: - Playwright specs for: chat send/stream, tool flow, uploads preview, delete chat, policy denies, SSE resilience. - CI job: run smoke on PR, full suite nightly.</p> <p>Acceptance tests: - CI green for smoke; failing specs produce trace/screenshot artifacts.</p> <p>Exit criteria: - Contributors see clear, fast feedback on PRs; nightly E2E produces stable artifacts.</p> <p>Tracking and Metrics per Sprint: - Build: PASS/FAIL on typecheck and unit. - Lint: PASS with zero new warnings in touched areas. - Tests: unit+integration must pass; E2E smoke (when applicable). - Observability: new metrics/spans visible in dev dashboards when relevant.</p> <p>Review cadence: Demo and checkpoint at the end of each sprint; update this document and the canonical roadmap with any deltas.</p>"},{"location":"roadmap/sprint-roadmap/#2025-10-31-sprint-addendum-immediate-focus","title":"2025-10-31 Sprint Addendum \u2014 Immediate Focus","text":"<p>Sprint A \u2014 UI Parity Polish (now) - Fix tool lifecycle de-duplication: single \u201cTool: \u201d block even when <code>request_id</code> appears only on <code>tool.result</code>. - Uploads progress: exactly one upload block per filename; show \u201cUploaded:\u201d when only a final event is observed. - Settings modal: ensure Alpine initialization so modal opens on first click in automation. - Tests: extend Playwright specs to assert the above behaviors. <p>Sprint B \u2014 API Contract Tests + Docs - Add pytest probes for: <code>/v1/session/message</code>, <code>/v1/session/{id}/events</code> (SSE), <code>/v1/uploads</code>, <code>/v1/tools</code>, <code>/v1/ui/settings/sections</code>. - Document request/response examples in technical manual for each UI-used endpoint.</p> <p>Sprint C \u2014 Credential UX + Model Test - Settings: add provider key masking hints and a light-weight \u201cTest model\u201d (optional <code>/v1/llm/test</code>) wiring. - Update runtime-config to surface provider availability for boot-time UX hints.</p> <p>Sprint D \u2014 Memory + Observability - Health: surface WAL/outbox lag with thresholds and banners; collect Prometheus metrics. - Tests: chaos test to assert outbox/WAL resilience; Playwright checks for health banners without blocking chat.</p>"},{"location":"technical-manual/","title":"Technical Manual","text":"<p>Standards: ISO/IEC 12207\u00a76, ISO/IEC 42010, ISO/IEC 29148</p>"},{"location":"technical-manual/#overview","title":"Overview","text":"<p>SomaAgent01 is a microservices-based conversational AI platform implementing event-driven architecture with Kafka as the message bus.</p>"},{"location":"technical-manual/#architecture","title":"Architecture","text":""},{"location":"technical-manual/#system-components","title":"System Components","text":"Component Type Port Purpose Gateway FastAPI 21016 HTTP API with SSE streaming, authentication, routing Conversation Worker Kafka Consumer - Process user messages, generate LLM responses Tool Executor Kafka Consumer - Execute tools requested by conversations Memory Replicator Kafka Consumer - Replicate memory.wal events to PostgreSQL Memory Sync Background Worker - Retry failed memory writes from outbox Outbox Sync Background Worker - Retry failed Kafka publishes from outbox UI Proxy FastAPI Router - Aggregate UI polling and message endpoints"},{"location":"technical-manual/#infrastructure","title":"Infrastructure","text":"Service Port Purpose Kafka 20000 Event streaming (KRaft mode, single broker) Redis 20001 Session cache, API keys PostgreSQL 20002 Sessions, events, memory replica, outbox OPA 20009 Policy evaluation"},{"location":"technical-manual/#kafka-topics","title":"Kafka Topics","text":"<ul> <li><code>conversation.inbound</code>: User messages from gateway</li> <li><code>conversation.outbound</code>: Assistant responses to clients</li> <li><code>tool.requests</code>: Tool execution requests</li> <li><code>tool.results</code>: Tool execution results</li> <li><code>memory.wal</code>: Write-ahead log for all memory operations</li> <li><code>memory.wal.dlq</code>: Dead letter queue for failed memory events</li> <li><code>config_updates</code>: Runtime configuration changes</li> </ul>"},{"location":"technical-manual/#data-flow","title":"Data Flow","text":"<pre><code>User \u2192 Gateway \u2192 conversation.inbound \u2192 Conversation Worker \u2192 SLM \u2192 conversation.outbound \u2192 Gateway \u2192 User\n                                              \u2193\n                                         SomaBrain (HTTP)\n                                              \u2193\n                                         memory.wal \u2192 Memory Replicator \u2192 PostgreSQL\n</code></pre>"},{"location":"technical-manual/#security","title":"Security","text":"<ul> <li>Authentication: JWT (HS256/RS256) or API keys</li> <li>Authorization: OPA policy evaluation, OpenFGA (optional)</li> <li>Encryption: TLS termination at reverse proxy, Fernet for stored secrets</li> <li>Browser auth: Same-origin cookies or header/bearer tokens (no custom CSRF endpoint)</li> </ul>"},{"location":"technical-manual/#standards-compliance","title":"Standards Compliance","text":"<ul> <li>ISO/IEC 12207\u00a76: Software construction and integration</li> <li>ISO/IEC 42010: Architecture description with stakeholder concerns</li> <li>ISO/IEC 29148: Requirements traceability</li> <li>ISO/IEC 27001: Information security controls</li> </ul>"},{"location":"technical-manual/#related-documents","title":"Related Documents","text":"<ul> <li>Architecture Details</li> <li>Outbound Events</li> <li>Security Controls</li> <li>Deployment Guide</li> <li>SomaBrain Integration</li> </ul>"},{"location":"technical-manual/architecture-blueprint/","title":"SomaAgent 01 Architecture Blueprint (Initial Version)","text":"<p>Status: Draft v0.1 \u2013 generated from codebase scan (Nov 9 2025). Will iterate as cross\u2011cutting concern assessment progresses.</p>"},{"location":"technical-manual/architecture-blueprint/#1-highlevel-layering","title":"1. High\u2011Level Layering","text":"<ol> <li>Edge &amp; API Layer</li> <li><code>gateway</code>: Public FastAPI service (HTTP+WebSocket/SSE), auth, rate limiting, policy enforcement, uploads, notifications, LLM invoke streaming proxy, speech endpoints.</li> <li><code>delegation_gateway</code>: Narrow FastAPI surface for asynchronous delegation task submission &amp; status.</li> <li>Worker &amp; Orchestration Layer</li> <li><code>conversation_worker</code>: Consumes <code>conversation.inbound</code>, produces <code>conversation.outbound</code>; policy filtering, background recall, orchestration of tool calls via Gateway streaming or non-stream fallback.</li> <li><code>tool_executor</code>: Consumes <code>tool.requests</code>, produces <code>tool.results</code> + UI facing tool lifecycle events; sandboxed execution, resource management, auditing.</li> <li><code>delegation_worker</code>: Consumes delegation tasks, persists them for downstream processing.</li> <li><code>memory_sync</code>: Retries failed memory writes from Postgres outbox \u2192 publishes <code>memory.wal</code> upon success.</li> <li><code>memory_replicator</code>: Consumes <code>memory.wal</code> \u2192 persists replica rows \u2192 publishes DLQ on failure.</li> <li><code>outbox_sync</code>: Publishes generic durable outbox rows to Kafka (backpressure aware; health adaptive).</li> <li>Core Domain / Data Layer</li> <li>External SomaBrain memory/LLM backend (HTTP) integrated via Gateway &amp; workers.</li> <li>Policy (OPA) &amp; optional OpenFGA (authorization + deny by fail\u2011closed design).</li> <li>Postgres stores: sessions, memory write outbox, memory replica, notifications, attachments, tool catalog, model profiles, audit, delegation, export jobs, DLQ.</li> <li>Redis: session cache, budget manager, rate limiting buckets, requeue store, Celery broker/result (where Celery used).</li> <li>Kafka: durable event bus topics (see \u00a72).</li> <li>Cross\u2011Cutting Subsystems</li> <li>Observability: per\u2011service Prometheus exporter, rich metric families (latency, counts, gauges, backlog, DLQ depth, tool execution, replication lag).</li> <li>Tracing: OTLP instrumentation (FastAPI + httpx + manual spans).</li> <li>Policy Enforcement: Gateway middleware (OPA), worker policy client checks for <code>conversation.send</code>, <code>memory.write</code>, <code>tool.execute</code>.</li> <li>Durable Publishing &amp; Outbox: <code>DurablePublisher</code> + Postgres outbox with <code>outbox_sync</code> &amp; memory write outbox with <code>memory_sync</code>.</li> <li>DLQ Pattern: Kafka DLQ topic + Postgres DLQ store (replicator).</li> <li>Idempotency: <code>generate_for_memory_payload</code> used across memory writes/tool result capture.</li> <li>Settings: <code>SA01Settings</code> (env), UI settings document (<code>UiSettingsStore</code>), runtime overlays used for uploads, AV, speech, etc.</li> <li>Telemetry: structured tool/memory metrics publisher + TelemetryStore for historical analysis.</li> <li>Security &amp; Content Hygiene: API key store, JWT cookie decoding, masking / sensitive key scrubbing, optional ClamAV scanning, rate limiting middleware, sandboxed tool execution.</li> <li>Tool Runtime: <code>ToolRegistry</code> + <code>ExecutionEngine</code> + <code>SandboxManager</code> + <code>ResourceManager</code> for deterministic bounded execution.</li> </ol>"},{"location":"technical-manual/architecture-blueprint/#2-event-topic-topology","title":"2. Event &amp; Topic Topology","text":"Topic Producers Consumers Purpose <code>conversation.inbound</code> Gateway (user messages) conversation_worker User -&gt; LLM orchestration path <code>conversation.outbound</code> conversation_worker, tool_executor (UI tool events), memory recall updates Gateway SSE (stream to clients) Downstream chat / context events <code>tool.requests</code> conversation_worker (tool orchestration), manual system events tool_executor Execute tool functions <code>tool.results</code> tool_executor Gateway SSE / conversation_worker (poll via session store) Return tool outcomes <code>memory.wal</code> memory_sync (after successful remember), conversation_worker (direct writes), tool_executor (tool result capture), attachment ingest flows memory_replicator Persist memory replica &amp; provide replication metrics <code>memory.wal.dlq</code> memory_replicator (on failure) ops consumers / DLQ inspection Failure isolation <code>config_updates</code> (future) config service or admin ops Gateway (_config_update_listener) Hot reload runtime settings <code>ui.notifications</code> notifications API endpoints Gateway SSE clients UI notification propagation <code>somastack.delegation</code> delegation_gateway delegation_worker Asynchronous task distribution <p>(Additional internal topics may appear in future revisions \u2013 maintain a versioned schema registry proposal.)</p>"},{"location":"technical-manual/architecture-blueprint/#3-principal-data-flows","title":"3. Principal Data Flows","text":"<p>A. User Message \u2192 Assistant Reply 1. Client -&gt; Gateway <code>/v1/conversation/...</code> (HTTP) \u2192 validates, publishes <code>conversation.inbound</code>. 2. <code>conversation_worker</code> consumes event, applies policy, persists session event. 3. Worker streams LLM via Gateway internal invoke endpoint; emits <code>assistant.stream</code> events to <code>conversation.outbound</code>. 4. Tool orchestration: worker detects tool calls, publishes <code>tool.requests</code>; awaits <code>tool.results</code> (polling session store) \u2192 reinvokes LLM if needed. 5. Gateway SSE endpoint streams <code>conversation.outbound</code> events back to client.</p> <p>B. Tool Execution &amp; Memory Capture 1. <code>tool_executor</code> consumes <code>tool.requests</code> \u2192 policy check \u2192 sandboxed execution. 2. Publishes result to <code>tool.results</code> and UI stream (<code>conversation.outbound</code> tool lifecycle events). 3. Captures successful tool result into SomaBrain memory (policy gated) \u2192 publishes <code>memory.wal</code>. 4. <code>memory_replicator</code> persists replica row; replication metrics updated.</p> <p>C. Memory Write Reliability 1. Direct writes (conversation_worker / tool_executor) may fail \u2192 enqueue into Postgres memory write outbox. 2. <code>memory_sync</code> retries outbox items with exponential backoff; upon success publishes <code>memory.wal</code>. 3. Replicator persists; DLQ used for irrecoverable events.</p> <p>D. Configuration Hot Reload 1. (Future) Config admin updates produce <code>config_updates</code> events. 2. Gateway listener applies validated settings overlay (via <code>set_settings</code>).</p> <p>E. Notifications 1. Notification CRUD endpoints persist rows &amp; emit Kafka <code>ui.notifications</code> events. 2. Gateway SSE merges notifications into live client stream.</p>"},{"location":"technical-manual/architecture-blueprint/#4-crosscutting-concerns-current-state","title":"4. Cross\u2011Cutting Concerns (Current State)","text":"<ul> <li>Observability: Each service starts its own metrics HTTP server; duplication risk for port collisions handled with fallback strategies (e.g. tool_executor increments port). Consider central sidecar pattern or single pushgateway in K8s.</li> <li>Tracing: OTLP endpoint configurable; httpx &amp; FastAPI automatically instrumented. Need unified trace IDs across Kafka hops (inject/extract in message headers missing currently).</li> <li>Policy: Fail\u2011closed pattern ensures memory writes/tool executions blocked on OPA outage; health fallback for conversation messages returns explicit denial message.</li> <li>Reliability Patterns: Outbox, DLQ, exponential backoff, health-adjusted batch sizing (<code>outbox_sync</code>). Add circuit breakers around external SomaBrain calls on gateway.</li> <li>Security: JWT cookie parsing with multiple alg support; API key store, rate limiting, sandboxed tools. Need mTLS / ingress controller integration plan for production.</li> <li>Settings &amp; Overlays: Central SA01Settings + dynamic UI document overlays. Missing versioned rollout &amp; staged environment layering.</li> <li>Data Privacy: Masking logic in settings diff &amp; audit diff; SENSITIVE_KEYS scrubbing. Need encryption at rest for secrets &amp; tool credentials (Vault / KMS integration).</li> </ul>"},{"location":"technical-manual/architecture-blueprint/#5-production-hardening-recommendations-preview","title":"5. Production Hardening Recommendations (Preview)","text":"Area Gap Recommendation Deployment Health Mixed health endpoints Standardize <code>/health</code> &amp; <code>/ready</code> + readiness gating on dependencies Graceful Shutdown Few explicit close hooks Implement cancellation signals &amp; drain Kafka consumers before exit Backpressure Manual sleep loops Introduce consumer lag gauges + dynamic batch sizing (already for outbox) across all workers Schema Governance Inline JSONSchema only External schema registry (e.g. Git + CI validation or Redpanda/Confluent) Secrets Env vars only Vault/Kubernetes Secrets integration + rotation policy Tracing Missing Kafka span propagation Add message headers for trace context; wrap publish/consume with span linking Resource Isolation Tool sandbox local only Containerized / VM sandbox option, CPU/mem quotas enforced by cgroups in K8s Configuration Ad\u2011hoc overlays Central config service (CRD or GitOps) + versioned update pipeline Multi\u2011Tenancy Tenant IDs present Formal tenant isolation layers (namespaces, quotas) &amp; FGA model expansion Memory Storage External SomaBrain dependency Introduce circuit breaker + bulkhead isolation; evaluate fallback local cache Rate Limiting Per-IP fixed window Token bucket / sliding window; incorporate tenant + API key dimensions"},{"location":"technical-manual/architecture-blueprint/#6-kubernetes-mapping-outline","title":"6. Kubernetes Mapping (Outline)","text":"Service K8s Kind Notes gateway Deployment + Service (ClusterIP) HTTP ingress (Ingress/Nginx/Envoy); config &amp; secret mounted; HPA by CPU/RPS conversation_worker Deployment Consumer group scaling; PodDisruptionBudget tool_executor Deployment Needs ephemeral scratch volume for sandbox; securityContext tightened memory_sync Deployment Lower replica count; backoff tuning via env ConfigMap memory_replicator Deployment Single replica or partitioned; WAL lag metric exported outbox_sync Deployment Could merge with memory_sync for simplicity (arg) delegation_gateway Deployment + Service Separate ingress path; optional merging into gateway if traffic low delegation_worker Deployment Lightweight consumer OPA Deployment + Service Sidecar or central; policy bundles via ConfigMap Redis / Postgres / Kafka Managed / StatefulSets Evaluate cloud managed vs self-hosted; backup &amp; retention policies Prometheus/Grafana Helm chart Scrape all metrics ports; service monitors <p>Config via ConfigMaps (non-sensitive) &amp; Secrets (JWT keys, API keys, provider credentials). Use <code>Deployment</code> annotations for config checksum to trigger rolling restarts.</p>"},{"location":"technical-manual/architecture-blueprint/#7-terraform-baseline-components","title":"7. Terraform Baseline Components","text":"<ul> <li>Network: VPC, subnets, SG rules for Kafka/Postgres/Redis/OPA.</li> <li>Data: Managed Postgres (point-in-time restore), Redis (cache tier), Kafka cluster (MSK / Redpanda).</li> <li>Observability: Managed Prometheus (AMP) + Grafana (AG), OTLP collector (OpenTelemetry).</li> <li>Security: Secrets Manager / Vault, KMS CMKs for envelope encryption; IAM roles per service pod.</li> <li>CI/CD: Artifact registry (Docker), Terraform state backend (S3 + DynamoDB lock), IAM least-privilege.</li> </ul>"},{"location":"technical-manual/architecture-blueprint/#8-schema-interface-governance-roadmap-next-iteration","title":"8. Schema &amp; Interface Governance Roadmap (Next Iteration)","text":"<ul> <li>Adopt versioned JSONSchema files per event type (<code>schemas/events/&lt;name&gt;.v1.json</code>).</li> <li>Pre\u2011commit validation &amp; CI check for breaking changes (semantic diff tool).</li> <li>Introduce compatibility matrix document enumerating allowed evolution rules (additive only until major bump).</li> </ul>"},{"location":"technical-manual/architecture-blueprint/#9-future-centralization-targets","title":"9. Future Centralization Targets","text":"<ol> <li>Unified Config Service: gRPC/HTTP publishing config versions \u2192 produces <code>config_updates</code> + maintains audit log.</li> <li>Message Envelope Standard: Add headers {trace_id, span_id, tenant_id, schema_version} for every Kafka message.</li> <li>Telemetry Correlation: Link tool execution \u2192 memory write \u2192 user response chain via shared trace.</li> <li>Vector Store Abstraction: Pluggable embedding/memory backend interface (SomaBrain default; add alternatives).</li> <li>Unified Policy Layer: Consolidate OPA/FGA decisions into a single composite engine with caching &amp; metrics.</li> </ol>"},{"location":"technical-manual/architecture-blueprint/#10-immediate-action-backlog-derivable-from-blueprint","title":"10. Immediate Action Backlog (Derivable from Blueprint)","text":"<ul> <li>Implement Kafka trace header propagation.</li> <li>Standardize health readiness endpoints across services.</li> <li>Add graceful shutdown (SIGTERM handlers) draining consumers &amp; closing httpx clients.</li> <li>Introduce schema registry folder + CI validator.</li> <li>Build config service MVP (emit <code>config_updates</code>).</li> <li>Harden tool sandbox (resource caps + timeouts central policy).</li> <li>Add encryption (at rest) strategy doc &amp; Vault integration scaffold.</li> <li>Expand rate limiting to tenant/API key dimension.</li> <li>Create K8s Helm chart prototypes per service with values schema.</li> </ul> <p>This blueprint will evolve; subsequent versions will add diagrams, explicit sequence charts, and performance SLO definitions.</p>"},{"location":"technical-manual/architecture/","title":"Architecture","text":"<p>Standards: ISO/IEC 42010</p>"},{"location":"technical-manual/architecture/#system-context","title":"System Context","text":"<p>SomaAgent01 is a distributed conversational AI platform using microservices architecture with event-driven communication via Kafka.</p>"},{"location":"technical-manual/architecture/#components","title":"Components","text":""},{"location":"technical-manual/architecture/#gateway-servicesgatewaymainpy","title":"Gateway (<code>services/gateway/main.py</code>)","text":"<p>Purpose: Public-facing HTTP API with SSE streaming</p> <p>Responsibilities: - Accept user messages via POST /v1/session/message - Publish to conversation.inbound topic - Stream responses from conversation.outbound via SSE (WebSocket may be added later) - Authenticate requests (JWT/API keys) - Enforce OPA policies - Manage sessions in PostgreSQL - Cache session metadata in Redis</p> <p>Technology: FastAPI, aiokafka, asyncpg, redis-py</p> <p>Ports: - HTTP: 21016 (default; configurable via <code>GATEWAY_PORT</code>) - Metrics: 9600 (Prometheus)</p>"},{"location":"technical-manual/architecture/#conversation-worker-servicesconversation_workermainpy","title":"Conversation Worker (<code>services/conversation_worker/main.py</code>)","text":"<p>Purpose: Process user messages and generate responses</p> <p>Responsibilities: - Consume conversation.inbound topic - Analyze message intent/sentiment - Fetch conversation history from PostgreSQL - Call SLM (OpenAI-compatible API) for response generation - Publish response to conversation.outbound - Write user and assistant messages to SomaBrain via HTTP - Emit memory.wal events - Handle escalation to larger models - Track token budgets per tenant/persona</p> <p>Technology: aiokafka, httpx, asyncpg</p> <p>Metrics: 9601</p>"},{"location":"technical-manual/architecture/#tool-executor-servicestool_executormainpy","title":"Tool Executor (<code>services/tool_executor/main.py</code>)","text":"<p>Purpose: Execute tools requested by conversation worker</p> <p>Responsibilities: - Consume tool.requests topic - Execute tool functions (code execution, web search, etc.) - Publish results to tool.results topic - Sandbox execution environment</p> <p>Technology: aiokafka, subprocess</p> <p>Metrics: 9602</p>"},{"location":"technical-manual/architecture/#memory-replicator-servicesmemory_replicatormainpy","title":"Memory Replicator (<code>services/memory_replicator/main.py</code>)","text":"<p>Purpose: Replicate memory events to PostgreSQL</p> <p>Responsibilities: - Consume memory.wal topic - Insert events into memory_replica table - Track replication lag - Send failed events to memory.wal.dlq</p> <p>Technology: aiokafka, asyncpg</p> <p>Metrics: 9603</p>"},{"location":"technical-manual/architecture/#memory-sync-servicesmemory_syncmainpy","title":"Memory Sync (<code>services/memory_sync/main.py</code>)","text":"<p>Purpose: Retry failed memory writes</p> <p>Responsibilities: - Poll memory_write_outbox table - Retry SomaBrain HTTP calls - Emit memory.wal on success - Exponential backoff for retries</p> <p>Technology: asyncpg, httpx</p> <p>Metrics: 9604</p>"},{"location":"technical-manual/architecture/#outbox-sync-servicesoutbox_syncmainpy","title":"Outbox Sync (<code>services/outbox_sync/main.py</code>)","text":"<p>Purpose: Retry failed Kafka publishes</p> <p>Responsibilities: - Poll outbox table - Retry Kafka publish - Delete on success - Exponential backoff</p> <p>Technology: aiokafka, asyncpg</p> <p>Metrics: 9415</p>"},{"location":"technical-manual/architecture/#data-stores","title":"Data Stores","text":""},{"location":"technical-manual/architecture/#postgresql","title":"PostgreSQL","text":"<p>Schema: - <code>sessions</code>: session_id, persona_id, tenant, metadata, created_at, updated_at - <code>session_events</code>: id, session_id, occurred_at, payload - <code>outbox</code>: id, topic, payload, dedupe_key, created_at, published_at - <code>memory_replica</code>: id, event_id, session_id, persona_id, tenant, role, payload, wal_timestamp, created_at - <code>memory_write_outbox</code>: id, payload, tenant, session_id, persona_id, idempotency_key, created_at, retry_count - <code>dlq</code>: id, topic, event, error, created_at - <code>model_profiles</code>: role, deployment_mode, model, base_url, temperature, kwargs - <code>ui_settings</code>: id, document (JSONB) - <code>attachments</code>: id, tenant, session_id, filename, mime, size, sha256, status, content, created_at</p>"},{"location":"technical-manual/architecture/#redis","title":"Redis","text":"<p>Keys: - <code>session:{session_id}:meta</code>: Session metadata cache - <code>api_key:{key_id}</code>: API key details - <code>llm_cred:{provider}</code>: Encrypted LLM credentials (Fernet) - <code>budget:{tenant}:{persona_id}</code>: Token usage counters</p>"},{"location":"technical-manual/architecture/#kafka","title":"Kafka","text":"<p>Configuration: - Mode: KRaft (no Zookeeper) - Partitions: 3 per topic - Replication: 1 (single broker) - Retention: 168 hours (7 days)</p>"},{"location":"technical-manual/architecture/#communication-patterns","title":"Communication Patterns","text":""},{"location":"technical-manual/architecture/#request-response-http","title":"Request-Response (HTTP)","text":"<pre><code>Client \u2192 Gateway \u2192 SomaBrain HTTP API\n</code></pre>"},{"location":"technical-manual/architecture/#event-driven-kafka","title":"Event-Driven (Kafka)","text":"<pre><code>Gateway \u2192 conversation.inbound \u2192 Conversation Worker \u2192 conversation.outbound \u2192 Gateway\n</code></pre>"},{"location":"technical-manual/architecture/#outbox-pattern","title":"Outbox Pattern","text":"<pre><code>Service \u2192 PostgreSQL outbox \u2192 Outbox Sync \u2192 Kafka\n</code></pre>"},{"location":"technical-manual/architecture/#deployment-modes","title":"Deployment Modes","text":"<ul> <li>DEV: Local development, env-based LLM keys</li> <li>STAGING: Pre-production, Gateway-managed credentials</li> <li>PROD: Production, Gateway-managed credentials, strict auth</li> </ul>"},{"location":"technical-manual/architecture/#observability","title":"Observability","text":"<ul> <li>Metrics: Prometheus (per-service ports 9600-9610)</li> <li>Tracing: OpenTelemetry (OTLP endpoint configurable)</li> <li>Logging: Structured JSON logs to stdout</li> </ul>"},{"location":"technical-manual/architecture/#standards-compliance","title":"Standards Compliance","text":"<ul> <li>ISO/IEC 42010: Architecture viewpoints (functional, deployment, information)</li> <li>ISO/IEC 12207\u00a76.3.3: Software architectural design</li> </ul>"},{"location":"technical-manual/config-registry/","title":"Config Registry Plan","text":""},{"location":"technical-manual/config-registry/#intent","title":"Intent","text":"<p>Centralize runtime configuration with validation, layering, and safe rollouts.</p>"},{"location":"technical-manual/config-registry/#interface","title":"Interface","text":"<ul> <li><code>ConfigRegistry(schema)</code>: holds a validated snapshot (<code>version</code>, <code>checksum</code>, <code>payload</code>).</li> <li><code>load_defaults(payload)</code>: initialize from defaults (files/env-derived), validates against schema.</li> <li><code>apply_update(payload)</code>: validate and apply remote update; notifies subscribers.</li> <li><code>subscribe(callback)</code>: receive applied snapshots.</li> <li><code>build_ack(result, error=None)</code>: helper to emit ack events (published by caller).</li> </ul>"},{"location":"technical-manual/config-registry/#schema","title":"Schema","text":"<ul> <li>JSON Schema at <code>schemas/config/registry.v1.schema.json</code> defines overlays for <code>uploads</code>, <code>antivirus</code>, <code>speech</code>, plus <code>secrets</code> (reference keys) and <code>feature_flags</code>.</li> </ul>"},{"location":"technical-manual/config-registry/#transport-rollout","title":"Transport &amp; Rollout","text":"<ul> <li>Publisher: gateway admin tool or CI job posts config to topic <code>config_updates</code>.</li> <li>Consumer: gateway <code>_config_update_listener</code> parses event and calls <code>ConfigRegistry.apply_update</code> then publishes ack to <code>config_updates.ack</code>.</li> <li>Rollback: re-publish prior <code>version</code> snapshot.</li> </ul>"},{"location":"technical-manual/config-registry/#metrics","title":"Metrics","text":"<ul> <li><code>config_update_apply_total{result}</code>: ok|rejected|error.</li> <li><code>config_update_version_info</code>: gauge label for current version.</li> </ul>"},{"location":"technical-manual/config-registry/#next-steps","title":"Next Steps","text":"<ol> <li>Wire <code>ConfigRegistry</code> into gateway startup; store at <code>app.state.config_registry</code>.</li> <li>Expand schema as more overlays are standardized (rate limit, realtime, tools).</li> <li>Add admin endpoint <code>POST /v1/admin/config/apply</code> (authz guarded) to trigger updates in dev.</li> </ol>"},{"location":"technical-manual/deployment/","title":"Deployment Guide","text":"<p>Standards: ISO/IEC 12207\u00a76.4</p>"},{"location":"technical-manual/deployment/#deployment-modes","title":"Deployment Modes","text":""},{"location":"technical-manual/deployment/#dev-local-development","title":"DEV (Local Development)","text":"<p>Purpose: Local development and testing</p> <p>Configuration: <pre><code># .env\nDEPLOYMENT_MODE=DEV\nAUTH_ENABLED=false\nOPENROUTER_API_KEY=&lt;your-key&gt;\n</code></pre></p> <p>Start: <pre><code>make deps-up\nmake stack-up\nmake ui\n</code></pre></p>"},{"location":"technical-manual/deployment/#staging-pre-production","title":"STAGING (Pre-Production)","text":"<p>Purpose: Integration testing, QA validation</p> <p>Configuration: <pre><code># .env\nDEPLOYMENT_MODE=STAGING\nAUTH_ENABLED=true\nJWT_SECRET=&lt;random-256-bit-key&gt;\nGATEWAY_MANAGED_CREDENTIALS=true\n</code></pre></p> <p>Deploy: <pre><code># Recommended: Kubernetes (staging overlay)\nkubectl apply -k infra/k8s/overlays/staging/\n\n# Or: Docker Compose using the base manifest with env overrides\n# (No dedicated staging compose file is provided.)\ndocker compose up -d\n</code></pre></p>"},{"location":"technical-manual/deployment/#prod-production","title":"PROD (Production)","text":"<p>Purpose: Live production environment</p> <p>Configuration: <pre><code># .env (use secrets manager in production)\nDEPLOYMENT_MODE=PROD\nAUTH_ENABLED=true\nJWT_SECRET=&lt;vault://secret/jwt-secret&gt;\nOPENROUTER_API_KEY=&lt;vault://secret/openrouter-key&gt;\nTLS_ENABLED=true\n</code></pre></p> <p>Deploy: <pre><code># Using Helm\nhelm upgrade --install soma-stack infra/helm/soma-stack/ \\\n  --namespace production \\\n  --values infra/helm/overlays/prod/values.yaml\n\n# Verify\nkubectl get pods -n production\nkubectl logs -n production deployment/gateway\n</code></pre></p>"},{"location":"technical-manual/deployment/#infrastructure-requirements","title":"Infrastructure Requirements","text":""},{"location":"technical-manual/deployment/#minimum-resources","title":"Minimum Resources","text":"Component CPU Memory Storage Gateway 0.5 512MB - Conversation Worker 1.0 1GB - Tool Executor 0.5 512MB - Kafka 1.0 2GB 10GB PostgreSQL 1.0 2GB 20GB Redis 0.5 512MB 1GB"},{"location":"technical-manual/deployment/#recommended-resources-production","title":"Recommended Resources (Production)","text":"Component CPU Memory Storage Replicas Gateway 2.0 2GB - 3 Conversation Worker 2.0 4GB - 5 Tool Executor 1.0 2GB - 3 Kafka 4.0 8GB 100GB 3 PostgreSQL 4.0 8GB 200GB 1 (with replicas) Redis 2.0 4GB 10GB 1 (with sentinel)"},{"location":"technical-manual/deployment/#environment-variables","title":"Environment Variables","text":""},{"location":"technical-manual/deployment/#required","title":"Required","text":"Variable Description Example <code>DEPLOYMENT_MODE</code> Deployment environment <code>DEV</code>, <code>STAGING</code>, <code>PROD</code> <code>OPENROUTER_API_KEY</code> LLM provider API key <code>sk-or-v1-...</code> <code>AUTH_PASSWORD</code> UI authentication password <code>&lt;strong-password&gt;</code> <code>POSTGRES_PASSWORD</code> PostgreSQL password <code>&lt;random-password&gt;</code>"},{"location":"technical-manual/deployment/#optional","title":"Optional","text":"Variable Description Default <code>GATEWAY_PORT</code> Gateway HTTP port <code>21016</code> <code>KAFKA_BOOTSTRAP_SERVERS</code> Kafka brokers <code>localhost:20000</code> <code>REDIS_URL</code> Redis connection URL <code>redis://localhost:20001</code> <code>SOMABRAIN_BASE_URL</code> Memory service URL <code>http://localhost:9696</code> <code>LOG_LEVEL</code> Logging level <code>INFO</code>"},{"location":"technical-manual/deployment/#docker-compose-deployment","title":"Docker Compose Deployment","text":""},{"location":"technical-manual/deployment/#single-node-setup","title":"Single-Node Setup","text":"<pre><code># 1. Configure environment\ncp .env.example .env\nnano .env\n\n# 2. Start stack\ndocker compose up -d\n\n# 3. Verify\ndocker compose ps\ncurl http://localhost:${GATEWAY_PORT:-21016}/v1/health\n</code></pre>"},{"location":"technical-manual/deployment/#multi-node-setup","title":"Multi-Node Setup","text":"<pre><code># 1. Start infrastructure on node1\ndocker compose -f infra/docker/shared-infra.compose.yaml up -d\n\n# 2. Start services on node2, node3\nexport KAFKA_BOOTSTRAP_SERVERS=node1:20000\nexport POSTGRES_HOST=node1\nexport REDIS_URL=redis://node1:20001\n\ndocker compose up -d gateway conversation-worker tool-executor\n</code></pre>"},{"location":"technical-manual/deployment/#kubernetes-deployment","title":"Kubernetes Deployment","text":""},{"location":"technical-manual/deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes 1.24+</li> <li>Helm 3.10+</li> <li>kubectl configured</li> </ul>"},{"location":"technical-manual/deployment/#deploy-with-helm","title":"Deploy with Helm","text":"<pre><code># 1. Add Helm repository (if external)\nhelm repo add soma https://charts.somaagent01.ai\nhelm repo update\n\n# 2. Create namespace\nkubectl create namespace somaagent01\n\n# 3. Install\nhelm install soma-stack infra/helm/soma-stack/ \\\n  --namespace somaagent01 \\\n  --values infra/helm/overlays/prod/values.yaml\n\n# 4. Verify\nkubectl get pods -n somaagent01\nkubectl get svc -n somaagent01\n</code></pre>"},{"location":"technical-manual/deployment/#deploy-with-kustomize","title":"Deploy with Kustomize","text":"<pre><code># 1. Apply base + overlay\nkubectl apply -k infra/k8s/overlays/prod/\n\n# 2. Verify\nkubectl get all -n somaagent01\n\n# 3. Check logs\nkubectl logs -n somaagent01 deployment/gateway -f\n</code></pre>"},{"location":"technical-manual/deployment/#monitoring-setup","title":"Monitoring Setup","text":""},{"location":"technical-manual/deployment/#prometheus","title":"Prometheus","text":"<pre><code># Deploy Prometheus\nkubectl apply -f infra/observability/prometheus.yml\n\n# Verify scrape targets\nkubectl port-forward -n monitoring svc/prometheus 9090:9090\n# Visit http://localhost:9090/targets\n</code></pre>"},{"location":"technical-manual/deployment/#grafana","title":"Grafana","text":"<pre><code># Deploy Grafana (external)\n# Import dashboards from observability project\n# Point at Prometheus: http://prometheus.monitoring.svc:9090\n</code></pre>"},{"location":"technical-manual/deployment/#alertmanager","title":"Alertmanager","text":"<pre><code># Deploy Alertmanager\nkubectl apply -f infra/observability/alertmanager.yml\n\n# Configure alerts\nkubectl apply -f infra/observability/alerts.yml\n</code></pre>"},{"location":"technical-manual/deployment/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"technical-manual/deployment/#postgresql-backup","title":"PostgreSQL Backup","text":"<pre><code># Manual backup\ndocker compose exec postgres pg_dump -U somauser somadb &gt; backup.sql\n\n# Automated backup (cron)\n0 2 * * * docker compose exec postgres pg_dump -U somauser somadb | gzip &gt; /backups/somadb-$(date +\\%Y\\%m\\%d).sql.gz\n</code></pre>"},{"location":"technical-manual/deployment/#restore","title":"Restore","text":"<pre><code># Restore from backup\ndocker compose exec -T postgres psql -U somauser somadb &lt; backup.sql\n</code></pre>"},{"location":"technical-manual/deployment/#kafka-topic-backup","title":"Kafka Topic Backup","text":"<pre><code># Export topic data\ndocker compose exec kafka kafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic conversation.inbound \\\n  --from-beginning \\\n  --max-messages 10000 &gt; topic-backup.json\n</code></pre>"},{"location":"technical-manual/deployment/#security-hardening","title":"Security Hardening","text":""},{"location":"technical-manual/deployment/#tls-configuration","title":"TLS Configuration","text":"<pre><code># docker-compose.yaml\nservices:\n  gateway:\n    environment:\n      - TLS_ENABLED=true\n      - TLS_CERT_PATH=/certs/server.crt\n      - TLS_KEY_PATH=/certs/server.key\n    volumes:\n      - ./certs:/certs:ro\n</code></pre>"},{"location":"technical-manual/deployment/#network-isolation","title":"Network Isolation","text":"<pre><code># docker-compose.yaml\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n    internal: true\n\nservices:\n  gateway:\n    networks:\n      - frontend\n      - backend\n  postgres:\n    networks:\n      - backend\n</code></pre>"},{"location":"technical-manual/deployment/#secrets-management","title":"Secrets Management","text":"<pre><code># Using Docker secrets\necho \"my-secret-key\" | docker secret create jwt_secret -\n\n# Reference in compose\nservices:\n  gateway:\n    secrets:\n      - jwt_secret\n    environment:\n      - JWT_SECRET_FILE=/run/secrets/jwt_secret\n</code></pre>"},{"location":"technical-manual/deployment/#scaling","title":"Scaling","text":""},{"location":"technical-manual/deployment/#horizontal-scaling","title":"Horizontal Scaling","text":"<pre><code># Scale conversation workers\ndocker compose up -d --scale conversation-worker=5\n\n# Kubernetes\nkubectl scale deployment conversation-worker --replicas=5 -n somaagent01\n</code></pre>"},{"location":"technical-manual/deployment/#vertical-scaling","title":"Vertical Scaling","text":"<pre><code># docker-compose.yaml\nservices:\n  conversation-worker:\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 4G\n        reservations:\n          cpus: '1.0'\n          memory: 2G\n</code></pre>"},{"location":"technical-manual/deployment/#health-checks","title":"Health Checks","text":""},{"location":"technical-manual/deployment/#liveness-probes","title":"Liveness Probes","text":"<pre><code># Kubernetes\nlivenessProbe:\n  httpGet:\n    path: /v1/health\n    port: 21016\n  initialDelaySeconds: 30\n  periodSeconds: 10\n</code></pre>"},{"location":"technical-manual/deployment/#readiness-probes","title":"Readiness Probes","text":"<pre><code>readinessProbe:\n  httpGet:\n    path: /v1/ready\n    port: 21016\n  initialDelaySeconds: 10\n  periodSeconds: 5\n</code></pre>"},{"location":"technical-manual/deployment/#rollback-procedures","title":"Rollback Procedures","text":""},{"location":"technical-manual/deployment/#docker-compose","title":"Docker Compose","text":"<pre><code># Rollback to previous version\ndocker compose down\ngit checkout &lt;previous-tag&gt;\ndocker compose up -d\n</code></pre>"},{"location":"technical-manual/deployment/#kubernetes","title":"Kubernetes","text":"<pre><code># Rollback deployment\nkubectl rollout undo deployment/gateway -n somaagent01\n\n# Check rollout status\nkubectl rollout status deployment/gateway -n somaagent01\n</code></pre>"},{"location":"technical-manual/deployment/#helm","title":"Helm","text":"<pre><code># Rollback release\nhelm rollback soma-stack -n somaagent01\n\n# Rollback to specific revision\nhelm rollback soma-stack 3 -n somaagent01\n</code></pre>"},{"location":"technical-manual/developer-mode-parity/","title":"Developer Mode Parity Plan","text":""},{"location":"technical-manual/developer-mode-parity/#goals","title":"Goals","text":"<ul> <li>Local environment behavior mirrors production features (flags, rate limits, topic names) with safe defaults.</li> <li>Simple onboarding: one <code>make dev</code> brings up all required dependencies.</li> <li>Deterministic seeds for profiles, tool catalog entries, tenants, feature flags.</li> </ul>"},{"location":"technical-manual/developer-mode-parity/#compose-profiles","title":"Compose Profiles","text":"<ul> <li><code>docker-compose.yaml</code> base: add <code>profiles:</code> for optional services (clamav, somabrain mock, tracing collector, grafana).</li> <li><code>docker-compose.dev.yaml</code> overlay: mounts source, enables watch reload, exposes metrics ports.</li> </ul>"},{"location":"technical-manual/developer-mode-parity/#make-targets","title":"Make Targets","text":"<ul> <li><code>make dev</code>: build images (or use host .venv), start compose with dev profile.</li> <li><code>make seed</code>: run seed script for model profiles, tool catalog, API keys.</li> <li><code>make test-fast</code>: run unit tests excluding integration requiring external services.</li> </ul>"},{"location":"technical-manual/developer-mode-parity/#feature-flags","title":"Feature Flags","text":"<p>Expose environment or config registry overlays with defaults: - <code>GATEWAY_WRITE_THROUGH</code> false by default. - <code>SA01_ENABLE_TOOL_EVENTS</code> false. - <code>speech_realtime_enabled</code> false.</p>"},{"location":"technical-manual/developer-mode-parity/#tooling","title":"Tooling","text":"<ul> <li>Add <code>scripts/seed_dev_data.py</code> populating: profiles, a test API key, sample notification.</li> <li>Provide <code>.env.example</code> listing required variables with comments.</li> </ul>"},{"location":"technical-manual/developer-mode-parity/#debugging-observability","title":"Debugging &amp; Observability","text":"<ul> <li>Enable verbose logging + trace sampling (100%) in dev.</li> <li>Expose Prometheus and Jaeger/Tempo ports.</li> <li>Provide <code>scripts/trace_dump.py</code> to query recent spans via OTLP exporter fallback.</li> </ul>"},{"location":"technical-manual/developer-mode-parity/#next-steps","title":"Next Steps","text":"<ol> <li>Add compose dev profile scaffolds.</li> <li>Add seed script and Make target.</li> <li>Add .env.example file.</li> <li>Document workflow in README.</li> </ol>"},{"location":"technical-manual/eventing-standards/","title":"Eventing &amp; Streaming Standards","text":""},{"location":"technical-manual/eventing-standards/#topics-naming","title":"Topics &amp; Naming","text":"<ul> <li>Prefix by domain and bounded context: <code>somastack.&lt;domain&gt;.&lt;entity&gt;[.&lt;suffix&gt;]</code>.</li> <li>Examples: <code>somastack.delegation</code>, <code>memory.wal</code>, <code>ui.notifications</code>, <code>somastack.config.updates</code>.</li> <li>Dead-letter: <code>&lt;topic&gt;.dlq</code> with same keying.</li> </ul>"},{"location":"technical-manual/eventing-standards/#schemas","title":"Schemas","text":"<ul> <li>Versioned JSON Schemas stored under <code>schemas/&lt;domain&gt;/...vN.schema.json</code>.</li> <li>Payload must include:</li> <li><code>type</code>: stable string code (e.g., <code>ui.notification</code>).</li> <li><code>ts</code>: producer timestamp ISO-8601 (optional, consumers may add).</li> <li><code>trace.trace_id</code> and <code>trace.span_id</code> (redundant to headers).</li> <li>Backward compatibility: only additive changes in same version; breaking change \u21d2 bump version &amp; topic suffix <code>.v2</code> or embed <code>schema_version</code>.</li> </ul>"},{"location":"technical-manual/eventing-standards/#headers","title":"Headers","text":"<ul> <li>Required: <code>traceparent</code> (W3C), optional <code>tracestate</code>.</li> <li>Compatibility: also include <code>trace_id</code> and <code>span_id</code> for systems without W3C parsing.</li> <li>Optional multi-tenancy: <code>tenant</code> header when applicable.</li> </ul>"},{"location":"technical-manual/eventing-standards/#keys-ordering","title":"Keys &amp; Ordering","text":"<ul> <li>Use a deterministic key to preserve per-entity ordering:</li> <li>Delegation: <code>task_id</code>.</li> <li>Memory WAL: <code>session_id</code> or <code>persona_id</code>.</li> <li>Notifications: <code>tenant_id</code>.</li> </ul>"},{"location":"technical-manual/eventing-standards/#consumer-groups","title":"Consumer Groups","text":"<ul> <li>One group per service role (e.g., <code>delegation-worker</code>, <code>memory-replicator</code>).</li> <li>Scale horizontally by increasing partitions and replicas within same group.</li> </ul>"},{"location":"technical-manual/eventing-standards/#backpressure-retries","title":"Backpressure &amp; Retries","text":"<ul> <li>Consumers must handle transient failures with bounded retries and DLQ on exceed.</li> <li>Use exponential backoff with jitter for reprocessing.</li> <li>Producers should use outbox pattern (already present) for reliability.</li> </ul>"},{"location":"technical-manual/eventing-standards/#observability","title":"Observability","text":"<ul> <li>Start a PRODUCER span for publish and a CONSUMER span for handle.</li> <li>Propagate <code>traceparent</code> header; mirror into payload <code>trace</code> for logs.</li> <li>Metrics:</li> <li><code>events_published_total{topic}</code></li> <li><code>events_consumed_total{topic}</code></li> <li><code>event_handle_latency_seconds{topic}</code></li> <li><code>dlq_total{topic}</code></li> </ul>"},{"location":"technical-manual/eventing-standards/#governance","title":"Governance","text":"<ul> <li>PR checklist for new topics:</li> <li>Schema file added + docs.</li> <li>Sample payloads provided.</li> <li>Key selection rationale.</li> <li>Backward &amp; forward compatibility notes.</li> </ul>"},{"location":"technical-manual/eventing-standards/#testing","title":"Testing","text":"<ul> <li>Unit: schema validate and header presence.</li> <li>Integration: round-trip publish/consume with traced context in a test kafka (or mocked bus).</li> </ul>"},{"location":"technical-manual/export-jobs/","title":"Export Jobs","text":"<p>This page describes asynchronous memory export jobs handled by the Gateway.</p>"},{"location":"technical-manual/export-jobs/#what-they-do","title":"What They Do","text":"<p>Export jobs produce an NDJSON file of memory replica rows that match your filters. They run in the background and you can poll for status and download when complete.</p> <ul> <li>Format: NDJSON (one JSON object per line)</li> <li>Scope: Rows from the memory replica (read-only view)</li> <li>Filters: <code>tenant</code>, <code>persona_id</code>, <code>role</code>, <code>session_id</code>, <code>universe</code>, <code>namespace</code>, text <code>q</code>, time range (<code>min_ts</code>, <code>max_ts</code>), and an optional <code>limit_total</code></li> </ul>"},{"location":"technical-manual/export-jobs/#enabling-export-jobs","title":"Enabling Export Jobs","text":"<p>By default, local file writes are disabled and the export runner is off. Enable with environment flags:</p> <ul> <li><code>DISABLE_FILE_SAVING=false</code> (or <code>GATEWAY_DISABLE_FILE_SAVING=false</code>)</li> <li><code>EXPORT_JOBS_ENABLED=true</code></li> <li>Optional:</li> <li><code>EXPORT_JOBS_DIR=/data/exports</code> (default: <code>/tmp/soma_export_jobs</code>)</li> <li><code>EXPORT_JOBS_MAX_ROWS=100000</code> (upper bound)</li> <li><code>EXPORT_JOBS_PAGE_SIZE=1000</code> (DB page size)</li> <li><code>EXPORT_JOBS_CONCURRENCY=1</code> (worker concurrency)</li> <li><code>EXPORT_JOBS_POLL_SECONDS=2</code> (queue poll interval)</li> <li><code>GATEWAY_EXPORT_REQUIRE_TENANT=true</code> to require a <code>tenant</code> in job params</li> </ul> <p>The runner starts automatically in the Gateway when <code>EXPORT_JOBS_ENABLED=true</code> and file saving is enabled.</p>"},{"location":"technical-manual/export-jobs/#endpoints","title":"Endpoints","text":"<p>All endpoints are policy-gated. Admin scope is required when auth is enabled. File saving must be enabled.</p> <ul> <li>POST <code>/v1/memory/export/jobs</code> \u2014 create a job</li> <li>GET <code>/v1/memory/export/jobs/{job_id}</code> \u2014 get status</li> <li>GET <code>/v1/memory/export/jobs/{job_id}/download</code> \u2014 download NDJSON file (when completed)</li> </ul>"},{"location":"technical-manual/export-jobs/#create-job","title":"Create Job","text":"<p>Request body (any subset): <pre><code>{\n  \"tenant\": \"acme\",\n  \"persona_id\": \"default\",\n  \"role\": \"assistant\",\n  \"session_id\": \"abc123\",\n  \"universe\": \"u1\",\n  \"namespace\": \"wm\",\n  \"q\": \"error OR timeout\",\n  \"min_ts\": 1730937600,\n  \"max_ts\": 1731024000,\n  \"limit_total\": 50000\n}\n</code></pre></p> <p>Response: <pre><code>{ \"job_id\": 42, \"status\": \"queued\" }\n</code></pre></p> <p>Curl example: <pre><code>curl -s -X POST http://localhost:21016/v1/memory/export/jobs \\\n  -H 'Content-Type: application/json' \\\n  -H 'Authorization: Bearer &lt;admin-jwt&gt;' \\\n  -d '{\"tenant\":\"acme\",\"q\":\"timeout\",\"limit_total\":2000}'\n</code></pre></p>"},{"location":"technical-manual/export-jobs/#check-status","title":"Check Status","text":"<p>Response contains a <code>download_url</code> when ready: <pre><code>{\n  \"id\": 42,\n  \"status\": \"completed\",\n  \"row_count\": 1987,\n  \"byte_size\": 4123456,\n  \"download_url\": \"/v1/memory/export/jobs/42/download\"\n}\n</code></pre></p> <p>Curl example: <pre><code>curl -s http://localhost:21016/v1/memory/export/jobs/42 \\\n  -H 'Authorization: Bearer &lt;admin-jwt&gt;' | jq .\n</code></pre></p>"},{"location":"technical-manual/export-jobs/#download-file","title":"Download File","text":"<p>Content type is <code>application/x-ndjson</code>. <pre><code>curl -L http://localhost:21016/v1/memory/export/jobs/42/download \\\n  -H 'Authorization: Bearer &lt;admin-jwt&gt;' -o export_42.ndjson\n</code></pre></p>"},{"location":"technical-manual/export-jobs/#file-contents","title":"File Contents","text":"<p>Each line is a JSON object with the following fields: <pre><code>{\n  \"id\": 123,\n  \"event_id\": \"evt_...\",\n  \"session_id\": \"abc123\",\n  \"persona_id\": \"default\",\n  \"tenant\": \"acme\",\n  \"role\": \"assistant\",\n  \"coord\": \"...\",\n  \"request_id\": \"...\",\n  \"trace_id\": \"...\",\n  \"wal_timestamp\": 1731000000.123,\n  \"created_at\": \"2025-11-07T10:00:00.000Z\",\n  \"payload\": { /* original memory payload */ }\n}\n</code></pre></p>"},{"location":"technical-manual/export-jobs/#operational-notes","title":"Operational Notes","text":"<ul> <li>Jobs are queued in Postgres and processed by a lightweight in-process worker.</li> <li>Runner concurrency is controlled via <code>EXPORT_JOBS_CONCURRENCY</code>.</li> <li>Exports are written atomically using a <code>*.part</code> temp file then <code>os.replace</code>.</li> <li>If a job fails, status moves to <code>failed</code> and the <code>error</code> string is set.</li> <li>Download may return 410 if the file was removed (e.g., after cleanup).</li> </ul>"},{"location":"technical-manual/export-jobs/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>403 \"File export is disabled\": ensure <code>DISABLE_FILE_SAVING=false</code>.</li> <li>400 \"tenant parameter required\": set <code>GATEWAY_EXPORT_REQUIRE_TENANT=false</code> or include <code>tenant</code>.</li> <li>409 \"job not completed\": wait for <code>status=completed</code>.</li> <li>Runner not starting: set <code>EXPORT_JOBS_ENABLED=true</code>; check Gateway logs for schema init.</li> </ul>"},{"location":"technical-manual/features/","title":"Feature Capability Registry (Draft Schema)","text":"<p>Status: Draft (Sprint 0) Owner: Architecture / Platform Team Last Updated: 2025-11-09</p>"},{"location":"technical-manual/features/#purpose","title":"Purpose","text":"<p>Centralize all feature toggles and rollout controls into a typed, observable registry. Replace scattered <code>os.getenv</code> checks with a single source of truth supporting profiles (minimal, standard, enhanced, max) and health-aware degrade strategies.</p>"},{"location":"technical-manual/features/#objectives","title":"Objectives","text":"<ul> <li>Best mode enabled by default (profile: <code>enhanced</code>).</li> <li>Health-aware auto-degrade (error/latency thresholds) instead of manual flag flapping.</li> <li>Auditable transitions (enabled \u2192 degraded \u2192 disabled) with reason codes.</li> <li>Metrics &amp; diagnostics endpoint for real-time visibility.</li> <li>Backward compatibility: environment variables still honored during migration phase; deprecated after Sprint 1 exit gate.</li> </ul>"},{"location":"technical-manual/features/#descriptor-schema","title":"Descriptor Schema","text":"<p>Each capability is represented by a <code>FeatureDescriptor</code> object.</p> Field Type Required Description <code>key</code> <code>str</code> yes Unique machine-readable identifier (snake_case). <code>description</code> <code>str</code> yes Concise human description (&lt;=120 chars). <code>default_enabled</code> <code>bool</code> yes Base on/off before profile &amp; dependency evaluation. <code>profiles</code> <code>dict[str,bool]</code> yes Override enable state per profile (<code>minimal</code>, <code>standard</code>, <code>enhanced</code>, <code>max</code>). <code>dependencies</code> <code>list[str]</code> no Other feature keys that must be enabled and healthy. <code>degrade_strategy</code> <code>str</code> yes One of: <code>auto</code>, <code>manual</code>, <code>none</code>. <code>auto</code> allows health-based transition. <code>cost_impact</code> <code>str</code> yes <code>low</code> <code>metrics_key</code> <code>str</code> yes Key suffix for Prometheus labels (e.g. <code>embeddings_ingest</code>). <code>tags</code> <code>list[str]</code> no Classification: <code>observability</code>, <code>security</code>, <code>performance</code>, <code>beta</code>. <code>enabled_env_var</code> <code>str</code> no Legacy env var that can override during migration. <code>stability</code> <code>str</code> yes <code>stable</code>, <code>beta</code>, <code>experimental</code>. <code>degrade_thresholds</code> <code>dict[str,float]</code> no Health thresholds (e.g. <code>{error_rate:0.05, p95_latency_ms:800}</code>) for auto degrade. <code>rollback_action</code> <code>str</code> no Summary of safe fallback when disabled/degraded. <code>audit_critical</code> <code>bool</code> yes If true, all state changes require explicit audit log entry."},{"location":"technical-manual/features/#state-model","title":"State Model","text":"<p><pre><code>          +-----------+            health breach / dependency fail\n    ON --&gt;| DEGRADING |----------------------------------+\n    ^     +-----------+                                   |\n    |            | (grace period / evaluation)            v\n    |            v                                   +---------+\nmanual disable   +-----------+   terminal or manual  | DISABLED|\nre-enable -----&gt; | DEGRADED  |----------------------&gt;+---------+\n                  +-----------+          |              ^\n                       | recovery       |              |\n                       +----------------+--------------+\n                                   health recovery / manual enable\n</code></pre> - <code>ON</code> \u2192 <code>DEGRADING</code>: system detects threshold breach; starts observation window. - <code>DEGRADING</code> \u2192 <code>DEGRADED</code>: confirm sustained breach; apply restricted mode/fallback. - <code>DEGRADED</code> \u2192 <code>ON</code>: health metrics back within thresholds for N consecutive windows. - <code>DEGRADED</code>/<code>ON</code> \u2192 <code>DISABLED</code>: manual action or hard failure (e.g., fatal config). Only manual path returns to <code>ON</code>.</p>"},{"location":"technical-manual/features/#metrics","title":"Metrics","text":"<p>Prometheus metrics (all labeled by <code>feature</code>): - <code>feature_enabled{feature}</code> gauge: 1 when ON, 0 otherwise. - <code>feature_degraded{feature}</code> gauge: 1 when DEGRADED, 0 otherwise. - <code>feature_state_transitions_total{feature,state}</code> counter. - <code>feature_health_error_rate{feature}</code> gauge (optional for auto features). - <code>feature_health_latency_p95_ms{feature}</code> gauge.</p>"},{"location":"technical-manual/features/#diagnostics-endpoint","title":"Diagnostics Endpoint","text":"<p><code>GET /v1/features</code> returns: <pre><code>{\n  \"profile\": \"enhanced\",\n  \"features\": [\n    {\n      \"key\": \"embeddings_ingest\",\n      \"state\": \"on\",\n      \"degraded\": false,\n      \"stability\": \"beta\",\n      \"dependencies\": [],\n      \"error_rate\": 0.012,\n      \"p95_latency_ms\": 420,\n      \"reason\": null\n    },\n    {\n      \"key\": \"semantic_recall\",\n      \"state\": \"disabled\",\n      \"degraded\": false,\n      \"stability\": \"experimental\",\n      \"dependencies\": [\"embeddings_ingest\"],\n      \"reason\": \"profile:max only\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"technical-manual/features/#profiles","title":"Profiles","text":"Profile Intent Example Enabled Example Disabled minimal Critical core <code>conversation_flow</code>, <code>memory_write</code> <code>embeddings_ingest</code>, <code>semantic_recall</code> standard Production base + <code>tool_executor</code>, <code>scheduler</code> <code>semantic_recall</code> (beta) enhanced Full best mode + <code>embeddings_ingest</code>, <code>sandbox_usage_metrics</code> <code>semantic_recall</code> (experimental) max Advanced / experimental All including <code>semantic_recall</code> (none, unless forced)"},{"location":"technical-manual/features/#degrade-strategies","title":"Degrade Strategies","text":"Strategy Behavior auto Transition when thresholds breached; apply fallback (e.g. use cached embeddings only). manual Changes only via authorized admin action. none No degrade path; either ON or DISABLED (e.g. security-critical feature)."},{"location":"technical-manual/features/#example-descriptors","title":"Example Descriptors","text":"<pre><code>FeatureDescriptor(\n    key=\"embeddings_ingest\",\n    description=\"Generate vector embeddings for messages and tool outputs\",\n    default_enabled=True,\n    profiles={\"minimal\": False, \"standard\": True, \"enhanced\": True, \"max\": True},\n    dependencies=[],\n    degrade_strategy=\"auto\",\n    cost_impact=\"medium\",\n    metrics_key=\"embeddings_ingest\",\n    tags=[\"performance\", \"memory\"],\n    enabled_env_var=\"ENABLE_EMBED_ON_INGEST\",\n    stability=\"beta\",\n    degrade_thresholds={\"error_rate\": 0.05, \"p95_latency_ms\": 900},\n    rollback_action=\"Skip embedding generation; proceed without vector metadata\",\n    audit_critical=True,\n)\n\nFeatureDescriptor(\n    key=\"semantic_recall\",\n    description=\"Vector similarity recall for contextual memory injection\",\n    default_enabled=False,\n    profiles={\"minimal\": False, \"standard\": False, \"enhanced\": False, \"max\": True},\n    dependencies=[\"embeddings_ingest\"],\n    degrade_strategy=\"auto\",\n    cost_impact=\"high\",\n    metrics_key=\"semantic_recall\",\n    tags=[\"beta\", \"memory\"],\n    stability=\"experimental\",\n    degrade_thresholds={\"error_rate\": 0.07, \"p95_latency_ms\": 1200},\n    rollback_action=\"Fall back to recency + session-scoped heuristics\",\n    audit_critical=True,\n)\n</code></pre>"},{"location":"technical-manual/features/#audit-logging","title":"Audit &amp; Logging","text":"<p>On state transition emit structured log: <pre><code>{\"event\":\"feature_state_change\",\"feature\":\"embeddings_ingest\",\"from\":\"on\",\"to\":\"degraded\",\"reason\":\"error_rate&gt;0.05\",\"timestamp\":\"...\",\"profile\":\"enhanced\"}\n</code></pre> Audit entries include masked env overrides (not actual secret values).</p>"},{"location":"technical-manual/features/#migration-plan","title":"Migration Plan","text":"<ol> <li>Sprint 0: Document schema (this file), add lint rule plan.</li> <li>Sprint 1: Implement registry; dual-path env overrides; expose metrics &amp; diagnostics.</li> <li>Sprint 2: Remove direct env flag reads; enforce registry usage; finalize lint rule.</li> <li>Sprint 3+: Add auto-degrade watchers; integrate alerting &amp; dashboards.</li> </ol>"},{"location":"technical-manual/features/#lint-enforcement-strategy","title":"Lint / Enforcement Strategy","text":"<ul> <li>Add static check forbidding <code>os.getenv(\"ENABLE_\"</code> / <code>os.getenv(\"SA01_ENABLE_\"</code> outside registry after Sprint 2.</li> <li>Provide a suppress comment pattern for transitional exceptions (expires after date).</li> </ul>"},{"location":"technical-manual/features/#open-questions","title":"Open Questions","text":"<ul> <li>Persistence of last known states? (Initial approach: in-memory; future: lightweight store for restart continuity.)</li> <li>Multi-tenant overrides per feature? (Phase after unified config M10.)</li> <li>Cross-feature coordinated degrade (e.g. memory pressure) \u2013 schedule evaluation.</li> </ul>"},{"location":"technical-manual/features/#next-steps","title":"Next Steps","text":"<ul> <li>Validate descriptor coverage for all current flags.</li> <li>Finalize list of initial features (embeddings_ingest, semantic_recall, scheduler_celery, tool_events, content_masking, token_metrics, error_classifier, reasoning_stream, sandbox_usage_metrics).</li> <li>Implement registry module (<code>services/common/features.py</code>).</li> </ul> <p>END OF DRAFT</p>"},{"location":"technical-manual/gateway-llm-routing/","title":"Gateway LLM Routing &amp; Settings","text":"<p>This document explains how the Gateway resolves model settings, normalizes provider base URLs, selects credentials, and performs LLM invocations for both streaming and non\u2011streaming paths.</p>"},{"location":"technical-manual/gateway-llm-routing/#overview","title":"Overview","text":"<ul> <li>Single entry points for LLM calls:</li> <li>POST <code>/v1/llm/invoke</code> (non\u2011stream)</li> <li>POST <code>/v1/llm/invoke/stream</code> (SSE stream)</li> <li>The dialogue model profile is the source of truth and is saved via the UI Settings API.</li> <li>Provider credentials are stored centrally in the Gateway and are never read from service env vars in normal operation.</li> </ul>"},{"location":"technical-manual/gateway-llm-routing/#model-profile-and-credentials","title":"Model Profile and Credentials","text":"<p>Endpoints used by the Web UI and operators (centralized settings-only flow):</p> <ul> <li>GET <code>/v1/ui/settings</code> \u2192 returns the effective UI agent config, model profile, and credential presence map.</li> <li>PUT <code>/v1/ui/settings</code> \u2192 accepts <code>model_profile</code> and <code>agent</code> payloads (legacy direct <code>llm_credentials</code> removed; use sections).</li> <li>GET <code>/v1/ui/settings/sections</code> \u2192 full modal sections schema for the SPA.</li> <li>POST <code>/v1/ui/settings/sections</code> \u2192 single writer: persists agent settings, model profile, and any <code>api_key_*</code> credential fields (encrypted). This replaces legacy <code>/v1/llm/credentials</code>.</li> <li>GET <code>/v1/ui/settings/credentials</code> \u2192 status map of stored provider secrets (<code>present</code> + <code>updated_at</code>; never returns actual secrets).</li> <li>POST <code>/v1/llm/test</code> \u2192 resolves the active profile for the role (e.g., <code>dialogue</code>), detects provider, checks that credentials exist, and performs a reachability probe.</li> </ul> <p>Notes: - Workers no longer fetch credentials via internal endpoints; they only invoke <code>/v1/llm/invoke</code> and let the Gateway inject secrets. - Legacy endpoints <code>/v1/llm/credentials</code> and <code>/v1/llm/credentials/{provider}</code> have been removed; documentation and scripts should use the sections save path exclusively.</p>"},{"location":"technical-manual/gateway-llm-routing/#base-url-normalization","title":"Base URL Normalization","text":"<p>The Gateway normalizes OpenAI\u2011compatible base URLs before use to avoid common misconfigurations.</p> <p>Normalization rules (simplified): - Trim whitespace and trailing slashes. - Strip a trailing <code>/v1</code> and/or <code>/chat/completions</code> from the path. - Map provider\u2011specific pitfalls:   - OpenRouter: inputs ending in <code>/openai</code> are rewritten to <code>/api</code> so that appending <code>/v1/chat/completions</code> works. Example:     - Input: <code>https://openrouter.ai/openai</code> \u2192 Normalized: <code>https://openrouter.ai/api</code> - In non\u2011DEV deployments, if a scheme is present and not <code>https</code>, enforce <code>https</code>.</p> <p>Provider detection is based on the base URL host: - <code>*.groq.com</code> \u2192 <code>groq</code> - <code>openrouter.ai</code> \u2192 <code>openrouter</code> - <code>api.openai.com</code> \u2192 <code>openai</code> - otherwise \u2192 <code>other</code></p> <p>Default base URLs (when needed): - groq \u2192 <code>https://api.groq.com/openai/v1</code> - openai \u2192 <code>https://api.openai.com/v1</code> - openrouter \u2192 <code>https://openrouter.ai/api/v1</code></p>"},{"location":"technical-manual/gateway-llm-routing/#base-url-overrides","title":"Base URL Overrides","text":"<p>Callers cannot override the profile\u2019s base URL. The Gateway always uses the value saved in the profile and ignores any <code>overrides.base_url</code> provided by clients. This ensures a single source of truth for provider routing.</p>"},{"location":"technical-manual/gateway-llm-routing/#endtoend-flow","title":"End\u2011to\u2011End Flow","text":"<p>1) UI saves Settings:    - PUT <code>/v1/ui/settings</code> with <code>model_profile</code> and (optionally) <code>llm_credentials</code>. 2) Worker consumes canonical runtime settings from the Gateway (internal token) and routes all LLM calls via the Gateway\u2019s <code>/v1/llm/invoke(/stream)</code>. 3) Gateway resolves the profile, normalizes the base URL, detects the provider, fetches the secret, and calls the provider\u2019s OpenAI\u2011compatible <code>/v1/chat/completions</code> endpoint. 4) Results are audited under action <code>llm.invoke</code> with status, latency, usage, and provider metadata.</p>"},{"location":"technical-manual/gateway-llm-routing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"technical-manual/gateway-llm-routing/#symptoms-and-fixes","title":"Symptoms and Fixes","text":"<ul> <li>401 Unauthorized from provider</li> <li>Cause: Invalid/expired API key or lack of access to the selected model.</li> <li>Fix: Re\u2011enter the provider key via the Settings modal and Save (sections flow persists + encrypts the key).</li> <li> <p>Verify: POST <code>/v1/llm/test</code> should show <code>credentials_present: true</code> and the provider host.</p> </li> <li> <p>405 Method Not Allowed on OpenRouter</p> </li> <li>Cause: Using <code>/openrouter.ai/openai</code> as base, which is not compatible when composing the full path.</li> <li> <p>Fix: Normalization maps <code>/openai</code> \u2192 <code>/api</code>. Save Settings again so the profile base URL normalizes to <code>https://openrouter.ai/api</code>.</p> </li> <li> <p>Chat path returns standardized error</p> </li> <li>Check audit: <code>GET /v1/admin/audit/export?action=llm.invoke | tail</code></li> <li>If you see <code>http_status=401</code> or <code>405</code>, follow the specific fixes above.</li> </ul>"},{"location":"technical-manual/gateway-llm-routing/#quick-sanity-checks","title":"Quick sanity checks","text":"<pre><code># 1. Inspect settings\ncurl -s http://localhost:21016/v1/ui/settings | jq .\n\n# 2. Credentials presence map\ncurl -s http://localhost:21016/v1/ui/settings/credentials | jq .\n\n# 3. Provider test\ncurl -s -X POST http://localhost:21016/v1/llm/test \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"role\":\"dialogue\"}' | jq .\n\n# 4. Tail recent LLM audits\ncurl -s \"http://localhost:21016/v1/admin/audit/export?action=llm.invoke\" | tail -n 10\n</code></pre>"},{"location":"technical-manual/gateway-llm-routing/#examples","title":"Examples","text":"<p>Set Groq as the dialogue model (UI or API):</p> <pre><code>curl -s -X PUT http://localhost:21016/v1/ui/settings \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n        \"model_profile\": {\n          \"model\": \"llama-3.1-8b-instant\",\n          \"base_url\": \"https://api.groq.com/openai/v1\",\n          \"temperature\": 0.2\n        }\n      }'\n</code></pre> <p>Store Groq API key via Settings sections (centralized):</p> <pre><code>curl -s -X POST http://localhost:21016/v1/ui/settings/sections \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n        \"sections\": [\n          {\"id\":\"llm\",\"fields\":[\n            {\"id\":\"chat_model_provider\",\"value\":\"groq\"},\n            {\"id\":\"chat_model_name\",\"value\":\"llama-3.1-8b-instant\"},\n            {\"id\":\"chat_model_api_base\",\"value\":\"https://api.groq.com/openai/v1\"},\n            {\"id\":\"api_key_groq\",\"value\":\"&lt;GROQ_API_KEY&gt;\"}\n          ]}\n        ]\n      }'\n</code></pre> <p>Validate and invoke:</p> <pre><code>curl -s -X POST http://localhost:21016/v1/llm/test \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"role\":\"dialogue\"}' | jq .\n\ncurl -s -X POST http://localhost:21016/v1/llm/invoke \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Internal-Token: dev-internal-token' \\\n  -d '{\"role\":\"dialogue\",\"messages\":[{\"role\":\"user\",\"content\":\"Say hi in one word.\"}]}' | jq .\n</code></pre>"},{"location":"technical-manual/memory-embeddings-plan/","title":"Memory &amp; Embeddings Plan","text":""},{"location":"technical-manual/memory-embeddings-plan/#current-pipeline","title":"Current Pipeline","text":"<ol> <li>Gateway writes memory events (remember) \u2192 Memory Write Outbox (Postgres) as fallback.</li> <li><code>memory_sync</code> publishes to <code>memory.wal</code> topic.</li> <li><code>memory_replicator</code> consumes WAL, writes replica table (<code>memory_replicas</code>).</li> <li>Query endpoints read from replica (fast path) with filters.</li> </ol>"},{"location":"technical-manual/memory-embeddings-plan/#gaps","title":"Gaps","text":"<ul> <li>No vector embeddings abstraction (embedding function provider variance).</li> <li>No TTL/compaction strategy (potential unbounded growth).</li> <li>No memory importance scoring for prioritization.</li> </ul>"},{"location":"technical-manual/memory-embeddings-plan/#abstraction-proposal","title":"Abstraction Proposal","text":"<p><code>MemoryStore</code> interface: - <code>add(memory_event)</code>: returns ID and embedding vector metadata. - <code>search(query_vector, filters, limit, min_score)</code>. - <code>compact(strategy)</code>: perform TTL or size-based pruning; strategies: <code>ttl</code>, <code>lru</code>, <code>importance</code>.</p> <p>Vector Layer: - Pluggable provider (OpenAI, local model) via <code>EmbeddingProvider</code> with <code>embed_text(list[str])</code>. - Cache embeddings keyed by sha256(text) to avoid recompute.</p> <p>Schema Additions: - <code>embedding</code> (vector serialized as list[float] or binary) column in replica table. - <code>score</code> / <code>importance</code> field numeric. - <code>expires_at</code> for TTL-managed memories.</p> <p>Metrics: - <code>memory_embeddings_total{provider}</code> - <code>memory_embedding_latency_seconds{provider}</code> - <code>memory_replica_rows_total</code> gauge - <code>memory_compaction_rows_deleted_total{strategy}</code></p> <p>Background Jobs: - Embeddings backfill: scan rows without embedding, compute, update. - Compaction job: run interval (e.g., 10m) applying strategy (default TTL days from config overlay).</p> <p>Search API Upgrade: - Add <code>/v1/memory/search</code> accepting hybrid params: text query, semantic toggle, filters. - If semantic enabled: embed query; perform vector similarity; merge with keyword results.</p> <p>Phased Delivery: Phase 1: Embedding provider + schema column + ingestion embedding. Phase 2: Search endpoint hybrid; metrics instrumentation. Phase 3: Compaction + TTL + importance scorer (simple heuristic: length + recency weight). Phase 4: Provider registry + multi-model A/B support.</p> <p>Risks &amp; Mitigation: - Vector size inflation: enforce max embedding dimensions and provider-specific normalization. - Long compute times: asynchronous embedding pipeline + caching. - Backward compatibility: embedding column nullable; queries fallback to keyword search.</p> <p>Next Steps: 1. Add <code>embedding</code> nullable column to replica table migration. 2. Implement <code>EmbeddingProvider</code> interface and OpenAI stub. 3. Hook provider into <code>memory_replicator</code> on consume. 4. Add metrics counters/histograms. 5. Implement <code>/v1/memory/search</code> hybrid endpoint. 6. Compaction + TTL job scaffold.</p>"},{"location":"technical-manual/monitoring/","title":"Monitoring &amp; Observability","text":"<p>Standards: ISO/IEC 21500\u00a77.5</p>"},{"location":"technical-manual/monitoring/#metrics","title":"Metrics","text":""},{"location":"technical-manual/monitoring/#prometheus-endpoints","title":"Prometheus Endpoints","text":"Service Port Endpoint Gateway 9600 <code>/metrics</code> Conversation Worker 9601 <code>/metrics</code> Tool Executor 9602 <code>/metrics</code> Memory Replicator 9603 <code>/metrics</code> Memory Sync 9604 <code>/metrics</code> Outbox Sync 9415 <code>/metrics</code> Circuit Breaker 9610 <code>/metrics</code>"},{"location":"technical-manual/monitoring/#key-metrics","title":"Key Metrics","text":"<p>Gateway: - <code>http_requests_total</code> - Total HTTP requests - <code>http_request_duration_seconds</code> - Request latency - <code>streaming_connections_active</code> - Active streaming (SSE) connections - <code>kafka_publish_errors_total</code> - Failed Kafka publishes</p> <p>Conversation Worker: - <code>messages_processed_total</code> - Messages processed - <code>llm_call_duration_seconds</code> - LLM API latency - <code>llm_tokens_used_total</code> - Token consumption - <code>kafka_consumer_lag</code> - Consumer lag</p> <p>Tool Executor: - <code>tools_executed_total</code> - Tool executions - <code>tool_execution_duration_seconds</code> - Execution time - <code>tool_failures_total</code> - Failed executions</p> <p>Circuit Breaker: - <code>circuit_breaker_state</code> - Current state (0=closed, 1=open, 2=half-open) - <code>circuit_breaker_open_events_total</code> - Times circuit opened</p>"},{"location":"technical-manual/monitoring/#prometheus-configuration","title":"Prometheus Configuration","text":"<pre><code># infra/observability/prometheus.yml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'gateway'\n    static_configs:\n      - targets: ['localhost:9600']\n\n  - job_name: 'conversation-worker'\n    static_configs:\n      - targets: ['localhost:9601']\n\n  - job_name: 'tool-executor'\n    static_configs:\n      - targets: ['localhost:9602']\n\n  - job_name: 'circuit-breakers'\n    static_configs:\n      - targets: ['localhost:9610']\n\nrule_files:\n  - 'alerts.yml'\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets: ['localhost:9093']\n</code></pre>"},{"location":"technical-manual/monitoring/#alerts","title":"Alerts","text":"<pre><code># infra/observability/alerts.yml\ngroups:\n  - name: somaagent01\n    interval: 30s\n    rules:\n      - alert: HighErrorRate\n        expr: rate(http_requests_total{status=~\"5..\"}[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High error rate on {{ $labels.instance }}\"\n\n      - alert: HighLatency\n        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) &gt; 2\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High latency on {{ $labels.instance }}\"\n\n      - alert: CircuitBreakerOpen\n        expr: circuit_breaker_state == 1\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Circuit breaker open on {{ $labels.instance }}\"\n\n      - alert: KafkaConsumerLag\n        expr: kafka_consumer_lag &gt; 1000\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High Kafka consumer lag: {{ $value }}\"\n</code></pre>"},{"location":"technical-manual/monitoring/#dashboards","title":"Dashboards","text":""},{"location":"technical-manual/monitoring/#gateway-dashboard","title":"Gateway Dashboard","text":"<p>Panels: - Request rate (RPS) - Error rate (%) - P50/P95/P99 latency - Active streaming (SSE) connections - Kafka publish success rate</p>"},{"location":"technical-manual/monitoring/#worker-dashboard","title":"Worker Dashboard","text":"<p>Panels: - Messages processed/sec - LLM call latency - Token usage - Consumer lag - Error rate</p>"},{"location":"technical-manual/monitoring/#infrastructure-dashboard","title":"Infrastructure Dashboard","text":"<p>Panels: - Kafka broker health - PostgreSQL connections - Redis memory usage - Disk I/O - Network throughput</p>"},{"location":"technical-manual/monitoring/#logging","title":"Logging","text":""},{"location":"technical-manual/monitoring/#structured-logs","title":"Structured Logs","text":"<pre><code>import structlog\n\nlogger = structlog.get_logger(__name__)\n\nlogger.info(\n    \"message_processed\",\n    session_id=session_id,\n    duration_ms=duration * 1000,\n    tokens_used=tokens\n)\n</code></pre>"},{"location":"technical-manual/monitoring/#log-levels","title":"Log Levels","text":"Level Usage DEBUG Development only INFO Normal operations WARNING Recoverable errors ERROR Failures requiring attention CRITICAL System-wide failures"},{"location":"technical-manual/monitoring/#log-aggregation","title":"Log Aggregation","text":"<pre><code># View all logs\ndocker compose logs -f\n\n# Filter by service\ndocker compose logs -f gateway\n\n# Filter by level\ndocker compose logs gateway | grep ERROR\n\n# Export logs\ndocker compose logs &gt; logs.txt\n</code></pre>"},{"location":"technical-manual/monitoring/#tracing","title":"Tracing","text":""},{"location":"technical-manual/monitoring/#opentelemetry","title":"OpenTelemetry","text":"<pre><code>from opentelemetry import trace\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\n# Setup\nprovider = TracerProvider()\nprocessor = BatchSpanProcessor(OTLPSpanExporter(endpoint=\"localhost:4317\"))\nprovider.add_span_processor(processor)\ntrace.set_tracer_provider(provider)\n\n# Usage\ntracer = trace.get_tracer(__name__)\n\nwith tracer.start_as_current_span(\"process_message\"):\n    result = await process_message(message)\n</code></pre>"},{"location":"technical-manual/monitoring/#trace-context","title":"Trace Context","text":"<p>Traces propagate across services via Kafka headers: - <code>traceparent</code> - W3C trace context - <code>tracestate</code> - Vendor-specific data</p>"},{"location":"technical-manual/monitoring/#health-checks","title":"Health Checks","text":""},{"location":"technical-manual/monitoring/#endpoints","title":"Endpoints","text":"<p><pre><code># Gateway\ncurl http://localhost:${GATEWAY_PORT:-21016}/v1/health\n# Response: {\"status\": \"healthy\", \"version\": \"1.0.0\"}\n\n# Liveness (K8s)\ncurl http://localhost:${GATEWAY_PORT:-21016}/v1/health/live\n# Response: 200 OK\n\n### Prometheus Endpoints\n\n- Gateway: `/metrics` on `GATEWAY_METRICS_PORT` (default 8000)\n- Other services: `/metrics` on their `*_METRICS_PORT` env (see service code). Example defaults observed in-code:\n  - Outbox Sync: `${OUTBOX_SYNC_METRICS_PORT:-9469}`\n  - Memory Sync: `${MEMORY_SYNC_METRICS_PORT:-9471}`\n  - Replicator: `${REPLICATOR_METRICS_PORT}` (env-driven)\n  - Circuit Breakers exporter: `${CIRCUIT_BREAKER_METRICS_PORT:-9610}`\n# Readiness (K8s)\ncurl http://localhost:${GATEWAY_PORT:-21016}/v1/health/ready\n# Response: 200 OK (if Kafka/PostgreSQL accessible)\n**Gateway (canonical names implemented)**:\n- `gateway_requests_total{method,endpoint,status_code}` \u2013 Request counts\n- `gateway_request_duration_seconds{method,endpoint}` \u2013 Request latency\n- `gateway_sse_connections` \u2013 Active SSE connections\n- `sse_messages_sent_total{message_type,session_id}` \u2013 SSE message counts\n```bash\n#!/bin/bash\n# scripts/check_stack.sh\n\nservices=(\n  \"Kafka:20000\"\n  \"Redis:20001\"\n  \"PostgreSQL:20002\"\n  \"Gateway:21016\"\n)\n\nfor service in \"${services[@]}\"; do\n  name=\"${service%%:*}\"\n  port=\"${service##*:}\"\n\n  if nc -z localhost $port 2&gt;/dev/null; then\n### Health Checks\n\n```bash\n# Comprehensive health\ncurl http://localhost:${GATEWAY_PORT:-21016}/v1/health\n\n# K8s style aliases exposed at root\ncurl http://localhost:${GATEWAY_PORT:-21016}/live     # liveness\ncurl http://localhost:${GATEWAY_PORT:-21016}/ready    # readiness\ncurl http://localhost:${GATEWAY_PORT:-21016}/healthz  # health alias\n</code></pre>     echo \"\u2705 $name: healthy\"   else     echo \"\u274c $name: unhealthy\"   fi done <pre><code>## SLOs\n\n### Service Level Objectives\n\n| Metric | Target | Measurement |\n|--------|--------|-------------|\n| Availability | 99.9% | Uptime over 30 days |\n| Latency (P95) | &lt; 2s | Request duration |\n| Error Rate | &lt; 0.1% | 5xx responses |\n| Message Processing | &lt; 5s | End-to-end latency |\n\n### SLO Monitoring\n\n```promql\n# Availability (30d)\navg_over_time(up{job=\"gateway\"}[30d]) * 100\n\n# Latency P95\nhistogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\n\n# Error rate\nrate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])\n</code></pre></p>"},{"location":"technical-manual/monitoring/#alertmanager","title":"Alertmanager","text":"<pre><code># infra/observability/alertmanager.yml\nglobal:\n  resolve_timeout: 5m\n\nroute:\n  group_by: ['alertname', 'cluster']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 12h\n  receiver: 'slack'\n\nreceivers:\n  - name: 'slack'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'\n        channel: '#alerts'\n        title: '{{ .GroupLabels.alertname }}'\n        text: '{{ range .Alerts }}{{ .Annotations.summary }}\\n{{ end }}'\n</code></pre>"},{"location":"technical-manual/monitoring/#runbook-links","title":"Runbook Links","text":"<ul> <li>High Error Rate</li> <li>High Latency</li> <li>Circuit Breaker Open</li> <li>Kafka Consumer Lag</li> </ul>"},{"location":"technical-manual/notifications/","title":"UI Notifications (SSE + REST)","text":"<p>This document describes the end-to-end Notifications system: storage schema, REST API, SSE streaming events, and the Web UI integration (badge, modal, toasts).</p>"},{"location":"technical-manual/notifications/#overview","title":"Overview","text":"<ul> <li>Transport: Server-Sent Events (single <code>EventSource</code> per session) multiplexing conversation + <code>ui.notification</code> events.</li> <li>Storage: Postgres table <code>ui_notifications</code> with TTL; periodic janitor deletes expired rows.</li> <li>Publish: Kafka topic <code>ui.notifications</code>, also merged onto the session SSE stream.</li> <li>API surface: REST for CRUD; SSE for realtime delivery.</li> </ul>"},{"location":"technical-manual/notifications/#rest-api","title":"REST API","text":"<ul> <li>Create notification</li> <li><code>POST /v1/ui/notifications</code></li> <li>Body: <code>{ \"type\": \"string\", \"title\": \"string\", \"body\": \"string\", \"severity\": \"info|success|warning|error\", \"ttl_seconds\": 3600, \"meta\": { ... } }</code></li> <li> <p>201 \u2192 <code>{ notification: { id, type, title, body, severity, created_at, read_at, meta } }</code></p> </li> <li> <p>List notifications</p> </li> <li><code>GET /v1/ui/notifications?limit=50&amp;unread_only=true</code></li> <li> <p>200 \u2192 <code>{ notifications: [ ... ], next_cursor: { created_at, id } | null }</code></p> </li> <li> <p>Mark as read</p> </li> <li><code>POST /v1/ui/notifications/{id}/read</code></li> <li> <p>200 \u2192 <code>{ ok: true }</code></p> </li> <li> <p>Clear all</p> </li> <li><code>DELETE /v1/ui/notifications/clear</code></li> <li>200 \u2192 <code>{ cleared: &lt;int&gt; }</code></li> </ul> <p>Authorization and tenant scoping mirror the session SSE access rules.</p>"},{"location":"technical-manual/notifications/#sse-events","title":"SSE Events","text":"<ul> <li>Event type: <code>ui.notification</code></li> <li>Payloads:</li> <li>Created: <code>{ type: \"ui.notification\", action: \"created\", notification: { ... } }</code></li> <li>Read: <code>{ type: \"ui.notification\", action: \"read\", id: \"...\" }</code></li> <li>Cleared: <code>{ type: \"ui.notification\", action: \"cleared\" }</code></li> </ul> <p>These events are emitted on the same SSE stream as chat events: <code>GET /v1/session/{session_id}/events</code>.</p>"},{"location":"technical-manual/notifications/#web-ui-integration","title":"Web UI Integration","text":"<ul> <li>Single SSE client in <code>webui/js/stream.js</code> dispatches events to an event bus (<code>sse:event</code>).</li> <li>Notifications store: <code>webui/components/notifications/notificationsStore.js</code> consumes REST + bus and maintains a reactive state <code>{ list, unreadCount }</code>.</li> <li>Alpine bridge: <code>webui/index.js</code> bridges store -&gt; <code>$store.notificationSse</code> for templates (badge + modal) and exposes <code>globalThis.notificationsSse</code> helpers.</li> <li>Badge: <code>webui/components/notifications/notification-icons.html</code> binds to <code>$store.notificationSse.unreadCount</code> and shows <code>#notification-badge</code>.</li> <li>Modal: <code>webui/components/notifications/notification-modal.html</code> lists <code>$store.notificationSse.list</code> and uses <code>globalThis.notificationsSse.markRead/clearAll</code>.</li> <li>Toasts: the unified <code>notificationsStore.js</code> also manages a lightweight toast stack (frontend) and mirrors actions to REST where possible. Modal open will mark unread as read via the SSE-backed store.</li> </ul>"},{"location":"technical-manual/notifications/#observability","title":"Observability","text":"<ul> <li>Prometheus counter <code>ui_notifications_total{event,severity,type}</code> increments on create/read/clear.</li> <li>SSE connection metrics and heartbeat monitoring exist in the gateway.</li> </ul>"},{"location":"technical-manual/notifications/#expiry-cleanup","title":"Expiry &amp; Cleanup","text":"<ul> <li>Notifications include an optional TTL (<code>ttl_seconds</code>).</li> <li>A background janitor deletes rows past expiry; this does not emit SSE events.</li> </ul>"},{"location":"technical-manual/notifications/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>No badge updates: ensure the SSE stream is connected (look for connection to <code>/v1/session/.../events</code>) and that the badge element exists.</li> <li>Create works but no realtime: check Kafka availability and that the gateway merges the <code>ui.notifications</code> consumer into the session multiplexer.</li> <li>401/403 on API calls: verify JWT/session and tenant access checks; the notifications endpoints reuse the standard authorization path.</li> </ul>"},{"location":"technical-manual/notifications/#example-curl","title":"Example (curl)","text":"<pre><code>curl -sS -X POST \\\n  -H 'Content-Type: application/json' \\\n  --cookie 'session=...' \\\n  http://localhost:21016/v1/ui/notifications \\\n  -d '{\"type\":\"demo\",\"title\":\"Hi\",\"body\":\"Hello\",\"severity\":\"info\"}'\n</code></pre>"},{"location":"technical-manual/outbound-events/","title":"Outbound SSE Event Contract (sa01-v1)","text":"<p>This document describes the unified, versioned event shapes emitted to the canonical SSE stream at:</p> <ul> <li>/v1/session/{session_id}/events</li> </ul> <p>All events share a common envelope and MUST be JSON-serializable.</p>"},{"location":"technical-manual/outbound-events/#common-envelope","title":"Common envelope","text":"<ul> <li>event_id: string (UUID)</li> <li>session_id: string (UUID)</li> <li>persona_id: string | null</li> <li>role: string \u2014 one of: user, assistant, tool, system (future)</li> <li>message: string \u2014 primary text payload; may be empty for lifecycle markers</li> <li>metadata: object \u2014 additional fields; see type-specific sections</li> <li>version: string \u2014 protocol version, currently \"sa01-v1\"</li> <li>type: string \u2014 semantic event type, namespaced as below</li> </ul>"},{"location":"technical-manual/outbound-events/#assistant-events","title":"Assistant events","text":"<ul> <li>assistant.thinking</li> <li>Purpose: indicate the assistant has started planning/thinking.</li> <li>role: assistant</li> <li>message: \"\"</li> <li> <p>metadata:</p> <ul> <li>status: \"thinking\"</li> <li>source: \"worker\"</li> <li>analysis: { intent: string, sentiment: string, tags: string[] }</li> </ul> </li> <li> <p>assistant.stream</p> </li> <li>Purpose: streaming partial content.</li> <li>role: assistant</li> <li>message: cumulative content buffer (not a delta)</li> <li> <p>metadata:</p> <ul> <li>status: \"streaming\"</li> <li>source: \"slm\" | \"escalation_llm\"</li> <li>analysis: {...}</li> <li>stream_index: number (1-based)</li> </ul> </li> <li> <p>assistant.final</p> </li> <li>Purpose: final response for a turn.</li> <li>role: assistant</li> <li>message: complete assistant answer</li> <li>metadata:<ul> <li>status: \"completed\"</li> <li>source: \"slm\" | \"escalation_llm\"</li> <li>analysis: {...}</li> <li>escalation: { reason: string, metadata: object } | null</li> </ul> </li> </ul>"},{"location":"technical-manual/outbound-events/#tool-events","title":"Tool events","text":"<ul> <li>tool.start</li> <li>Purpose: indicate tool execution has begun.</li> <li>role: tool</li> <li>message: \"\"</li> <li> <p>metadata:</p> <ul> <li>status: \"start\"</li> <li>source: \"tool_executor\"</li> <li>tool_name: string</li> <li>request_id: string (stable across lifecycle)</li> </ul> </li> <li> <p>tool.result</p> </li> <li>Purpose: final tool result payload for display and memory.</li> <li>role: tool</li> <li>message: compacted string form of payload (JSON if structured)</li> <li>metadata:<ul> <li>status: \"success\" | \"error\" | \"blocked\" | string</li> <li>source: \"tool_executor\"</li> <li>tool_name: string</li> <li>request_id: string (stable across lifecycle)</li> <li>execution_time: number (seconds)</li> <li>sandbox_logs: string | null (when available)</li> </ul> </li> </ul>"},{"location":"technical-manual/outbound-events/#notes","title":"Notes","text":"<ul> <li>The UI should treat unknown fields as opaque and forward-compatible.</li> <li>For long-term stability, clients should use <code>type</code> and <code>metadata.status</code> to drive rendering, not rely on implicit roles alone.</li> <li>The assistant.stream events carry the full cumulative buffer to simplify UI replacement logic.</li> </ul>"},{"location":"technical-manual/production-hardening/","title":"Production Hardening Plan (Phase: Pre-K8s \u2192 K8s \u2192 Terraform)","text":""},{"location":"technical-manual/production-hardening/#objectives","title":"Objectives","text":"<ul> <li>Establish consistent health/readiness/liveness endpoints across services.</li> <li>Guarantee graceful shutdown and background task cancellation (no orphaned tasks, clean closing of Kafka &amp; HTTP clients).</li> <li>Standardize observability: metrics, structured logs, OpenTelemetry traces, Kafka trace headers (traceparent) for cross-service correlation.</li> <li>Harden configuration &amp; secrets management for container and cluster deployment.</li> <li>Provide Kubernetes deployment primitives (Helm charts scaffold) with probes, resource requests/limits, security context, and topology hints.</li> <li>Prepare Terraform baseline for cloud infra (Kafka, Postgres, Redis, object storage buckets, secret stores) and CI integration hooks.</li> </ul>"},{"location":"technical-manual/production-hardening/#scope","title":"Scope","text":"<p>Services: <code>gateway</code>, <code>delegation_gateway</code>, <code>delegation_worker</code>, <code>conversation_worker</code>, <code>tool_executor</code>, <code>memory_sync</code>, <code>memory_replicator</code>, <code>outbox_sync</code>, <code>celery_worker</code> (+ any future <code>memory_service</code>).</p>"},{"location":"technical-manual/production-hardening/#readiness-liveness-standardization","title":"Readiness &amp; Liveness Standardization","text":"<p>Checklist per HTTP service: - Endpoint: <code>GET /live</code> returns <code>{status: \"alive\"}</code> (fast path, no external deps). - Endpoint: <code>GET /ready</code> probes critical dependencies (DB schema ensure, Kafka metadata fetch, cache ping). Failure \u21d2 HTTP 503. - Endpoint: <code>GET /health</code> retains richer component detail (already present in <code>gateway</code>). - Worker processes (non-HTTP): Provide a lightweight HTTP sidecar or expose periodic heartbeat metric (e.g., <code>worker_last_heartbeat_timestamp</code>).</p> <p>Action Items: 1. Add <code>/ready</code> + <code>/live</code> to any remaining HTTP apps (verify <code>conversation_worker</code> if it exposes HTTP; else document alternative). 2. Introduce a shared readiness helper in <code>services/common/readiness.py</code> (probe functions: postgres, kafka, redis, optional external) to remove duplication. 3. Document readiness contract in OpenAPI and Helm values.</p>"},{"location":"technical-manual/production-hardening/#graceful-shutdown","title":"Graceful Shutdown","text":"<p>Current state: lifecycle helper integrated for several workers; gateway tracks tasks and cancels on lifespan shutdown. Required: - Ensure each service closes: Kafka producer/consumer, HTTP clients, async DB pools, background tasks (janitors, exporters, listeners). - Add signal handlers (SIGINT/SIGTERM) via shared helper across workers (<code>service_lifecycle.py</code>). - Emit shutdown trace span and log marker for correlation.</p> <p>Action Items: 1. Audit each worker for running tasks without cancellation tokens; wrap in stop Event. 2. Gateway: add termination timeout enforcement (e.g., 20s) before forced exit. 3. Add unit test simulating cancellation for one worker (mock bus + dummy loop). (Low priority if environment constraints.)</p>"},{"location":"technical-manual/production-hardening/#observability-enhancements","title":"Observability Enhancements","text":"<p>Completed: trace headers (<code>trace_id</code>, <code>span_id</code>, <code>traceparent</code>) and payload injection. Next: - Add metrics: startup duration (<code>service_startup_seconds</code>), last successful readiness timestamp, graceful shutdown duration. - Structured logging: ensure <code>trace_id</code> and <code>span_id</code> included in all top-level log records (logging filter). - Add <code>ServiceMonitor</code> annotations example in Helm chart for Prometheus scraping.</p>"},{"location":"technical-manual/production-hardening/#configuration-secrets","title":"Configuration &amp; Secrets","text":"<p>Currently: environment variables + direct secret fetch helper (<code>vault_secrets</code>). Target: - Central config registry abstraction with layered precedence: default \u2192 environment \u2192 remote dynamic overrides (Kafka topic <code>config_updates</code>). - Schema validation for config documents (JSONSchema versioned). - Staged rollout: publish new config version, consumer validates &amp; acknowledges; revert on failure. - Secrets: reference by key (e.g., <code>${secret:openai}</code>) resolved at runtime through secret provider interface; no raw secrets in config files.</p> <p>Action Items: 1. Draft <code>services/common/config_registry.py</code> (load, validate, subscribe, ack model). 2. Add <code>schemas/config/registry.v1.schema.json</code> for structural validation. 3. Extend existing <code>_config_update_listener</code> to send ack events / metrics.</p>"},{"location":"technical-manual/production-hardening/#kubernetes-helm-scaffold","title":"Kubernetes (Helm) Scaffold","text":"<p>Chart Structure (proposed): <pre><code>helm/\n  Chart.yaml\n  values.yaml\n  templates/\n    deployment-gateway.yaml\n    deployment-delegation-gateway.yaml\n    deployment-workers.yaml\n    service.yaml\n    configmap-env.yaml\n    secret-env.yaml\n    ingress.yaml\n    servicemonitor.yaml (optional)\n</code></pre> Key Values: - <code>image.repository</code>, <code>image.tag</code>. - <code>resources.{requests,limits}</code> per component. - <code>autoscaling.enabled</code>, HPA metrics (CPU/memory, custom latency metric optional). - <code>env</code>: list of key/value, plus secretRefs. - <code>readinessProbe</code> and <code>livenessProbe</code> hitting <code>/ready</code> &amp; <code>/live</code>. - <code>podSecurityContext</code> (runAsNonRoot, fsGroup). <code>securityContext</code> (drop capabilities, readOnlyRootFilesystem). - <code>topologySpreadConstraints</code> for HA.</p> <p>Action Items: 1. Scaffold chart and minimal templates referencing readiness endpoints. 2. Add <code>NOTIFICATIONS_JANITOR_ENABLED=false</code> override capability via values. 3. Document example <code>values-production.yaml</code> with tightened resource limits.</p>"},{"location":"technical-manual/production-hardening/#terraform-baseline","title":"Terraform Baseline","text":"<p>Components: - VPC / networking (if not managed separately). - Postgres (managed service) + Redis (Elasticache/Valkey) + Kafka (MSK / Redpanda / Aiven) + Object storage bucket. - Secret store (AWS Secrets Manager / Vault integration). - IAM roles (pod service accounts) &amp; security groups for DB/Kafka.</p> <p>Action Items: 1. Define module layout <code>infra/terraform/</code> with environments: <code>dev</code>, <code>prod</code>. 2. Add remote state (<code>backend.tf</code>) pattern placeholder. 3. Variables for sizing, engine versions, retention, encryption. 4. Output endpoints and ARNs consumed by Helm chart values (CI pipeline artifact).</p>"},{"location":"technical-manual/production-hardening/#reliability-backpressure","title":"Reliability &amp; Backpressure","text":"<ul> <li>Implement circuit breakers (already using <code>pybreaker</code>) consistently for all outbound calls (LLM, SomaBrain, config fetch).</li> <li>Add retry with jitter for publishing when Kafka temporarily unavailable (in DurablePublisher fallback path already present). Confirm exponential backoff.</li> <li>Memory pipeline: add WAL lag metric, compaction job schedule via cron-like worker.</li> </ul> <p>Action Items: 1. Add <code>memory_wal_lag_seconds</code> metric (difference between now and last WAL timestamp). 2. Add background compaction placeholder in <code>memory_replicator</code> (feature-flagged).</p>"},{"location":"technical-manual/production-hardening/#security-posture-preview","title":"Security Posture (Preview)","text":"<p>Will be detailed in separate security review document; key early tasks: - Ensure no secrets logged; add log filter to redact known patterns. - Validate JWT algorithms enforced (already fail-fast for missing PyJWT). - Policy enforcement metrics (exists) \u2013 add decision latency histogram.</p>"},{"location":"technical-manual/production-hardening/#developer-mode-parity","title":"Developer Mode Parity","text":"<ul> <li>Provide <code>docker-compose.dev.yaml</code> layering optional services &amp; mock dependencies.</li> <li>Seed scripts for model profiles, tool catalog entries, test tenants.</li> <li>Enable watch mode (reload) for FastAPI services.</li> </ul>"},{"location":"technical-manual/production-hardening/#metrics-backlog-summary","title":"Metrics Backlog Summary","text":"Metric Type Purpose service_startup_seconds Histogram Measure startup initialization cost service_shutdown_seconds Histogram Ensure graceful shutdown bounded readiness_last_success_timestamp Gauge Track last successful readiness probe memory_wal_lag_seconds Gauge Monitor replication freshness config_update_apply_total Counter (labels: result) Track config rollout success/failure policy_decision_latency_seconds Histogram Observe authorization performance"},{"location":"technical-manual/production-hardening/#prioritized-next-steps-execution-queue","title":"Prioritized Next Steps (Execution Queue)","text":"<ol> <li>Shared readiness helper &amp; apply to all HTTP services.</li> <li>Config registry scaffold + schema + ack metrics.</li> <li>Helm chart initial commit with gateway + delegation + one worker (conversation_worker) deployments.</li> <li>Startup/shutdown metrics instrumentation.</li> <li>memory WAL lag metric + compaction placeholder.</li> <li>Policy decision latency histogram.</li> <li>Terraform directory scaffold + variable definitions.</li> <li>Developer mode compose profile enhancements.</li> </ol>"},{"location":"technical-manual/production-hardening/#risk-mitigations","title":"Risk &amp; Mitigations","text":"Risk Mitigation Inconsistent readiness logic Central helper + tests Secret leakage in logs Redaction filter + scanning CI job Trace correlation gaps Mandatory headers (implemented) + docs Unbounded shutdown Timeout + structured shutdown spans Config drift across envs Registry with versioned schema + ack metrics"},{"location":"technical-manual/production-hardening/#acceptance-criteria-phase-completion","title":"Acceptance Criteria (Phase Completion)","text":"<ul> <li>All HTTP services respond to <code>/ready</code> and <code>/live</code> within &lt;200ms when healthy.</li> <li>Helm chart deploys gateway &amp; delegation services with passing probes.</li> <li>Traceparent visible in Kafka messages and spans link across publish/consume.</li> <li>Config registry publishes and validates a sample update end-to-end.</li> <li>Startup and shutdown metrics exposed and observable in Prometheus scrape.</li> <li>Terraform scaffold defines core infra modules and variables (no full apply required yet).</li> <li>Security review doc placeholder created referencing redaction and policy latency goals.</li> </ul> <p>Version: 0.1.0 Last Updated: (auto-fill in future CI step)</p>"},{"location":"technical-manual/security-review/","title":"Security Posture Review (Draft)","text":""},{"location":"technical-manual/security-review/#identity-auth","title":"Identity &amp; Auth","text":"<ul> <li>JWT cookie parsing with algorithm enforcement; PyJWT required.</li> <li>API keys via Redis-backed store; prefixes and revocation supported.</li> <li>Policy middleware (OPA) applied globally in gateway; fail-closed configurable.</li> </ul>"},{"location":"technical-manual/security-review/#secrets","title":"Secrets","text":"<ul> <li>No secrets logged: add redaction filter (TODO) for common keys and bearer patterns.</li> <li>Secret resolution via <code>vault_secrets</code> helper; plan to add reference-by-key in config registry.</li> </ul>"},{"location":"technical-manual/security-review/#data-handling","title":"Data Handling","text":"<ul> <li>Uploads guarded by allowed/denied mime lists; antivirus optional with strict mode.</li> <li>Sensitive payload scrubbing for audit/details (present in gateway).</li> </ul>"},{"location":"technical-manual/security-review/#transport-tls","title":"Transport &amp; TLS","text":"<ul> <li>Recommend mTLS at edge (Envoy/Kong); ensure <code>X-Forwarded-Proto</code> honored for WS URL building.</li> </ul>"},{"location":"technical-manual/security-review/#authorization","title":"Authorization","text":"<ul> <li>Metrics for policy decisions; add latency histogram to observe OPA/sidecar performance.</li> </ul>"},{"location":"technical-manual/security-review/#multi-tenancy","title":"Multi-tenancy","text":"<ul> <li>Tenant extracted from auth metadata; topic headers support <code>tenant</code> (future).</li> </ul>"},{"location":"technical-manual/security-review/#supply-chain","title":"Supply Chain","text":"<ul> <li>Pin critical packages in <code>pyproject.toml</code>; run <code>pip-audit</code> in CI (TODO).</li> </ul>"},{"location":"technical-manual/security-review/#next-steps","title":"Next Steps","text":"<ol> <li>Implement log redaction filter and unit tests.</li> <li>Add <code>policy_decision_latency_seconds</code> histogram and sampling.</li> <li>Add OpenFGA optional enforcement points (documented toggles).</li> <li>Secrets-by-reference support in config registry and integrity checks.</li> <li>CI: add SAST/dep scan + secret scanning on commits.</li> </ol>"},{"location":"technical-manual/security/","title":"Security Controls","text":"<p>Standards: ISO/IEC 27001\u00a75</p>"},{"location":"technical-manual/security/#authentication","title":"Authentication","text":""},{"location":"technical-manual/security/#jwt-authentication","title":"JWT Authentication","text":"<p>Supported algorithms: - HS256 (symmetric, default) - RS256 (asymmetric, production)</p> <p>Configuration: <pre><code># .env\nJWT_SECRET=&lt;256-bit-random-key&gt;\nJWT_ALGORITHM=HS256\nJWT_EXPIRY_SECONDS=3600\n</code></pre></p> <p>Token structure: <pre><code>{\n  \"sub\": \"user123\",\n  \"tenant\": \"acme\",\n  \"persona_id\": \"default\",\n  \"exp\": 1706140800,\n  \"iat\": 1706137200\n}\n</code></pre></p>"},{"location":"technical-manual/security/#api-key-authentication","title":"API Key Authentication","text":"<p>Storage: Redis with SHA256 hash</p> <p>Format: <code>sk-soma-&lt;32-char-random&gt;</code></p> <p>Usage: <pre><code>curl -H \"Authorization: Bearer sk-soma-abc123...\" \\\n  http://localhost:${GATEWAY_PORT:-21016}/v1/session/message\n</code></pre></p>"},{"location":"technical-manual/security/#ui-authentication","title":"UI Authentication","text":"<p>Method: Password-based (configurable)</p> <p>Configuration: <pre><code>AUTH_PASSWORD=&lt;strong-password&gt;\nAUTH_ENABLED=true\n</code></pre></p>"},{"location":"technical-manual/security/#authorization","title":"Authorization","text":""},{"location":"technical-manual/security/#opa-policies","title":"OPA Policies","text":"<p>Policy file: <code>policy/tool_policy.rego</code></p> <p>Example: <pre><code>package tool_policy\n\ndefault allow = false\n\nallow {\n  input.tool == \"code_execution\"\n  input.tenant == \"trusted\"\n}\n\nallow {\n  input.tool == \"web_search\"\n}\n</code></pre></p> <p>Evaluation: <pre><code>import httpx\n\nresponse = await httpx.post(\n    \"http://localhost:20009/v1/data/tool_policy/allow\",\n    json={\"input\": {\"tool\": \"code_execution\", \"tenant\": \"acme\"}}\n)\nallowed = response.json()[\"result\"]\n</code></pre></p>"},{"location":"technical-manual/security/#openfga-optional","title":"OpenFGA (Optional)","text":"<p>Configuration: <pre><code>OPENFGA_ENABLED=true\nOPENFGA_STORE_ID=&lt;store-id&gt;\nOPENFGA_API_URL=http://localhost:8080\n</code></pre></p> <p>Model: <pre><code>model\n  schema 1.1\n\ntype user\n\ntype session\n  relations\n    define owner: [user]\n    define viewer: [user] or owner\n</code></pre></p>"},{"location":"technical-manual/security/#encryption","title":"Encryption","text":""},{"location":"technical-manual/security/#secrets-encryption","title":"Secrets Encryption","text":"<p>Method: Fernet (symmetric)</p> <p>Key generation: <pre><code>from cryptography.fernet import Fernet\nkey = Fernet.generate_key()\nprint(key.decode())\n</code></pre></p> <p>Configuration: <pre><code>FERNET_KEY=&lt;base64-encoded-key&gt;\n</code></pre></p> <p>Usage: <pre><code>from python.helpers.crypto import encrypt_secret, decrypt_secret\n\nencrypted = encrypt_secret(\"my-api-key\")\n# Store in Redis: llm_cred:openrouter\n\ndecrypted = decrypt_secret(encrypted)\n# Use for LLM calls\n</code></pre></p>"},{"location":"technical-manual/security/#tlsssl","title":"TLS/SSL","text":"<p>Gateway TLS: <pre><code># docker-compose.yaml\nservices:\n  gateway:\n    environment:\n      - TLS_ENABLED=true\n      - TLS_CERT_PATH=/certs/server.crt\n      - TLS_KEY_PATH=/certs/server.key\n    volumes:\n      - ./certs:/certs:ro\n</code></pre></p> <p>PostgreSQL TLS: <pre><code>POSTGRES_SSLMODE=require\nPOSTGRES_SSLCERT=/certs/client.crt\nPOSTGRES_SSLKEY=/certs/client.key\n</code></pre></p>"},{"location":"technical-manual/security/#network-security","title":"Network Security","text":""},{"location":"technical-manual/security/#firewall-rules","title":"Firewall Rules","text":"<p>Inbound: - 21016 (Gateway) - Public - 20015 (UI) - Public - All other ports - Internal only</p> <p>Outbound: - 443 (HTTPS) - LLM APIs, external services - 53 (DNS) - Name resolution</p>"},{"location":"technical-manual/security/#network-isolation","title":"Network Isolation","text":"<pre><code># docker-compose.yaml\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n    internal: true\n\nservices:\n  gateway:\n    networks:\n      - frontend\n      - backend\n\n  postgres:\n    networks:\n      - backend  # Not exposed to frontend\n</code></pre>"},{"location":"technical-manual/security/#cors-configuration","title":"CORS Configuration","text":"<pre><code>CORS_ORIGINS=https://app.example.com,https://admin.example.com\nCORS_ALLOW_CREDENTIALS=true\n</code></pre>"},{"location":"technical-manual/security/#data-security","title":"Data Security","text":""},{"location":"technical-manual/security/#pii-handling","title":"PII Handling","text":"<p>Classification: - Public: Session IDs, timestamps - Internal: User messages, agent responses - Confidential: API keys, passwords - Restricted: Payment info (not stored)</p> <p>Masking: <pre><code>import re\n\ndef mask_email(text: str) -&gt; str:\n    return re.sub(r'\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b', '&lt;email&gt;', text)\n\ndef mask_api_key(key: str) -&gt; str:\n    return f\"{key[:8]}...{key[-4:]}\"\n</code></pre></p>"},{"location":"technical-manual/security/#data-retention","title":"Data Retention","text":"Data Type Retention Location Sessions 90 days PostgreSQL Messages 90 days PostgreSQL Logs 7 days Docker volumes Metrics 30 days Prometheus Backups 30 days S3/GCS <p>Cleanup: <pre><code>-- Delete old sessions\nDELETE FROM sessions WHERE created_at &lt; NOW() - INTERVAL '90 days';\n\n-- Delete old events\nDELETE FROM session_events WHERE occurred_at &lt; NOW() - INTERVAL '90 days';\n</code></pre></p>"},{"location":"technical-manual/security/#secrets-management","title":"Secrets Management","text":"<p>Vault Integration (optional): <pre><code>VAULT_ENABLED=true\nVAULT_ADDR=https://vault.example.com\nVAULT_TOKEN=&lt;vault-token&gt;\n\n# Reference secrets\nOPENROUTER_API_KEY=vault://secret/openrouter-key\nJWT_SECRET=vault://secret/jwt-secret\n</code></pre></p> <p>Docker Secrets: <pre><code>secrets:\n  jwt_secret:\n    external: true\n\nservices:\n  gateway:\n    secrets:\n      - jwt_secret\n    environment:\n      - JWT_SECRET_FILE=/run/secrets/jwt_secret\n</code></pre></p>"},{"location":"technical-manual/security/#input-validation","title":"Input Validation","text":""},{"location":"technical-manual/security/#request-validation","title":"Request Validation","text":"<pre><code>from pydantic import BaseModel, Field, validator\n\nclass MessageRequest(BaseModel):\n    session_id: str = Field(..., min_length=1, max_length=100, regex=r'^[a-zA-Z0-9_-]+$')\n    message: str = Field(..., min_length=1, max_length=10000)\n\n    @validator('message')\n    def validate_message(cls, v):\n        if '&lt;script&gt;' in v.lower():\n            raise ValueError('XSS attempt detected')\n        return v\n</code></pre>"},{"location":"technical-manual/security/#sql-injection-prevention","title":"SQL Injection Prevention","text":"<pre><code># \u2705 Good (parameterized)\nawait conn.execute(\n    \"SELECT * FROM sessions WHERE id = $1\",\n    session_id\n)\n\n# \u274c Bad (vulnerable)\nawait conn.execute(\n    f\"SELECT * FROM sessions WHERE id = '{session_id}'\"\n)\n</code></pre>"},{"location":"technical-manual/security/#command-injection-prevention","title":"Command Injection Prevention","text":"<pre><code>import shlex\n\n# \u2705 Good (escaped)\ncommand = [\"python\", \"-c\", shlex.quote(user_code)]\nsubprocess.run(command, timeout=30)\n\n# \u274c Bad (vulnerable)\nos.system(f\"python -c '{user_code}'\")\n</code></pre>"},{"location":"technical-manual/security/#audit-logging","title":"Audit Logging","text":""},{"location":"technical-manual/security/#security-events","title":"Security Events","text":"<pre><code>logger.warning(\n    \"authentication_failed\",\n    ip_address=request.client.host,\n    user_agent=request.headers.get(\"user-agent\"),\n    reason=\"invalid_token\"\n)\n\nlogger.info(\n    \"authorization_denied\",\n    user_id=user_id,\n    resource=\"tool_execution\",\n    action=\"execute\",\n    reason=\"policy_violation\"\n)\n</code></pre>"},{"location":"technical-manual/security/#audit-trail","title":"Audit Trail","text":"<p>Logged events: - Authentication attempts (success/failure) - Authorization decisions - Sensitive data access - Configuration changes - Admin actions</p> <p>Storage: PostgreSQL <code>audit_log</code> table</p> <pre><code>CREATE TABLE audit_log (\n    id SERIAL PRIMARY KEY,\n    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    event_type VARCHAR(50) NOT NULL,\n    user_id VARCHAR(100),\n    ip_address INET,\n    details JSONB,\n    INDEX idx_timestamp (timestamp),\n    INDEX idx_event_type (event_type)\n);\n</code></pre>"},{"location":"technical-manual/security/#vulnerability-management","title":"Vulnerability Management","text":""},{"location":"technical-manual/security/#dependency-scanning","title":"Dependency Scanning","text":"<pre><code># Python dependencies\npip-audit\n\n# Docker images\ntrivy image agent0ai/agent-zero:latest\n\n# Infrastructure as Code\ncheckov -d infra/\n</code></pre>"},{"location":"technical-manual/security/#security-updates","title":"Security Updates","text":"<p>Process: 1. Monitor CVE databases 2. Update dependencies weekly 3. Test in staging 4. Deploy to production 5. Document in changelog</p>"},{"location":"technical-manual/security/#penetration-testing","title":"Penetration Testing","text":"<p>Frequency: Quarterly</p> <p>Scope: - Authentication bypass - Authorization flaws - Injection attacks - XSS/CSRF - API abuse</p>"},{"location":"technical-manual/security/#incident-response","title":"Incident Response","text":""},{"location":"technical-manual/security/#security-incident-procedure","title":"Security Incident Procedure","text":"<ol> <li>Detect: Alert triggered or reported</li> <li>Contain: Isolate affected systems</li> <li>Investigate: Analyze logs, identify root cause</li> <li>Remediate: Apply fixes, rotate credentials</li> <li>Document: Write incident report</li> <li>Review: Update policies and procedures</li> </ol>"},{"location":"technical-manual/security/#emergency-contacts","title":"Emergency Contacts","text":"<ul> <li>Security Team: security@example.com</li> <li>On-Call: +1-555-0100</li> <li>Escalation: CTO, CISO</li> </ul>"},{"location":"technical-manual/security/#credential-rotation","title":"Credential Rotation","text":"<pre><code># Rotate JWT secret\nNEW_SECRET=$(openssl rand -base64 32)\nkubectl set env deployment/gateway JWT_SECRET=$NEW_SECRET\n\n# Rotate database password\npsql -c \"ALTER USER somauser WITH PASSWORD 'new-password';\"\nkubectl set env deployment/gateway POSTGRES_PASSWORD=new-password\n\n# Rotate API keys\npython scripts/rotate_api_keys.py --tenant acme\n</code></pre>"},{"location":"technical-manual/security/#compliance","title":"Compliance","text":""},{"location":"technical-manual/security/#gdpr","title":"GDPR","text":"<ul> <li>Right to access: Export user data via API</li> <li>Right to erasure: Delete user data on request</li> <li>Data portability: JSON export format</li> <li>Consent: Explicit opt-in for data processing</li> </ul>"},{"location":"technical-manual/security/#soc-2","title":"SOC 2","text":"<ul> <li>Access controls: RBAC with OPA/OpenFGA</li> <li>Encryption: TLS in transit, Fernet at rest</li> <li>Monitoring: Prometheus + Alertmanager</li> <li>Audit logs: All security events logged</li> </ul>"},{"location":"technical-manual/security/#hipaa-if-applicable","title":"HIPAA (if applicable)","text":"<ul> <li>PHI encryption: AES-256</li> <li>Access logs: All PHI access logged</li> <li>BAA: Business Associate Agreement required</li> <li>Breach notification: 60-day requirement</li> </ul>"},{"location":"technical-manual/security/#security-checklist","title":"Security Checklist","text":""},{"location":"technical-manual/security/#deployment","title":"Deployment","text":"<ul> <li>[ ] TLS enabled on all public endpoints</li> <li>[ ] Secrets stored in Vault or encrypted</li> <li>[ ] Firewall rules configured</li> <li>[ ] Network isolation enabled</li> <li>[ ] Strong passwords enforced</li> <li>[ ] JWT secrets rotated</li> <li>[ ] Database credentials unique per environment</li> <li>[ ] Audit logging enabled</li> <li>[ ] Monitoring and alerting configured</li> <li>[ ] Backup encryption enabled</li> </ul>"},{"location":"technical-manual/security/#development","title":"Development","text":"<ul> <li>[ ] Dependencies scanned for vulnerabilities</li> <li>[ ] Input validation on all endpoints</li> <li>[ ] SQL queries parameterized</li> <li>[ ] No hardcoded secrets in code</li> <li>[ ] Security headers configured</li> <li>[ ] CORS properly configured</li> <li>[ ] Rate limiting enabled</li> <li>[ ] Error messages don't leak sensitive info</li> </ul>"},{"location":"technical-manual/security/#operations","title":"Operations","text":"<ul> <li>[ ] Security patches applied monthly</li> <li>[ ] Access reviews quarterly</li> <li>[ ] Penetration testing quarterly</li> <li>[ ] Incident response plan tested</li> <li>[ ] Backup restoration tested</li> <li>[ ] Disaster recovery plan documented</li> </ul>"},{"location":"technical-manual/selective-authorization/","title":"Selective Authorization Model (Post OPA Middleware Removal)","text":"<p>We removed the legacy global <code>EnforcePolicy</code> middleware that caused health failures by calling a non-existent <code>/v1/policy/evaluate</code>. Authorization now occurs selectively on sensitive endpoints using a lightweight <code>PolicyClient</code> and helper <code>authorize()</code>.</p>"},{"location":"technical-manual/selective-authorization/#goals","title":"Goals","text":"<ol> <li>Fail-closed for security critical actions (memory writes, tool execution).  </li> <li>No startup coupling\u2014health endpoints remain green even if policy backend is down.  </li> <li>Low latency decision path with small response surface (boolean allow/deny).  </li> <li>Observable: decisions and latency metrics exported via Prometheus (<code>auth_decisions_total</code>, <code>auth_duration_seconds</code>).</li> </ol>"},{"location":"technical-manual/selective-authorization/#components","title":"Components","text":"Component File Responsibility <code>PolicyClient</code> <code>services/common/policy_client.py</code> HTTP evaluation against OPA data path; short TTL cache; fail-closed. <code>authorize()</code> <code>services/common/authorization.py</code> Wraps evaluation, records metrics, raises <code>403 policy_denied</code> on failure. <code>require_policy()</code> <code>services/common/authorization.py</code> Decorator for concise inline enforcement (future usage). Metrics <code>services/common/authorization.py</code> Decision counters + latency histogram."},{"location":"technical-manual/selective-authorization/#environment-variables","title":"Environment Variables","text":"Name Default Purpose <code>POLICY_BASE_URL</code> <code>http://opa:8181</code> Base URL of OPA/policy service. <code>POLICY_DATA_PATH</code> <code>/v1/data/soma/allow</code> Data path returning truthy allow decision. <code>POLICY_CACHE_TTL</code> <code>2</code> Seconds to cache identical decisions. <p>Note: <code>POLICY_FAIL_OPEN</code> is intentionally ignored\u2014system now fails closed for safety.</p>"},{"location":"technical-manual/selective-authorization/#metrics","title":"Metrics","text":"Metric Labels Description <code>auth_decisions_total</code> <code>action</code>, <code>result</code> (allow deny <code>auth_duration_seconds</code> <code>action</code> Latency histogram for decisions."},{"location":"technical-manual/selective-authorization/#current-enforcement-points","title":"Current Enforcement Points","text":"Endpoint Action Resource Context keys <code>POST /v1/learning/reward</code> <code>learning.reward</code> <code>learning</code> <code>session_id</code>, <code>signal</code> <code>POST /v1/tool/request</code> <code>tool.execute</code> <code>tool</code> <code>tool_name</code>, <code>session_id</code> <code>POST /v1/memory/batch</code> <code>memory.write</code> <code>memory</code> <code>batch_size</code> <code>GET /v1/admin/memory</code> <code>ops.memory.list</code> <code>OperationsAdministration</code> <code>tenant</code>, <code>persona_id</code>, <code>role</code>, <code>session_id</code> <code>GET /v1/admin/memory/{event_id}</code> <code>ops.memory.get</code> <code>OperationsAdministration</code> <code>event_id</code> <code>GET /v1/memory/export</code> <code>ops.memory.export.stream</code> <code>OperationsAdministration</code> filters (tenant/persona_id/role/session_id) <code>POST /v1/memory/export/jobs</code> <code>ops.memory.export.job.create</code> <code>OperationsAdministration</code> payload fields <code>GET /v1/memory/export/jobs/{job_id}</code> <code>ops.memory.export.job.status</code> <code>OperationsAdministration</code> <code>job_id</code> <code>GET /v1/memory/export/jobs/{job_id}/download</code> <code>ops.memory.export.job.download</code> <code>OperationsAdministration</code> <code>job_id</code> <code>GET /v1/admin/memory/metrics</code> <code>ops.memory.metrics</code> <code>OperationsAdministration</code> <code>tenant</code>, <code>namespace</code> <code>POST /v1/admin/migrate/export</code> <code>ops.migrate.export</code> <code>OperationsAdministration</code> payload fields <code>POST /v1/admin/migrate/import</code> <code>ops.migrate.import</code> <code>OperationsAdministration</code> <code>replace</code> <code>GET /v1/admin/dlq/{topic}</code> <code>ops.dlq.list</code> <code>OperationsAdministration</code> <code>topic</code> <code>DELETE /v1/admin/dlq/{topic}</code> <code>ops.dlq.purge</code> <code>OperationsAdministration</code> <code>topic</code> <code>POST /v1/admin/dlq/{topic}/{id}/reprocess</code> <code>ops.dlq.reprocess</code> <code>OperationsAdministration</code> <code>topic</code>, <code>id</code> <code>GET /v1/admin/audit/export</code> <code>ops.audit.export</code> <code>OperationsAdministration</code> filters (request_id/session_id/tenant/action) <code>GET /v1/admin/audit/decisions</code> <code>ops.audit.decisions.list</code> <code>OperationsAdministration</code> filters (tenant/session_id/request_id) <code>GET /constitution/version</code> <code>ops.constitution.version</code> <code>OperationsAdministration</code> \u2013 <code>POST /constitution/validate</code> <code>ops.constitution.validate</code> <code>OperationsAdministration</code> \u2013 <code>POST /constitution/load</code> <code>ops.constitution.load</code> <code>OperationsAdministration</code> \u2013 <p>Note: We collectively refer to the privileged operator/admin surface as \"OperationsAdministration\". These routes now perform selective policy checks in addition to existing scope checks.</p>"},{"location":"technical-manual/selective-authorization/#failure-modes","title":"Failure Modes","text":"Scenario Result HTTP Code Notes Policy allow Request continues 200/normal Decision cached (TTL). Policy deny Blocked 403 Audit handled by upstream layers (planned). Policy error/timeout Blocked (fail-closed) 403 Recorded as <code>result=error</code> metric then denial."},{"location":"technical-manual/selective-authorization/#rationale-for-selective-vs-global-middleware","title":"Rationale for Selective vs Global Middleware","text":"<p>Global middleware created a hard dependency on policy availability for every request including health probes, causing cascading failures and preventing stack bring-up. Selective enforcement isolates policy risk to sensitive domains only, improving reliability while preserving security posture.</p>"},{"location":"technical-manual/selective-authorization/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Decorator Adoption: Replace direct calls with <code>@require_policy(action, resource)</code> for cleaner routes.  </li> <li>Context Enrichment: Include <code>tenant</code>, <code>persona_id</code>, and redacted request body fields for finer-grained policies.  </li> <li>Audit Logging: Emit structured audit records on allow/deny including trace and request IDs.  </li> <li>OpenFGA Integration: Combine relationship checks (ownership, role) prior to policy evaluation.  </li> <li>Decision Bundling: Batch multiple tool calls decisions per request to reduce latency under high concurrency.  </li> </ol>"},{"location":"technical-manual/selective-authorization/#testing","title":"Testing","text":"<p>Unit tests: <code>tests/unit/test_selective_policy.py</code> cover allow, deny, error (fail-closed) paths by monkeypatching <code>PolicyClient.evaluate</code>. Integration tests (planned): exercise tool request and memory batch endpoints with mocked OPA service responses.</p>"},{"location":"technical-manual/selective-authorization/#quick-reference-usage","title":"Quick Reference (Usage)","text":"<pre><code>from services.common.authorization import authorize\n\n@app.post(\"/v1/tool/request\")\nasync def request_tool_execution(payload: ToolRequestPayload, request: Request):\n    await authorize(request, action=\"tool.execute\", resource=\"tool\", context={\"tool_name\": payload.tool_name})\n    # proceed\n</code></pre>"},{"location":"technical-manual/selective-authorization/#rollout-status","title":"Rollout Status","text":"<p>Selective auth deployed; global middleware removed. Health endpoints stable (200). Metrics available on <code>/metrics</code>.</p> <p>Maintainers: Security / Platform team. Update this document as new policy scopes are enforced.</p>"},{"location":"technical-manual/settings-routes/","title":"Settings &amp; Credentials Routes Catalog (Canonical)","text":"<p>Date: 2025-11-09 Scope: Authoritative list of Gateway settings/credentials endpoints, purpose, method, auth/policy, and notes.</p> <p>Legend - Auth: require_auth? (Y/N), Policy gate via OPA/OpenFGA? (Y/N) - Notes: short behavioral expectations; no secrets exposure rules</p>"},{"location":"technical-manual/settings-routes/#runtime-config-and-ui-settings","title":"Runtime-config and UI Settings","text":"<ul> <li>GET <code>/v1/runtime-config</code></li> <li>Auth: N (safe boot hints)</li> <li> <p>Notes: Returns UI-safe config; no secrets; reflects SSE/uploads flags and tool counts.</p> </li> <li> <p>GET <code>/v1/ui/settings/sections</code></p> </li> <li>Auth: N (read-only config for UI)</li> <li> <p>Notes: Normalized sections for SPA; source <code>UiSettingsStore</code>.</p> </li> <li> <p>POST <code>/v1/ui/settings/sections</code></p> </li> <li>Auth: Y when <code>REQUIRE_AUTH</code> and OPA enabled (policy enforced)</li> <li>Notes: Atomic write of UI sections, model profile upsert, and provider credential updates (keys prefixed <code>api_key_</code>). Emits masked audit diff and Kafka <code>config_updates</code> event.</li> </ul>"},{"location":"technical-manual/settings-routes/#model-profiles-llm","title":"Model Profiles &amp; LLM","text":"<ul> <li>POST <code>/v1/llm/test</code> (present in current gateway)</li> <li>Auth: Y (internal token)</li> <li> <p>Notes: Connectivity test for active profile; returns validation result; no raw secrets.</p> </li> <li> <p>POST <code>/v1/llm/invoke</code> and <code>/v1/llm/invoke/stream</code></p> </li> <li>Auth: Y (policy)</li> <li>Notes: Gateway resolves model/provider/base_url; workers/clients do not send base_url.</li> </ul>"},{"location":"technical-manual/settings-routes/#credentials-surface","title":"Credentials Surface","text":"<ul> <li>GET <code>/v1/ui/settings/credentials</code> (if present)</li> <li>Auth: Y (policy)</li> <li>Notes: Returns presence and timestamps only; never raw secret values.</li> </ul> <p>// Legacy credentials endpoints removed; use sections flow only.</p>"},{"location":"technical-manual/settings-routes/#audit-drift-planned","title":"Audit &amp; Drift (planned)","text":"<ul> <li>GET <code>/v1/config/drift</code> (planned M7)</li> <li>Auth: Y (policy)</li> <li> <p>Notes: Compares registry/db/cache versions; returns status ok|warning|critical.</p> </li> <li> <p>GET <code>/v1/audit/settings</code> (planned)</p> </li> <li>Auth: Y (policy)</li> <li>Notes: Returns masked diffs history for settings writes.</li> </ul>"},{"location":"technical-manual/settings-routes/#metrics-relevant-names","title":"Metrics (relevant names)","text":"<ul> <li><code>settings_read_total</code> \u2013 increments on settings reads.</li> <li><code>settings_write_total</code> \u2013 increments on settings writes.</li> <li><code>settings_write_latency_seconds</code> \u2013 histogram for write path.</li> </ul>"},{"location":"technical-manual/settings-routes/#references","title":"References","text":"<ul> <li>Gateway: <code>services/gateway/main.py</code></li> <li>Stores: <code>services/common/ui_settings_store.py</code>, <code>services/common/llm_credentials_store.py</code>, <code>services/common/model_profiles.py</code></li> <li>Metrics: <code>observability/metrics.py</code></li> <li>Audit schema: <code>schemas/audit/settings_write_diff.v1.schema.json</code></li> </ul>"},{"location":"technical-manual/somabrain-integration/","title":"SomaBrain Integration Guide","text":"<p>Date: 2025-11-03</p> <p>This document describes how SomaAgent01 integrates with SomaBrain across memory, recall, persona, policy, and ops. It covers API contracts we honor, runtime behaviors, and operator endpoints.</p>"},{"location":"technical-manual/somabrain-integration/#overview","title":"Overview","text":"<ul> <li>Client: <code>python/integrations/somabrain_client.py</code> (re-exported via <code>integrations/somabrain.py</code>) implements spec-compliant calls with defensive fallbacks and metrics.</li> <li>Runtime: Conversation Worker enriches memory writes with persona metadata; Gateway performs write-through when configured.</li> <li>Policy: Gateway evaluates OPA and (when configured) OpenFGA; decision receipts are recorded to the audit store.</li> <li>Ops: Admin endpoints expose SomaBrain memory metrics and migration (export/import) passthroughs.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#api-contracts","title":"API Contracts","text":"<ul> <li>remember: POST <code>/memory/remember</code></li> <li>No <code>coord</code> in the request (spec). Deterministic keys via payload/idempotency hashing.</li> <li>Universe is set via <code>metadata.universe_id</code> or client default <code>SOMA_NAMESPACE</code>.</li> <li>recall: POST <code>/memory/recall</code></li> <li>Prefer <code>?payload=&lt;json&gt;</code> query param. Fallback to JSON body. Legacy <code>/recall</code> fallback supported.</li> <li>recall stream: POST <code>/memory/recall/stream</code></li> <li>SSE-style event iterator. Prefer <code>?payload=&lt;json&gt;</code> first.</li> <li>persona: GET/PUT/DELETE <code>/persona/{id}</code> with ETag/If-Match semantics.</li> <li>constitution + OPA policy: <code>/constitution/*</code>, <code>/opa/policy</code> supported by the client and CLI.</li> <li>ops: <code>/memory/metrics</code>, <code>/migrate/export</code>, <code>/migrate/import</code>.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#persona-aware-memory-metadata","title":"Persona-aware Memory Metadata","text":"<p>File: <code>services/conversation_worker/main.py</code></p> <ul> <li>New helpers with TTL cache:</li> <li><code>_get_persona_cached(persona_id)</code>: fetches persona from SomaBrain and caches for <code>SOMABRAIN_PERSONA_TTL_SECONDS</code> (default 10s).</li> <li><code>_augment_metadata_with_persona(meta, persona)</code>: adds <code>persona_name</code>, <code>persona_updated_at</code>, and <code>persona_tags</code> (up to 8).</li> <li>Applied to both user and assistant memory writes in the Conversation Worker.</li> <li>Fail-safe: if persona fetch fails, enrichment is skipped; core behavior unchanged.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#gateway-admin-endpoints","title":"Gateway Admin Endpoints","text":"<p>File: <code>services/gateway/main.py</code></p> <ul> <li>GET <code>/v1/admin/memory/metrics</code></li> <li>Params: <code>tenant</code> (required), <code>namespace</code> (default <code>wm</code>)</li> <li>Authorization: admin scope required; optional admin rate limiting.</li> <li> <p>Proxies SomaBrain <code>/memory/metrics</code>.</p> </li> <li> <p>POST <code>/v1/admin/migrate/export</code></p> </li> <li>Body: <code>{ include_wm: bool = true, wm_limit: int = 128 }</code></li> <li>Authorization: admin scope required; rate limited.</li> <li> <p>Proxies SomaBrain <code>/migrate/export</code>.</p> </li> <li> <p>POST <code>/v1/admin/migrate/import</code></p> </li> <li>Body: <code>{ manifest: object, memories: object[], wm?: object[], replace?: bool }</code></li> <li>Authorization: admin scope required; rate limited.</li> <li>Proxies SomaBrain <code>/migrate/import</code>.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#policy-decision-receipts","title":"Policy Decision Receipts","text":"<p>File: <code>services/gateway/main.py</code></p> <ul> <li><code>_evaluate_opa(...)</code> now returns a decision receipt <code>{ allow, url, status_code, decision }</code> and blocks on deny.</li> <li><code>authorize_request(...)</code> emits an audit event <code>auth.decision</code> with:</li> <li>OPA receipt (or <code>skipped</code> when OPA is disabled)</li> <li>OpenFGA enforcement result <code>{ enforced: bool, allowed?: bool }</code></li> <li><code>tenant</code>, <code>subject</code>, <code>scope</code>, request path, IP, user-agent</li> <li>Logging is best-effort; failures to write audit events do not impact the request flow.</li> <li>OpenFGA behavior in dev/unit contexts: if not configured (missing <code>OPENFGA_STORE_ID</code>), enforcement is skipped but a receipt is still emitted with <code>enforced=false</code>.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#metrics","title":"Metrics","text":"<ul> <li><code>gateway_auth_opa_decisions_total{outcome}</code>: OPA policy outcomes</li> <li>outcomes: <code>allow</code>, <code>deny</code>, <code>skipped</code>, <code>error</code></li> <li><code>gateway_auth_fga_decisions_total{enforced,outcome}</code>: OpenFGA outcomes</li> <li><code>enforced</code>: <code>true</code> or <code>false</code></li> <li><code>outcome</code>: <code>allowed</code>, <code>denied</code>, <code>skipped</code>, <code>error</code></li> </ul>"},{"location":"technical-manual/somabrain-integration/#constitution-pass-through-endpoints-gateway","title":"Constitution Pass-Through Endpoints (Gateway)","text":"<p>File: <code>services/gateway/main.py</code></p> <ul> <li><code>GET /constitution/version</code>: proxies SomaBrain version/metadata.</li> <li><code>POST /constitution/validate</code>: proxies validation of a constitution document; post body forwarded verbatim.</li> <li><code>POST /constitution/load</code>: proxies load of a constitution; after success, Gateway performs a best\u2011effort OPA policy regeneration via <code>POST /opa/policy</code>.</li> </ul> <p>Auth &amp; Policy - All three routes require authentication and admin scope; OPA is evaluated with <code>{ action: \"constitution.manage\", resource: \"somabrain\" }</code> in the request context. - Default OPA decision path: <code>/v1/data/soma/policy/allow</code> (override with <code>OPA_DECISION_PATH</code>).</p>"},{"location":"technical-manual/somabrain-integration/#audit-decision-receipts-gateway","title":"Audit Decision Receipts (Gateway)","text":"<ul> <li>Gateway emits <code>auth.decision</code> audit events for every authorized request with structured details:</li> <li><code>details.opa</code>: <code>{ allow, url, status_code, decision }</code> or <code>{ skipped: true }</code> when OPA_URL is unset.</li> <li><code>details.openfga</code>: <code>{ enforced: true, allowed }</code> or <code>{ enforced: false, reason: \"not_configured\" }</code>.</li> <li> <p><code>details.scope</code>: captured scope string (if any) from the JWT.</p> </li> <li> <p>Admin API to list recent decision receipts:</p> </li> <li><code>GET /v1/admin/audit/decisions?tenant=&amp;session_id=&amp;request_id=&amp;subject=&amp;from_ts=&amp;to_ts=&amp;after=&amp;limit=</code></li> <li>Returns <code>{ items: [ { id, ts, tenant, subject, resource, details, ... } ], next_cursor }</code>.</li> <li>Requires admin scope when auth is enabled.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#web-ui-admin-wiring","title":"Web UI (Admin) Wiring","text":"<p>The Web UI exposes lightweight admin tools wired to the endpoints above.</p> <ul> <li>Decisions Viewer</li> <li>Open the left sidebar and click \u201cDecisions\u201d to launch the modal at <code>webui/components/admin/decisions.html</code>.</li> <li>The grid lists recent <code>auth.decision</code> receipts fetched from <code>GET /v1/admin/audit/decisions</code> with filter fields (tenant, session_id, request_id, subject, from_ts, to_ts) and pagination via <code>next_cursor</code>.</li> <li>Use \u201cExport NDJSON\u201d to download an NDJSON stream from <code>GET /v1/admin/audit/export?action=auth.decision</code> with the same filters applied, including the time range and subject.</li> <li> <p>Authorization: requires admin scope when <code>GATEWAY_REQUIRE_AUTH=true</code>. UI surfaces 401/403 as an inline banner.</p> </li> <li> <p>Constitution Tools</p> </li> <li>Click \u201cConstitution\u201d to open <code>webui/components/admin/constitution.html</code>.</li> <li>Version: calls <code>GET /constitution/version</code> and shows the current SomaBrain constitution metadata.</li> <li>Validate: paste a JSON document, posts <code>{ document: &lt;json&gt; }</code> to <code>POST /constitution/validate</code>.</li> <li>Load: posts <code>{ document: &lt;json&gt; }</code> to <code>POST /constitution/load</code> and, on success, Gateway triggers an OPA policy regeneration (<code>POST /opa/policy</code>).</li> <li>Authorization: admin scope required when auth is enabled; OPA decision path defaults to <code>/v1/data/soma/policy/allow</code>.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#optional-semantics-planning-hooks","title":"Optional Semantics &amp; Planning Hooks","text":"<p>File: <code>services/tool_executor/main.py</code></p> <ul> <li>After successful tool result memory write, optional calls to SomaBrain <code>link</code> and <code>plan_suggest</code> are performed.</li> <li>Guarded by <code>SOMABRAIN_ENABLE_LINK_PLAN</code> environment flag; failures do not affect main flow.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#cli-enhancements-where-present","title":"CLI Enhancements (where present)","text":"<ul> <li><code>scripts/constitution_admin.py</code> (if present)</li> <li>Payload dual-shape for validate/load: <code>{ input: doc, document: doc }</code></li> <li><code>load</code> triggers OPA policy regeneration via <code>POST /opa/policy</code></li> <li> <p>New <code>status</code> command shows constitution version and OPA policy hash.</p> </li> <li> <p><code>scripts/persona_admin.py</code> (if present)</p> </li> <li>Persona CAS CLI for GET/PUT/DELETE with ETag/If-Match support and conflict handling.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#testing","title":"Testing","text":"<ul> <li>Unit tests added for admin endpoints:</li> <li><code>tests/unit/test_admin_somabrain_endpoints.py</code></li> <li>Existing tests cover constitution CLI and persona CLI behaviors.</li> <li>Note: E2E tests require optional multimedia deps; unit tests cover new features without those deps.</li> </ul>"},{"location":"technical-manual/somabrain-integration/#configuration","title":"Configuration","text":"<ul> <li><code>SOMA_BASE_URL</code> default: <code>http://localhost:9696</code></li> <li><code>SOMA_NAMESPACE</code>: universe_id fallback; included in memory metadata.</li> <li><code>SOMABRAIN_PERSONA_TTL_SECONDS</code>: persona cache TTL (default 10s)</li> <li><code>GATEWAY_ADMIN_RPS</code>, <code>GATEWAY_ADMIN_BURST</code>: admin endpoint rate limit</li> <li><code>OPA_URL</code>, <code>OPA_DECISION_PATH</code>: OPA location and decision entrypoint</li> <li><code>OPENFGA_STORE_ID</code>: enable OpenFGA enforcement; when omitted, enforcement is skipped with a decision receipt</li> </ul>"},{"location":"technical-manual/somabrain-integration/#runbooks-brief","title":"Runbooks (brief)","text":"<ul> <li>Metrics: <code>GET /v1/admin/memory/metrics?tenant=&lt;id&gt;&amp;namespace=wm</code></li> <li>Export: <code>POST /v1/admin/migrate/export</code> with <code>{ \"include_wm\": true, \"wm_limit\": 128 }</code></li> <li>Import: <code>POST /v1/admin/migrate/import</code> with <code>{ manifest, memories, wm?, replace? }</code></li> </ul>"},{"location":"technical-manual/somabrain-integration/#non-goals","title":"Non-goals","text":"<ul> <li>No local constitution storage or signing in this repo; all constitution concerns remain in SomaBrain.</li> <li>No RAG; retrieval is via SomaBrain recall endpoints only.</li> </ul>"},{"location":"technical-manual/tools-messages-memories/","title":"Tools, Messages, and Memories Flow","text":"<p>This document describes how user messages flow through the system, how tools are executed, and how memories are persisted to SomaBrain. It also clarifies reliability features like WAL/outbox and authorization gates.</p>"},{"location":"technical-manual/tools-messages-memories/#overview","title":"Overview","text":"<ul> <li>UI sends user messages and uploads to the Gateway.</li> <li>Gateway publishes message events to Kafka, persists timeline, and (optionally) writes-through to SomaBrain with WAL/outbox.</li> <li>Conversation Worker invokes the LLM via Gateway, streams assistant tokens, and writes user/assistant memories.</li> <li>Tool Executor executes tool requests and publishes tool results, writing tool_result memories.</li> <li>UI renders assistant/tool events via SSE and a poll fallback.</li> </ul>"},{"location":"technical-manual/tools-messages-memories/#e2e-smoke-and-verification","title":"E2E smoke and verification","text":"<p>Run a lightweight browser smoke to validate the full path (UI \u2194 Gateway \u2194 Kafka \u2194 Workers \u2194 SomaBrain):</p> <ul> <li>Prereqs: Gateway, Conversation Worker, Tool Executor, Kafka, Redis, Postgres, SomaBrain running locally.</li> <li>Base URL: set UI_BASE_URL or WEB_UI_BASE_URL (default http://localhost:21016/).</li> <li>What it checks:</li> <li>UI loads without console errors.</li> <li>Chat input issues POST /v1/session/message.</li> <li>Optional: detects an AI reply element if workers are active.</li> </ul> <p>Quick runs:</p> <pre><code># Python pytest-based smoke (simple selectors)\npytest -q tests/e2e/test_ui_smoke.py -k smoke\n\n# Async Playwright script with console/network capture\npython tests/playwright/test_ui_smoke.py\n</code></pre> <p>Verify persistence:</p> <ul> <li>Check memory replica rows:</li> <li>GET /v1/admin/memory?tenant=&amp;session_id= (requires admin scope when auth enabled) <li>Inspect WAL/consumer lag:</li> <li>GET /v1/admin/kafka/status?topic=memory.wal&amp;group=memory-replicator</li> <li>Confirm tool schemas for prompts/UI:</li> <li>GET /v1/tools (names, descriptions, parameters JSON Schema)</li> <p>Key environment variables:</p> <ul> <li>SOMA_BASE_URL, SOMA_TENANT_ID, SOMA_NAMESPACE, MEMORY_WAL_TOPIC</li> <li>GATEWAY_WRITE_THROUGH, GATEWAY_WRITE_THROUGH_ASYNC (optional write-through)</li> <li>WORKER_GATEWAY_BASE (Conversation Worker \u2192 Gateway surface)</li> <li>TOOL_REQUESTS_TOPIC, TOOL_RESULTS_TOPIC (Kafka topics; defaults are sensible)</li> </ul>"},{"location":"technical-manual/tools-messages-memories/#mermaid-sequence","title":"Mermaid sequence","text":"<pre><code>sequenceDiagram\n    participant UI as Web UI\n    participant GW as Gateway\n    participant PG as Postgres (timeline)\n    participant K as Kafka\n    participant CW as Conversation Worker\n    participant LLM as LLM Provider(s)\n    participant TE as Tool Executor\n    participant SB as SomaBrain (Memories)\n\n    UI-&gt;&gt;GW: POST /v1/session/message (+/v1/uploads)\n    GW-&gt;&gt;PG: append_event(type=user)\n    GW-&gt;&gt;K: publish conversation.inbound\n    alt write-through enabled\n        GW-&gt;&gt;SB: remember(type=conversation_event, role=user)\n        GW-&gt;&gt;K: publish memory.wal (result)\n    end\n\n    K--&gt;&gt;CW: conversation.inbound\n    CW-&gt;&gt;GW: POST /v1/llm/invoke(/stream)\n    GW--&gt;&gt;CW: tokens/response\n    CW-&gt;&gt;PG: append_event(type=assistant)\n    alt write-through enabled\n        CW-&gt;&gt;SB: remember(type=assistant)\n        CW-&gt;&gt;K: publish memory.wal (result)\n    end\n    GW--&gt;&gt;UI: SSE /v1/session/{id}/events (assistant)\n\n    opt large/expensive attachment\n        CW-&gt;&gt;K: publish tool.requests (document_ingest)\n    end\n\n    K--&gt;&gt;TE: tool.requests\n    TE-&gt;&gt;TE: execute tool (policy, telemetry)\n    TE-&gt;&gt;PG: append_event(type=tool)\n    TE-&gt;&gt;K: publish tool.results\n    alt policy allows memory\n        TE-&gt;&gt;SB: remember(type=tool_result)\n        TE-&gt;&gt;K: publish memory.wal (result)\n    end\n    GW--&gt;&gt;UI: SSE /v1/session/{id}/events (tool)\n</code></pre>"},{"location":"technical-manual/tools-messages-memories/#contracts-tiny","title":"Contracts (tiny)","text":"<ul> <li>Conversation event (user/assistant)</li> <li>Keys: event_id, session_id, role, message/content, attachments[], metadata{}</li> <li>Guarantees: appended to timeline; optional memory write-through guarded by OPA; WAL/outbox for durability</li> <li>Tool request</li> <li>Keys: event_id, session_id, persona_id, tool_name, args{}, metadata{}</li> <li>Policy: tool.execute enforced in Tool Executor</li> <li>Tool result</li> <li>Keys: event_id, session_id, persona_id, tool_name, status, payload, metadata{}</li> <li>Persisted: timeline + memory(type=tool_result) if policy allows</li> </ul>"},{"location":"technical-manual/tools-messages-memories/#reliability-and-policy","title":"Reliability and policy","text":"<ul> <li>OPA pre-checks on memory.write in Worker and Tool Executor</li> <li>WAL publish (memory.wal) after successful remember; Gateway/Worker/Tool Executor enqueue memory writes into a retry outbox on failure</li> <li>Session cache (Redis) stores persona/tenant context for quick access and UI controls</li> </ul>"},{"location":"technical-manual/tools-messages-memories/#tool-invocation-from-chat","title":"Tool invocation from chat","text":"<p>There are two coordinated paths, and both are implemented:</p> <p>1) Model-led orchestration (Conversation Worker) - The worker exposes available tools (with JSON Schemas) to the LLM using the OpenAI tools API contract. - When the model emits tool_calls during streaming, the worker publishes tool.requests, waits for tool.results (correlated via request_id), injects the results into the message context, and continues the generation to produce the final assistant answer. - Policy is still enforced at execution time by the Tool Executor.</p> <p>2) UI affordance (Gateway + Web UI) - POST /v1/tool/request allows clients to publish tool.requests directly. - The Web UI supports a slash command: <code>/tool &lt;tool_name&gt; &lt;json-args&gt;</code>.</p> <p>Tool discovery - GET /v1/tools returns the in-repo Tool Registry with name, description, and input parameters (JSON Schema) so prompts and UIs can stay aligned with runtime capabilities.</p>"},{"location":"technical-manual/tools-messages-memories/#attachments-and-ingestion","title":"Attachments and ingestion","text":"<p>Uploads are handled by the Gateway via <code>/v1/uploads</code>, which returns attachment references like <code>/v1/attachments/{id}</code>. Services ingest by ID; no filesystem paths are required.</p>"},{"location":"technical-manual/tools-messages-memories/#internal-service-to-service-attachments-api","title":"Internal service-to-service attachments API","text":"<p>To support ingestion without exposing raw bytes publicly, the Gateway provides an internal S2S endpoint secured by an internal token:</p> <ul> <li>GET <code>/internal/attachments/{id}/binary</code></li> <li>Headers:<ul> <li><code>X-Internal-Token: &lt;token&gt;</code> (must match <code>GATEWAY_INTERNAL_TOKEN</code>)</li> <li>Optional: <code>X-Tenant-Id: &lt;tenant&gt;</code> for tenant scoping</li> </ul> </li> <li>Response headers include:<ul> <li><code>Content-Type</code></li> <li><code>Content-Disposition</code> (with filename)</li> <li><code>X-Attachment-Status</code> (<code>clean</code> | <code>quarantined</code>)</li> <li><code>X-Attachment-Size</code> (bytes)</li> </ul> </li> <li> <p>Behavior: Allows retrieval even when status is <code>quarantined</code>; callers must enforce policy.</p> </li> <li> <p>HEAD <code>/internal/attachments/{id}/binary</code></p> </li> </ul> <p>Public download remains available at GET <code>/v1/attachments/{id}</code>, which blocks <code>quarantined</code> payloads.</p>"},{"location":"technical-manual/tools-messages-memories/#ingestion-by-id-flow","title":"Ingestion by ID flow","text":"<ul> <li>UI uploads via <code>/v1/uploads</code> produce <code>/v1/attachments/{id}</code> references.</li> <li>Conversation Worker parses the attachment ID from that path and:</li> <li> <p>HEADs the internal endpoint to get <code>X-Attachment-Size</code>.</p> </li> <li> <p>The <code>document_ingest</code> tool fetches bytes from the internal endpoint using <code>X-Internal-Token</code>, extracts text (text/PDF/IMG), and returns the result.</p> </li> </ul>"},{"location":"technical-manual/tools-messages-memories/#ports-and-environment-alignment","title":"Ports and environment alignment","text":"<ul> <li>Gateway host port: 21016 (set <code>GATEWAY_PORT=21016</code> in Docker Compose)</li> <li>SomaBrain base URL: <code>http://host.docker.internal:9696</code> (propagated via <code>SOMA_BASE_URL</code>)</li> <li>Internal token: set the same <code>GATEWAY_INTERNAL_TOKEN</code> for Gateway and all internal callers (Worker, Tool Executor)</li> </ul>"},{"location":"technical-manual/runbooks/circuit-breaker/","title":"Runbook: Circuit Breaker Open","text":"<p>Placeholder. Document procedures when circuit breaker is open.</p>"},{"location":"technical-manual/runbooks/high-error-rate/","title":"Runbook: High Error Rate","text":"<p>Placeholder. Describe steps to investigate elevated 5xx responses.</p>"},{"location":"technical-manual/runbooks/high-latency/","title":"Runbook: High Latency","text":"<p>Placeholder. Describe steps to diagnose increased P95 latency.</p>"},{"location":"technical-manual/runbooks/kafka-lag/","title":"Runbook: Kafka Consumer Lag","text":"<p>Placeholder. Outline steps to inspect consumer lag and remediate.</p>"},{"location":"testing/architecture/","title":"Testing Architecture (Live-First)","text":"<p>This repository adopts a live-first testing strategy: tests are designed to exercise real services (Gateway, workers, Postgres, Kafka, OPA, Redis) without mocks, matching how the stack runs in development and production.</p>"},{"location":"testing/architecture/#test-layers","title":"Test Layers","text":"<ul> <li>Unit (fast, pure-Python logic) \u2014 used sparingly; prefer live modules where possible.</li> <li>Integration (<code>@pytest.mark.live</code>, <code>@pytest.mark.db</code>, <code>@pytest.mark.kafka</code>, <code>@pytest.mark.gateway</code>) \u2014 validate concrete flows against running services.</li> <li>E2E (<code>@pytest.mark.e2e</code>) \u2014 cross-service journeys (document ingest, memory write-through, chat SSE flows, UI checks).</li> </ul>"},{"location":"testing/architecture/#markers","title":"Markers","text":"<p>Registered in <code>pytest.ini</code>: - <code>live</code>: requires full stack. - <code>db</code>, <code>kafka</code>, <code>gateway</code>: target specific subsystems. - <code>e2e</code>, <code>playwright</code>: cross-service + UI flows. - <code>smoke</code>, <code>slow</code>, <code>performance</code>, <code>critical</code>, <code>flaky</code>, <code>optional</code>.</p>"},{"location":"testing/architecture/#running-against-real-services","title":"Running Against Real Services","text":"<p>Use Make targets to bring up the stack and run tests against it.</p> <pre><code># Start deps + stack, then run full suite\nmake test-live\n\n# Or run only e2e\nmake deps-up-live &amp;&amp; pytest -vv -m e2e\n\n# Health check\nmake health\n</code></pre>"},{"location":"testing/architecture/#reliability-patterns","title":"Reliability Patterns","text":"<ul> <li>Prefer event-driven waiting over sleeps. Use <code>tests/utils.py::wait_for</code> and <code>wait_for_event</code>.</li> <li>Avoid swallowing exceptions in tests. Convert to explicit assertions or reasoned skips (with message).</li> <li>Consolidate duplicate coverage into parametrized tests.</li> </ul>"},{"location":"testing/architecture/#deletions-quarantine","title":"Deletions &amp; Quarantine","text":"<ul> <li>Capsule-related tests are obsolete and will be removed.</li> <li>Heavy live-only suites can be tagged <code>e2e</code> or <code>optional</code> depending on CI profile. The default developer workflow is live-first; CI may run a selected subset as smoke.</li> </ul>"},{"location":"testing/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Replace ad-hoc <code>sleep</code> polling with <code>wait_for</code>.</li> <li>Strengthen trivial \"length-only\" assertions with structural guarantees (schema, ordering, types).</li> <li>Reduce unknown mark warnings by using registered markers.</li> </ul>"},{"location":"user-manual/","title":"User Manual","text":"<p>Standards: ISO 21500\u00a74.2</p>"},{"location":"user-manual/#overview","title":"Overview","text":"<p>SomaAgent01 provides a conversational AI interface accessible via Web UI or API.</p>"},{"location":"user-manual/#quick-start","title":"Quick Start","text":""},{"location":"user-manual/#docker-recommended","title":"Docker (Recommended)","text":"<pre><code>docker pull agent0ai/agent-zero\ndocker run -p 50001:80 agent0ai/agent-zero\n</code></pre> <p>Visit <code>http://localhost:50001</code></p>"},{"location":"user-manual/#local-development","title":"Local Development","text":"<pre><code># 1. Start infrastructure\nmake deps-up\n\n# 2. Start services\nmake stack-up\n\n# 3. Start UI\nmake ui\n</code></pre> <p>Visit <code>http://127.0.0.1:3000</code></p>"},{"location":"user-manual/#features","title":"Features","text":"<ul> <li>Conversational Interface: Chat with AI assistant</li> <li>Memory: Persistent conversation history</li> <li>Multi-agent: Delegate subtasks to subordinate agents</li> <li>Tools: Code execution, web search, file operations</li> <li>Streaming: Real-time response streaming</li> <li>Attachments: Upload files for context</li> </ul>"},{"location":"user-manual/#system-requirements","title":"System Requirements","text":"<ul> <li>Docker: 20.10+ (for containerized deployment)</li> <li>Python: 3.11+ (for local development)</li> <li>Memory: 8GB RAM minimum</li> <li>Storage: 10GB available space</li> </ul>"},{"location":"user-manual/#ports","title":"Ports","text":"Service Port Purpose UI 20015 Web interface Gateway 21016 API endpoint (configurable via GATEWAY_PORT) Kafka 20000 Event streaming Redis 20001 Cache PostgreSQL 20002 Database OPA 20009 Policy engine"},{"location":"user-manual/#related-documents","title":"Related Documents","text":"<ul> <li>Installation Guide</li> <li>Usage Guide</li> <li>Troubleshooting</li> </ul>"},{"location":"user-manual/faq/","title":"Frequently Asked Questions","text":"<p>Standards: ISO/IEC 21500\u00a77.4</p>"},{"location":"user-manual/faq/#general","title":"General","text":""},{"location":"user-manual/faq/#what-is-somaagent01","title":"What is SomaAgent01?","text":"<p>SomaAgent01 is a microservices-based conversational AI platform built on Agent Zero framework. It provides a general-purpose AI assistant with code execution, memory, and multi-agent capabilities.</p>"},{"location":"user-manual/faq/#what-llm-providers-are-supported","title":"What LLM providers are supported?","text":"<ul> <li>OpenRouter (default)</li> <li>OpenAI</li> <li>Anthropic</li> <li>Groq</li> <li>Venice.ai</li> <li>GitHub Copilot</li> <li>Local models (via LiteLLM)</li> </ul>"},{"location":"user-manual/faq/#is-my-data-secure","title":"Is my data secure?","text":"<p>Yes. All credentials are encrypted (Fernet), sessions are isolated by tenant, and OPA policies enforce access control. See Security for details.</p>"},{"location":"user-manual/faq/#installation","title":"Installation","text":""},{"location":"user-manual/faq/#what-are-the-minimum-requirements","title":"What are the minimum requirements?","text":"<ul> <li>8GB RAM</li> <li>10GB disk space</li> <li>Docker 20.10+ or Python 3.11+</li> </ul>"},{"location":"user-manual/faq/#can-i-run-without-docker","title":"Can I run without Docker?","text":"<p>Yes. Use <code>make deps-up</code> for infrastructure, then <code>make stack-up</code> for services. See Installation Guide.</p>"},{"location":"user-manual/faq/#which-ports-are-required","title":"Which ports are required?","text":"<p>Core ports: 20000 (Kafka), 20001 (Redis), 20002 (PostgreSQL), 21016 (Gateway). See Port Reference.</p>"},{"location":"user-manual/faq/#usage","title":"Usage","text":""},{"location":"user-manual/faq/#how-do-i-save-conversations","title":"How do I save conversations?","text":"<p>Conversations are automatically saved to PostgreSQL. Use the UI's \"Export Chat\" button to download as JSON.</p>"},{"location":"user-manual/faq/#can-i-use-custom-tools","title":"Can I use custom tools?","text":"<p>Yes. Create tools in <code>python/tools/</code> following the existing pattern. See Extensibility.</p>"},{"location":"user-manual/faq/#how-does-memory-work","title":"How does memory work?","text":"<p>Short-term memory is in-session context. Long-term memory is stored in SomaBrain (port 9696) and persisted across sessions.</p>"},{"location":"user-manual/faq/#can-agents-access-the-internet","title":"Can agents access the internet?","text":"<p>Yes, via web search tools (DuckDuckGo, SearXNG) and browser agent (Playwright).</p>"},{"location":"user-manual/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-manual/faq/#gateway-returns-500-errors","title":"Gateway returns 500 errors","text":"<p>Check logs: <code>docker compose logs gateway</code>. Common causes: - Kafka not ready - PostgreSQL connection failed - Missing environment variables</p>"},{"location":"user-manual/faq/#agent-responses-are-slow","title":"Agent responses are slow","text":"<p>Check: - LLM provider rate limits - Network latency to LLM API - Kafka consumer lag: <code>docker compose logs conversation-worker</code></p>"},{"location":"user-manual/faq/#memory-not-persisting","title":"Memory not persisting","text":"<p>Verify SomaBrain is running: <pre><code>curl http://localhost:9696/health\n</code></pre></p> <p>If not, check <code>docker compose logs somabrain</code>.</p>"},{"location":"user-manual/faq/#ui-wont-load","title":"UI won't load","text":"<ol> <li>Check gateway health: <code>curl http://localhost:${GATEWAY_PORT:-21016}/v1/health</code></li> <li>Check UI logs: <code>docker compose logs ui</code></li> <li>Clear browser cache</li> </ol>"},{"location":"user-manual/faq/#development","title":"Development","text":""},{"location":"user-manual/faq/#how-do-i-contribute","title":"How do I contribute?","text":"<p>See Contribution Workflow.</p>"},{"location":"user-manual/faq/#how-do-i-run-tests","title":"How do I run tests?","text":"<pre><code>pytest tests/unit/\npytest tests/integration/\n</code></pre>"},{"location":"user-manual/faq/#how-do-i-add-a-new-service","title":"How do I add a new service?","text":"<ol> <li>Create service in <code>services/&lt;name&gt;/</code></li> <li>Add to <code>docker-compose.yaml</code></li> <li>Update documentation</li> <li>Add tests</li> </ol>"},{"location":"user-manual/faq/#support","title":"Support","text":""},{"location":"user-manual/faq/#where-can-i-get-help","title":"Where can I get help?","text":"<ul> <li>GitHub Issues: https://github.com/somatechlat/somaagent01/issues</li> <li>Discord: https://discord.gg/B8KZKNsPpj</li> <li>Documentation: https://docs.somaagent01.ai</li> </ul>"},{"location":"user-manual/faq/#how-do-i-report-a-bug","title":"How do I report a bug?","text":"<p>Open a GitHub issue with: - Steps to reproduce - Expected vs actual behavior - Logs (<code>docker compose logs</code>) - Environment details</p>"},{"location":"user-manual/faq/#is-there-a-community","title":"Is there a community?","text":"<p>Yes! Join our Discord server and Skool community. Links in README.</p>"},{"location":"user-manual/features/","title":"Features Overview","text":"<p>Standards: ISO/IEC 29148\u00a75.3</p>"},{"location":"user-manual/features/#core-features","title":"Core Features","text":""},{"location":"user-manual/features/#conversational-interface","title":"Conversational Interface","text":"<p>Chat with the AI assistant using natural language. The agent understands context and maintains conversation history.</p> <p>Example: <pre><code>User: What's the weather like?\nAgent: I'll search for current weather information...\n</code></pre></p>"},{"location":"user-manual/features/#code-execution","title":"Code Execution","text":"<p>The agent can write and execute code in multiple languages: - Python - JavaScript - Bash/Shell - SQL</p> <p>Example: <pre><code>User: Calculate the factorial of 10\nAgent: [Writes Python code, executes it, returns result]\n</code></pre></p>"},{"location":"user-manual/features/#memory-system","title":"Memory System","text":"<p>Persistent memory across sessions: - Short-term: Current conversation context - Long-term: Facts, preferences, solutions stored in SomaBrain</p> <p>Example: <pre><code>User: Remember my email is user@example.com\nAgent: \u2705 Saved to memory\n</code></pre></p> <p>Persona-aware metadata: - Runtime memory writes include persona summaries (name, tags) to improve downstream filtering and analysis.     - Config: <code>SOMABRAIN_PERSONA_TTL_SECONDS</code> controls persona cache TTL.</p>"},{"location":"user-manual/features/#multi-agent-cooperation","title":"Multi-Agent Cooperation","text":"<p>Delegate complex tasks to subordinate agents: - Main agent breaks down tasks - Subordinates work in parallel - Results aggregated and reported back</p> <p>Example: <pre><code>User: Analyze these 5 datasets simultaneously\nAgent: Creating 5 subordinate agents...\n</code></pre></p>"},{"location":"user-manual/features/#tool-ecosystem","title":"Tool Ecosystem","text":"<p>Built-in tools: - Web Search: DuckDuckGo, SearXNG integration - File Operations: Read, write, manage files - Browser Agent: Automated web browsing - Document Query: RAG-based document Q&amp;A - Scheduler: Task scheduling and automation</p>"},{"location":"user-manual/features/#streaming-responses","title":"Streaming Responses","text":"<p>Real-time response streaming: - See agent thinking process - Intervene at any point - Stop/pause execution</p>"},{"location":"user-manual/features/#attachments","title":"Attachments","text":"<p>Upload files for context: - Documents (PDF, TXT, MD) - Images (PNG, JPG) - Code files - Data files (CSV, JSON)</p>"},{"location":"user-manual/features/#advanced-features","title":"Advanced Features","text":""},{"location":"user-manual/features/#agent-profiles","title":"Agent Profiles","text":"<p>Different agent personalities: - Default: General-purpose assistant - Developer: Code-focused agent - Researcher: Research and analysis - Hacker: Security testing (Kali Linux)</p>"},{"location":"user-manual/features/#mcp-integration","title":"MCP Integration","text":"<p>Model Context Protocol support: - Connect to external MCP servers - Use third-party tools - Extend agent capabilities</p>"},{"location":"user-manual/features/#a2a-protocol","title":"A2A Protocol","text":"<p>Agent-to-Agent communication: - Connect multiple agent instances - Distributed task processing - Cross-agent memory sharing</p>"},{"location":"user-manual/features/#secrets-management","title":"Secrets Management","text":"<p>Secure credential storage: - Agents use credentials without seeing them - Fernet encryption - Vault integration (optional)</p>"},{"location":"user-manual/features/#admin-ops-somabrain","title":"Admin Ops (SomaBrain)","text":"<p>Operator-focused endpoints (admin scope required): - <code>GET /v1/admin/memory/metrics</code> \u2192 SomaBrain memory metrics for a tenant/namespace - <code>POST /v1/admin/migrate/export</code> \u2192 export memory state - <code>POST /v1/admin/migrate/import</code> \u2192 import memory state</p> <p>Policy decision receipts are captured for every protected call when OPA/OpenFGA are configured, aiding audits and troubleshooting.</p>"},{"location":"user-manual/features/#next-steps","title":"Next Steps","text":"<ul> <li>Installation Guide</li> <li>FAQ</li> <li>Technical Manual</li> </ul>"},{"location":"user-manual/installation/","title":"Installation Guide","text":"<p>Standards: ISO/IEC 12207\u00a76.4</p>"},{"location":"user-manual/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker: 20.10+ (for containerized deployment)</li> <li>Python: 3.11+ (for local development)</li> <li>Memory: 8GB RAM minimum</li> <li>Storage: 10GB available space</li> <li>OS: macOS, Linux, or Windows with WSL2</li> </ul>"},{"location":"user-manual/installation/#quick-start-docker-compose","title":"Quick Start (Docker Compose)","text":"<pre><code># From the repo root, start the minimal developer stack\nmake dev-up\n\n# Tail logs or check health\nmake dev-logs\ncurl -f http://localhost:${GATEWAY_PORT:-21016}/v1/health || echo \"\u274c Health check failed\"\n</code></pre> <p>Visit <code>http://localhost:${GATEWAY_PORT:-21016}/ui</code> to access the UI.</p>"},{"location":"user-manual/installation/#local-development-setup","title":"Local Development Setup","text":""},{"location":"user-manual/installation/#1-clone-repository","title":"1. Clone Repository","text":"<pre><code>git clone https://github.com/somatechlat/somaagent01.git\ncd somaagent01\n</code></pre>"},{"location":"user-manual/installation/#2-create-virtual-environment","title":"2. Create Virtual Environment","text":"<pre><code>python3.11 -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\npip install -r requirements.txt\n</code></pre>"},{"location":"user-manual/installation/#3-configure-environment-optional","title":"3. Configure Environment (optional)","text":"<p>Use the provided example as a minimal starting point:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Notes: - Provider API keys and model selection are managed via the Gateway UI Settings and stored centrally (do not place provider secrets in <code>.env</code>). - Infrastructure DSNs and ports may be adjusted via <code>.env</code> if needed.</p>"},{"location":"user-manual/installation/#4-start-infrastructure","title":"4. Start Infrastructure","text":"<pre><code># Start Kafka, Redis, PostgreSQL, OPA\nmake deps-up\n\n# Verify services are healthy\ndocker ps | grep -E \"kafka|redis|postgres|opa\"\n</code></pre>"},{"location":"user-manual/installation/#5-start-services","title":"5. Start Services","text":"<pre><code># Launch gateway + workers\nmake stack-up\n\n# Verify gateway is running\ncurl http://localhost:${GATEWAY_PORT:-21016}/v1/health\n</code></pre>"},{"location":"user-manual/installation/#6-start-ui-local-dev-option","title":"6. Start UI (local dev option)","text":"<pre><code>make ui\nopen http://127.0.0.1:3000\n</code></pre>"},{"location":"user-manual/installation/#port-reference","title":"Port Reference","text":"Service Port Purpose UI 3000 Web interface (local dev) Gateway 21016 API endpoint (configurable via GATEWAY_PORT) Kafka 20000 Event streaming Redis 20001 Cache PostgreSQL 20002 Database OPA 20009 Policy engine SomaBrain 9696 Memory service"},{"location":"user-manual/installation/#verification","title":"Verification","text":"<pre><code># Check all services\nmake check-stack\n\n# Expected output:\n# \u2705 Kafka: healthy\n# \u2705 Redis: healthy\n# \u2705 PostgreSQL: healthy\n# \u2705 Gateway: healthy\n</code></pre>"},{"location":"user-manual/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-manual/installation/#port-already-in-use","title":"Port Already in Use","text":"<pre><code># Find process using port\nlsof -i :21016\n\n# Kill process\nkill -9 &lt;PID&gt;\n</code></pre>"},{"location":"user-manual/installation/#docker-compose-fails","title":"Docker Compose Fails","text":"<pre><code># Clean up and restart\nmake down\ndocker system prune -f\nmake up\n</code></pre>"},{"location":"user-manual/installation/#database-connection-errors","title":"Database Connection Errors","text":"<pre><code># Reset database\ndocker compose down -v\ndocker compose up -d postgres\nsleep 5\nmake stack-up\n</code></pre>"},{"location":"user-manual/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Tutorial</li> <li>Features Overview</li> <li>FAQ</li> </ul>"},{"location":"user-manual/quick-start-tutorial/","title":"Quick Start Tutorial","text":"<p>This quick start gets you chatting with the agent on your local machine using a production-parity dev stack.</p>"},{"location":"user-manual/quick-start-tutorial/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose v2</li> <li>Python 3.12 with virtualenv (optional for running tests locally)</li> <li>At least 8GB RAM for the stack</li> </ul>"},{"location":"user-manual/quick-start-tutorial/#start-the-local-stack","title":"Start the local stack","text":"<p>We run all core services (Kafka, Redis, Postgres, OPA) and the app services (Gateway, Conversation Worker, Tool Executor, Memory Replicator/Sync, Outbox Sync) with the correct profiles and ports.</p> <p>1) Set the Gateway host port to 21016 and enable required profiles:</p> <pre><code>export GATEWAY_PORT=21016\ndocker compose --profile core --profile dev up -d\n</code></pre> <p>The UI will be available at: http://localhost:21016/ui/index.html</p> <p>Notes:</p> <ul> <li>LLM/secrets are centralized in the Gateway; the Conversation Worker fetches credentials via an internal token.</li> <li>Attachments are stored in Postgres and referenced by ID; services fetch bytes via the internal endpoint.</li> <li>SomaBrain base URL is aligned to port 9696 for memory writes and WAL emission.</li> </ul>"},{"location":"user-manual/quick-start-tutorial/#verify-health","title":"Verify health","text":"<p>Open http://localhost:21016/v1/health and confirm component statuses are okay. If Kafka is still booting, give it ~30\u201360s.</p>"},{"location":"user-manual/quick-start-tutorial/#configure-the-llm-groq-by-default","title":"Configure the LLM (Groq by default)","text":"<p>1) Open Settings in the UI. 2) In the LLM Credentials section, select provider \u201cgroq\u201d and paste your API key. 3) In the Model Profile section, set:     - Model: <code>llama-3.1-8b-instant</code> (or another Groq model you have access to)     - Base URL: <code>https://api.groq.com/openai/v1</code>     - Temperature: <code>0.2</code> 4) Save. The Gateway will normalize and persist these values globally.</p> <p>Verify from a terminal: <pre><code>curl -s -X POST http://localhost:21016/v1/llm/test -H 'Content-Type: application/json' -d '{\"role\":\"dialogue\"}' | jq .\n</code></pre></p>"},{"location":"user-manual/quick-start-tutorial/#upload-a-file-and-send-a-message","title":"Upload a file and send a message","text":"<p>1) In the UI, click the paperclip to upload a small text file. The UI posts to <code>/v1/uploads</code> and shows the file as an attachment. 2) Send a chat message and include the uploaded file if relevant. Small files are ingested inline.</p>"},{"location":"user-manual/quick-start-tutorial/#run-quick-tests-optional","title":"Run quick tests (optional)","text":"<ul> <li>API smoke and gateway unit tests:</li> </ul> <pre><code>pytest -q tests/test_gateway_llm_audit.py\n</code></pre> <ul> <li>Live E2E (requires running stack):</li> </ul> <pre><code>export GATEWAY_BASE_URL=http://localhost:21016\npytest -q tests/e2e/test_document_ingest_by_id.py\n</code></pre> <p>If you have Playwright installed and want to exercise the UI flow:</p> <pre><code>export GATEWAY_BASE_URL=http://localhost:21016\nexport E2E_LIVE=1\npytest -q tests/e2e/test_ui_chat_playwright.py\n</code></pre>"},{"location":"user-manual/quick-start-tutorial/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If the Gateway returns 5xx during first requests, Kafka metadata may still be warming up\u2014retry once after ~10s.</li> <li>Ensure <code>GATEWAY_INTERNAL_TOKEN</code> is the same on Gateway and Worker/Tool containers (compose defaults to <code>dev-internal-token</code>).</li> <li>If <code>/v1/admin/memory</code> returns 401/403, your environment requires admin auth; E2E memory checks will be skipped.</li> </ul> <p>Standards: ISO/IEC 29148\u00a75.2</p>"},{"location":"user-manual/quick-start-tutorial/#your-first-conversation","title":"Your First Conversation","text":""},{"location":"user-manual/quick-start-tutorial/#1-access-the-ui","title":"1. Access the UI","text":"<p>Open your browser to: <code>http://localhost:21016/ui/index.html</code></p>"},{"location":"user-manual/quick-start-tutorial/#2-login-if-enabled","title":"2. Login (if enabled)","text":"<p>If authentication is enabled, enter the password configured in <code>.env</code>. By default in local dev, auth is disabled.</p>"},{"location":"user-manual/quick-start-tutorial/#3-start-a-conversation","title":"3. Start a Conversation","text":"<p>Type in the chat input: <pre><code>Hello! Can you help me understand what you can do?\n</code></pre></p> <p>Expected: The agent responds with its capabilities.</p>"},{"location":"user-manual/quick-start-tutorial/#4-execute-code","title":"4. Execute Code","text":"<p>Try a simple task: <pre><code>Create a Python script that prints the current date and time, then run it.\n</code></pre></p> <p>Expected: The agent writes Python code, executes it, and shows the output.</p>"},{"location":"user-manual/quick-start-tutorial/#5-use-memory","title":"5. Use Memory","text":"<p>Ask the agent to remember something: <pre><code>Remember that my favorite programming language is Python.\n</code></pre></p> <p>Then in a new session: <pre><code>What's my favorite programming language?\n</code></pre></p> <p>Expected: The agent recalls the information from memory.</p>"},{"location":"user-manual/quick-start-tutorial/#common-tasks","title":"Common Tasks","text":""},{"location":"user-manual/quick-start-tutorial/#file-operations","title":"File Operations","text":"<pre><code>Create a file called test.txt with \"Hello World\" in it.\n</code></pre>"},{"location":"user-manual/quick-start-tutorial/#web-search","title":"Web Search","text":"<pre><code>Search for the latest news about AI agents.\n</code></pre>"},{"location":"user-manual/quick-start-tutorial/#multi-agent-delegation","title":"Multi-Agent Delegation","text":"<pre><code>I need to analyze a large dataset. Can you delegate this to a subordinate agent?\n</code></pre>"},{"location":"user-manual/quick-start-tutorial/#next-steps","title":"Next Steps","text":"<ul> <li>Features Overview</li> <li>FAQ</li> <li>Troubleshooting</li> </ul>"},{"location":"user-manual/troubleshooting/","title":"Troubleshooting Guide","text":"<p>Standards: ISO/IEC 21500\u00a77.4</p>"},{"location":"user-manual/troubleshooting/#common-issues","title":"Common Issues","text":""},{"location":"user-manual/troubleshooting/#gateway-health-check-fails","title":"Gateway Health Check Fails","text":"<p>Symptom: <code>curl http://localhost:21016/v1/health</code> returns error</p> <p>Diagnosis: <pre><code># Check if gateway is running\ndocker compose ps gateway\n\n# Check logs\ndocker compose logs gateway --tail=50\n</code></pre></p> <p>Solutions:</p> Cause Fix Kafka not ready Wait 30s, retry. Check <code>docker compose logs kafka</code> PostgreSQL connection failed Verify <code>docker compose ps postgres</code>, check credentials in <code>.env</code> Port 21016 in use <code>lsof -i :21016</code>, kill conflicting process"},{"location":"user-manual/troubleshooting/#conversation-worker-not-processing-messages","title":"Conversation Worker Not Processing Messages","text":"<p>Symptom: Messages sent but no response</p> <p>Diagnosis: <pre><code># Check worker logs\ndocker compose logs conversation-worker --tail=100\n\n# Check Kafka topic lag\ndocker compose exec kafka kafka-consumer-groups.sh \\\n  --bootstrap-server localhost:9092 \\\n  --group conversation-worker-group \\\n  --describe\n</code></pre></p> <p>Solutions:</p> Cause Fix Worker crashed <code>docker compose restart conversation-worker</code> LLM credentials missing/invalid Open Settings \u2192 LLM Credentials, set the provider (e.g., groq) and paste the key, then Save. (Legacy <code>/v1/llm/credentials</code> endpoint removed.) Kafka consumer lag Scale workers: <code>docker compose up -d --scale conversation-worker=3</code>"},{"location":"user-manual/troubleshooting/#memory-not-persisting","title":"Memory Not Persisting","text":"<p>Symptom: Agent forgets information between sessions</p> <p>Diagnosis: <pre><code># Check SomaBrain health\ncurl http://localhost:9696/health\n\n# Check memory replicator logs\ndocker compose logs memory-replicator --tail=50\n\n# Check PostgreSQL memory_replica table\ndocker compose exec postgres psql -U somauser -d somadb \\\n  -c \"SELECT COUNT(*) FROM memory_replica;\"\n</code></pre></p> <p>Solutions:</p> Cause Fix SomaBrain not running Start: <code>docker compose up -d somabrain</code> Memory replicator failed Check logs, restart: <code>docker compose restart memory-replicator</code> PostgreSQL disk full Free space, increase volume size"},{"location":"user-manual/troubleshooting/#ui-not-loading","title":"UI Not Loading","text":"<p>Symptom: Browser shows blank page or connection error</p> <p>Diagnosis: <pre><code># Check UI service\ndocker compose ps ui\n\n# Check UI logs\ndocker compose logs ui --tail=50\n\n# Check browser console (F12)\n</code></pre></p> <p>Solutions:</p> Cause Fix UI service not running <code>docker compose up -d ui</code> Gateway not accessible Verify gateway health, check network Browser cache issue Hard refresh (Ctrl+Shift+R), clear cache CORS error Check <code>CORS_ORIGINS</code> in <code>.env</code>"},{"location":"user-manual/troubleshooting/#high-cpu-usage","title":"High CPU Usage","text":"<p>Symptom: System slow, high CPU in <code>docker stats</code></p> <p>Diagnosis: <pre><code># Check resource usage\ndocker stats --no-stream\n\n# Check which service is consuming CPU\ndocker compose top\n</code></pre></p> <p>Solutions:</p> Cause Fix Kafka rebalancing Wait for stabilization (2-5 minutes) LLM streaming Normal during response generation Memory leak Restart affected service Too many workers Reduce scale: <code>docker compose up -d --scale conversation-worker=1</code>"},{"location":"user-manual/troubleshooting/#database-connection-pool-exhausted","title":"Database Connection Pool Exhausted","text":"<p>Symptom: <code>asyncpg.exceptions.TooManyConnectionsError</code></p> <p>Diagnosis: <pre><code># Check active connections\ndocker compose exec postgres psql -U somauser -d somadb \\\n  -c \"SELECT COUNT(*) FROM pg_stat_activity;\"\n</code></pre></p> <p>Solutions:</p> Cause Fix Connection leak Restart services: <code>docker compose restart</code> Too many workers Reduce worker count or increase <code>max_connections</code> in PostgreSQL Long-running queries Check <code>pg_stat_activity</code>, kill slow queries"},{"location":"user-manual/troubleshooting/#diagnostic-commands","title":"Diagnostic Commands","text":""},{"location":"user-manual/troubleshooting/#full-system-health-check","title":"Full System Health Check","text":"<pre><code># Quick health probes\ncurl -sS -D - http://localhost:21016/v1/health -o /dev/null | head -n 1\ncurl -sS http://localhost:21016/v1/ui/settings | jq .\ncurl -sS http://localhost:21016/v1/ui/settings/credentials | jq .\n\n# Expected output:\n# \u2705 Kafka: healthy\n# \u2705 Redis: healthy\n# \u2705 PostgreSQL: healthy\n# \u2705 OPA: healthy\n# \u2705 Gateway: healthy\n# \u2705 SomaBrain: healthy\n</code></pre>"},{"location":"user-manual/troubleshooting/#view-all-logs","title":"View All Logs","text":"<pre><code># All services\ndocker compose logs -f\n\n# Specific service\ndocker compose logs -f gateway\n\n# Last 100 lines\ndocker compose logs --tail=100 conversation-worker\n</code></pre>"},{"location":"user-manual/troubleshooting/#reset-everything","title":"Reset Everything","text":"<pre><code># Nuclear option: delete all data and restart\ndocker compose down -v\ndocker system prune -f\nmake dev-up\n\n## LLM Issues (401/405)\n\n### 401 Unauthorized during chat\n\nSymptoms:\n- Gateway audit shows `llm.invoke` with `http_status=401` and provider `groq`/`openrouter`.\n\nFix:\n- Open the Settings modal \u2192 enter provider key in the `api_key_*` field and Save (sections endpoint persists + encrypts).\n- Ensure the selected model is accessible by your key.\n- Verify with:\n  ```bash\n  curl -s -X POST http://localhost:21016/v1/llm/test -H 'Content-Type: application/json' -d '{\"role\":\"dialogue\"}' | jq .\n  ```\n\n### 405 Method Not Allowed (OpenRouter)\n\nSymptoms:\n- Audit shows provider `openrouter` with `http_status=405`.\n\nCause:\n- Base URL saved as `https://openrouter.ai/openai`, which is not compatible when composing `/v1/chat/completions`.\n\nFix:\n- Save Settings again; the Gateway normalizes `/openai` \u2192 `/api`.\n- Confirm the effective profile:\n  ```bash\n  curl -s http://localhost:21016/v1/ui/settings | jq .\n  ```\n</code></pre>"},{"location":"user-manual/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If issues persist:</p> <ol> <li> <p>Collect diagnostics:    <pre><code>docker compose logs &gt; logs.txt\ndocker compose ps &gt; services.txt\ndocker stats --no-stream &gt; stats.txt\n</code></pre></p> </li> <li> <p>Open GitHub issue: https://github.com/somatechlat/somaagent01/issues</p> </li> <li> <p>Include:</p> </li> <li>Steps to reproduce</li> <li>Error messages</li> <li>Log files</li> <li> <p>Environment (OS, Docker version)</p> </li> <li> <p>Join Discord: https://discord.gg/B8KZKNsPpj</p> </li> </ol>"},{"location":"user-manual/using-the-agent/","title":"Using the Agent","text":"<p>Placeholder overview of daily usage, starting chats, invoking tools, and managing tasks.</p>"}]}