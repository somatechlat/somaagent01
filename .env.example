# Agent Zero example environment file for local development.
# Copy this to .env and provide required secrets. Do NOT commit .env.

## ---------------------------------------------------------------------------
## Port bindings for Docker dependencies (can be adjusted if ports clash)
## ---------------------------------------------------------------------------
AGENT_UI_PORT=21015
GATEWAY_PORT=21016
# Canonical gateway/url variables
# Full base URL for services and API clients (preferred)
GATEWAY_BASE_URL=http://localhost:${GATEWAY_PORT}
# UI entry point served by the Gateway (UI path)
WEB_UI_BASE_URL=http://localhost:${GATEWAY_PORT}/ui
KAFKA_PORT=21000
REDIS_PORT=21001
POSTGRES_PORT=21002
OPA_PORT=21009

## ---------------------------------------------------------------------------
## Shared infrastructure connection strings
## ---------------------------------------------------------------------------
KAFKA_BOOTSTRAP_SERVERS=localhost:${KAFKA_PORT}
REDIS_URL=redis://localhost:${REDIS_PORT}/0
POSTGRES_DSN=postgresql://soma:soma@localhost:${POSTGRES_PORT}/somaagent01
OPA_URL=http://localhost:${OPA_PORT}
POLICY_BASE_URL=http://localhost:${OPA_PORT}
POLICY_DATA_PATH=/v1/data/soma/policy/allow
POLICY_FAIL_OPEN=false

## ---------------------------------------------------------------------------
## Gateway + Worker coordination
## ---------------------------------------------------------------------------
GATEWAY_ENC_KEY=O6qM9Oe7zB3w6CqQFctciVwEciXxV9nOcDSBxPTsPOg=
GATEWAY_INTERNAL_TOKEN=dev-internal-token
GATEWAY_REQUIRE_AUTH=false
GATEWAY_WRITE_THROUGH=true
GATEWAY_WRITE_THROUGH_ASYNC=true
CONVERSATION_INBOUND=conversation.inbound
CONVERSATION_OUTBOUND=conversation.outbound
CONVERSATION_GROUP=conversation-worker
TOOL_REQUESTS_TOPIC=tool.requests
TOOL_RESULTS_TOPIC=tool.results
TOOL_EXECUTOR_GROUP=tool-executor
MEMORY_WAL_TOPIC=memory.wal
SOMA_AGENT_MODE=DEV
SOMA_BASE_URL=http://localhost:9696
SOMA_TENANT_ID=public
SOMA_NAMESPACE=somabrain_ns:public
SOMA_MEMORY_NAMESPACE=wm

## ---------------------------------------------------------------------------
## LLM provider defaults (fill in API keys for live calls)
## ---------------------------------------------------------------------------
SLM_BASE_URL=https://api.groq.com/openai/v1
SLM_MODEL=openai/gpt-oss-120b
SLM_API_KEY=
# Alternatively: read from a mounted file or base64 value
# SLM_API_KEY_FILE=/var/run/secrets/slm_api_key
# SLM_API_KEY_B64=
USE_LLM=true

## Optional provider-specific keys used by tools/settings
GROQ_API_KEY=
OPENROUTER_API_KEY=
OPENAI_API_KEY=
HUGGINGFACE_API_KEY=
GITHUB_COPILOT=
# File-based alternatives (uncomment and set paths if mounting secrets)
# GROQ_API_KEY_FILE=/run/secrets/groq_api_key
# OPENROUTER_API_KEY_FILE=/run/secrets/openrouter_api_key
# OPENAI_API_KEY_FILE=/run/secrets/openai_api_key
# HUGGINGFACE_API_KEY_FILE=/run/secrets/hf_api_key

## LiteLLM global kwargs (newline-separated key=value entries, when used)
LITELLM_GLOBAL_KWARGS=

## ---------------------------------------------------------------------------
## UI runtime (local development)
## ---------------------------------------------------------------------------
UI_USE_GATEWAY=true
UI_GATEWAY_BASE=http://127.0.0.1:${GATEWAY_PORT}
AUTH_LOGIN=admin
AUTH_PASSWORD=
# AUTH_PASSWORD_FILE=/run/secrets/ui_admin_password

## Misc
DEFAULT_CHAT_MODEL=openai/gpt-4.1
ANONYMIZED_TELEMETRY=false

# Optional: other secrets via files
# REDIS_PASSWORD_FILE=/run/secrets/redis_password
# GATEWAY_JWT_SECRET_FILE=/run/secrets/gateway_jwt_secret
